{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本次练习目的\n",
    "1、使用sklearn数据集训练逻辑回归模型；\n",
    "2、调整学习率，样本数据拆分比率，观察训练结果；\n",
    "3、训练后模型参数保存到文件，在另一个代码中加载参数实现预测功能；\n",
    "4、总结逻辑回归运算及训练相关知识点\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、使用sklearn数据集训练逻辑回归模型；相关代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.9599791431817668, acc: 0.275\n",
      "epoch: 100, loss: 0.20727524272229064, acc: 0.925\n",
      "epoch: 200, loss: 0.09952397527942906, acc: 1.0\n",
      "epoch: 300, loss: 0.06761241758626649, acc: 1.0\n",
      "epoch: 400, loss: 0.05186177534773138, acc: 1.0\n",
      "epoch: 500, loss: 0.04231574368053575, acc: 1.0\n",
      "epoch: 600, loss: 0.03585666304876666, acc: 1.0\n",
      "epoch: 700, loss: 0.03117363029005732, acc: 1.0\n",
      "epoch: 800, loss: 0.027612472383512544, acc: 1.0\n",
      "epoch: 900, loss: 0.024807877155773147, acc: 1.0\n",
      "epoch: 1000, loss: 0.02253887738085033, acc: 1.0\n",
      "epoch: 1100, loss: 0.020663568068510364, acc: 1.0\n",
      "epoch: 1200, loss: 0.019086462068594788, acc: 1.0\n",
      "epoch: 1300, loss: 0.017740850811307746, acc: 1.0\n",
      "epoch: 1400, loss: 0.016578671072296648, acc: 1.0\n",
      "epoch: 1500, loss: 0.015564387019848724, acc: 1.0\n",
      "epoch: 1600, loss: 0.014671141013391755, acc: 1.0\n",
      "epoch: 1700, loss: 0.013878246069310093, acc: 1.0\n",
      "epoch: 1800, loss: 0.01316950295194264, acc: 1.0\n",
      "epoch: 1900, loss: 0.012532041169415406, acc: 1.0\n",
      "epoch: 2000, loss: 0.01195550253458501, acc: 1.0\n",
      "epoch: 2100, loss: 0.011431454444860026, acc: 1.0\n",
      "epoch: 2200, loss: 0.010952960687993443, acc: 1.0\n",
      "epoch: 2300, loss: 0.010514262442012385, acc: 1.0\n",
      "epoch: 2400, loss: 0.010110537749849036, acc: 1.0\n",
      "epoch: 2500, loss: 0.009737717789154061, acc: 1.0\n",
      "epoch: 2600, loss: 0.009392344853654172, acc: 1.0\n",
      "epoch: 2700, loss: 0.009071461380351406, acc: 1.0\n",
      "epoch: 2800, loss: 0.008772522368563036, acc: 1.0\n",
      "epoch: 2900, loss: 0.008493325623183483, acc: 1.0\n",
      "epoch: 3000, loss: 0.00823195572141525, acc: 1.0\n",
      "epoch: 3100, loss: 0.007986738647647155, acc: 1.0\n",
      "epoch: 3200, loss: 0.007756204795664942, acc: 1.0\n",
      "epoch: 3300, loss: 0.007539058588308144, acc: 1.0\n",
      "epoch: 3400, loss: 0.0073341533713538075, acc: 1.0\n",
      "epoch: 3500, loss: 0.007140470541634919, acc: 1.0\n",
      "epoch: 3600, loss: 0.0069571020976535725, acc: 1.0\n",
      "epoch: 3700, loss: 0.0067832359742843575, acc: 1.0\n",
      "epoch: 3800, loss: 0.0066181436559008796, acc: 1.0\n",
      "epoch: 3900, loss: 0.006461169664699083, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#使用make_classification创建数据集\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "##第一步，数据准备，有时需要预处理\n",
    "X,y=make_classification(n_samples=100,n_features=10)\n",
    "##数据拆分为训练数据和测试数据\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.6)\n",
    "# print(X_test.shape)查看训练数据分类后的形状\n",
    "# print(X_train.shape)\n",
    "##设置初始权重参数，超参数，训练轮次\n",
    "#权\n",
    "theta = np.random.randn(1,10)#生成形状为（1，10）的正态分布数组\n",
    "bias = 0\n",
    "#超\n",
    "lr = 0.01\n",
    "#轮\n",
    "epochs = 4000\n",
    "\n",
    "##第二步，模型运算(前向运算)\n",
    "\n",
    "def forward(x,theta,bias):\n",
    "    #线性运算 可以理解为z = theta*X + bias，下方是矩阵形式，X是一个样本所有的特征值之和\n",
    "    z = np.dot(theta,x.T) + bias#theta是（1，10），训练数据x是（80，10），矩阵乘法原因，需x转置之后才能运算\n",
    "    #sigmoid,激活函数，将y_hat转换为对应概率值\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    return y_hat\n",
    "\n",
    "##第三步，计算损失，且损失函数公式一般都由模型直接给出,本周学习用的是伯努利二分步对数损失函数\n",
    "def loss(y , y_hat) :\n",
    "    eposion = 1e-8\n",
    "    return - y * np.log( y_hat + eposion ) - ( 1 - y) * np.log( 1 -y_hat )\n",
    "\n",
    "## 第四步，计算梯度，求导，公式经由损失函数推出\n",
    "def calc_gradient(x,y,y_hat) :\n",
    "    m = x.shape[-1]#要用中括号\n",
    "    delta_theta = np.dot((y_hat - y), x ) / m\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    return delta_theta,delta_bias\n",
    "## 第五步，更新参数，重复训练（需要用到学习率）\n",
    "for i in range(epochs):\n",
    "    # 前向计算\n",
    "    y_hat = forward(X_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(X_train, y_train, y_hat)\n",
    "    # 更新参数\n",
    "    theta = theta - lr * delta_theta\n",
    "    bias = bias - lr * delta_bias\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # [False,True,...,False] -> [0,1,...,0]\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.3553031038909333, acc: 0.55\n",
      "epoch: 500, loss: 0.014736214709908855, acc: 1.0\n",
      "epoch: 1000, loss: 0.007818166030047351, acc: 1.0\n",
      "epoch: 1500, loss: 0.005395965710856491, acc: 1.0\n",
      "epoch: 2000, loss: 0.0041467644932795715, acc: 1.0\n",
      "epoch: 2500, loss: 0.0033798502997489494, acc: 1.0\n",
      "epoch: 3000, loss: 0.0028591624245286537, acc: 1.0\n",
      "epoch: 3500, loss: 0.0024815758665766544, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#导入iris数据集，进行训练\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#1、数据处理\n",
    "iris = load_iris()\n",
    "X = iris.data[:100, :]  # 前 100 个样本，所有 4 个属性\n",
    "y = iris.target[:100]   # 前 100 个样本的标签\n",
    "##数据拆分为训练数据和测试数据\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.6)\n",
    "# print(X_test.shape)查看训练数据分类后的形状\n",
    "# print(X_train.shape)\n",
    "##设置初始权重参数，超参数，训练轮次\n",
    "#权\n",
    "theta = np.random.randn(1,4)#生成形状为（1，10）的正态分布数组\n",
    "bias = 0\n",
    "#超\n",
    "lr = 0.01\n",
    "#轮\n",
    "epochs = 4000\n",
    "\n",
    "##第二步，模型运算(前向运算)\n",
    "\n",
    "def forward(x,theta,bias):\n",
    "    #线性运算 可以理解为z = theta*X + bias，下方是矩阵形式，X是一个样本所有的特征值之和\n",
    "    z = np.dot(theta,x.T) + bias#theta是（1，10），训练数据x是（80，10），矩阵乘法原因，需x转置之后才能运算\n",
    "    #sigmoid,激活函数，将y_hat转换为对应概率值\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    return y_hat\n",
    "\n",
    "##第三步，计算损失，且损失函数公式一般都由模型直接给出,本周学习用的是伯努利二分步对数损失函数\n",
    "def loss(y , y_hat) :\n",
    "    eposion = 1e-8\n",
    "    return - y * np.log( y_hat + eposion ) - ( 1 - y) * np.log( 1 -y_hat )\n",
    "\n",
    "## 第四步，计算梯度，求导，公式经由损失函数推出\n",
    "def calc_gradient(x,y,y_hat) :\n",
    "    m = x.shape[-1]#要用中括号\n",
    "    delta_theta = np.dot((y_hat - y), x ) / m\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    return delta_theta,delta_bias\n",
    "## 第五步，更新参数，重复训练（需要用到学习率）\n",
    "for i in range(epochs):\n",
    "    # 前向计算\n",
    "    y_hat = forward(X_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(X_train, y_train, y_hat)\n",
    "    # 更新参数\n",
    "    theta = theta - lr * delta_theta\n",
    "    bias = bias - lr * delta_bias\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # [False,True,...,False] -> [0,1,...,0]\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAACnCAIAAAD/iJ7qAAAgAElEQVR4Ae2dQWskyfH2/TEEPvR1D3swGMaH1YKvC0YYj88GG+FZpsGw4ME2uzQ++WR2YIchb8K8y1ym8aEv02AsDH3RpT/Un61H89vnjcyqLkndkkodhZGzszIiI5+IfDKqpjL3J7PZ7Ozs7C9/+csnn3zy17/+9Ze//OVsNvv5z3/+j3/847e//e3s4/XnP//5D3/4w8df1///i198fnKT649//OPFxcUnn3wioS+//PLf//73Z599Nl7H999//+LFi5OTky+++OL9+/fPnj1D9tmzZ+/fv//iiy9OTk5evHjx/fffcysLiUAikAiMQeAns9nsT3/603fd9fbt23/+85+ff/75gQjxpz/96Xfffff3v/9dnPXhw4ff/OY3Y6ykzUhCPDk5efv27Xa7/frrr5HNQiKQCCQCwwj8QIhcyhB//etff/vtt6WU77777ne/+53u7iVDPDk5+eyzz5bL5d/+9rcPHz4o1xu2L9x9210nJydff/3127dv/a5niNRDoNRkIRFIBBKBPgT+P0KEGevCvgjx5OTk/Pz8f//735dfftln00D9s2fPPnz4sN1uP3z48OzZsxcvXvz3v//VY7IT4osXL66urrbb7fv37we05a1EIBFIBByBn/zqV7+q6c9rfvazn33zzTfffvst2SJ3b/oO0TvOciKQCCQCjw2BsRkiJOiFJMTH5s60JxFIBO6CQBLiXdBL2UQgEXhSCCQhPil35mASgUTgLggkId4FvZRNBBKBJ4VAEuKTcmcOJhFIBO6CwF0J8Re/+Dz/lwgkAonA00DgToTo/+Kc5UQgEUgEpo5AEuLUPZj2JwKJwN4QSELcG5SpKBFIBKaOQBLi1D2Y9icCicDeEEhC3BuUqSgRSASmjkAS4tQ9mPYnAonA3hBIQtwblKkoEUgEpo5AEuLUPZj2JwKJwN4QSELcG5SpKBFIBKaOQBLi1D2Y9icCicDeEEhC3BuUqSgRSASmjkAS4tQ9mPYnAonA3hCYDCHO5/PVanV6enq7oc/nc/1XVtbr9Y2UnJ6ertfr7Xa72WzOzs5u1/stpOh3u90O21xK2XbX1dXVfD6fzWYuu91uF4uF/mOzm80mtFwsFqqh2Ww2q7E6OztDdrlcMhx17TV0jTFN2eFKZGezGRbSC124zcMgACDaXJbhPIZCDX7TKsa73W6FjMPyaEfXHMujqvyBED/99NP/112ffvrpbDb75ptv/vOf//z+979/VIbehRDPzs4uLy9FFqUUptb4AZ6dna3X6/skRLdtuVyWUrymWV4sFpr5p6enq9VK46Xl8BDm8/nl5eVZdw1gpVknhpVVAU9MRSEG1LLibpnqd/G1K0EzheaIAIF+Z7MZIlS6ZiofvDA+UEt3ucFNp3uDLI9B4ICE6EuWptB8Pl8ulyHh8mY+7VkDNck1SVarVUjWlGu4YD3sxWIBCS6Xy1vkemHuNW32rAd7SEk869EUJW2pDfYaZwqvr8twU3NuhCEEcXhkGCufsdJAp0pCWTY0cPldLV22lIJbIWJksb90Fznver1+/vy5c/1yufQuZrOZ26N+mwAyXrUZ85fcbbvd4l/1qCwbhzbDY4zTh8F3I0t3eQ2geWWWb4rAAR+ZCVZmgkJKEUzgsnp74NbxKlkFIiI8CXqA1hCU7pL+d+/eMfHqln01gU0wwG1WL65hIEa1MAw/vMOwsLkr9/JyufR1wicksxRtPGRJgxYe+Lp0V40VdBCgxo961tZrDfHdarWSr5uyYkw3j8x0sVjIHoWQLL+4uFitVs+fP1+v165WZdGNg0BsDI/XYRxZdrfWgdpMSKV5p9M77EsNfm0Y6QKOazq9FsyaYQQORYg+/bbbrdzGoxCTJyz4pbsUUgS6BuCyNNOtnX9LKRcXF5pIgdp2yqqBS/l8UIIgjtAMD+S17KgqjGVkpzRbdhc/+wqLxaJOfmtZzZzAa/P5fLPZzOfzYaxq2ZoQLy4uBAIrogx2WUwtpWAz2fSqu/Q88fr1axElAQC9rtdrOBdM0EyNwin4hfF6s+GyhzQ0FMYY0uRhhfXdYfDr9nrHCoA0qJ3OrSwMI3BAQqwTMWJajqyfgEp37Z0Q/fHtdi+PxhCigD4ELTbTkNqvZOJ+y5/CqC/dxU+eSRfdxSv5JlbOgOERVZQh6hH9hZVAsuEW6Tb2gHYpBeqpQQgrk8T7QCAVVbNgA10PFGAZ73e/hHiLQAUrt7zpdG+Q5T4EDkWIzQcHJ0SmAQVNJ00h3jFht8uW7tItSYV8BynawM6ENY9UIXcIsrUGH5rbjKCbSmXpLn7ufHqipXenyr7XoE3KWK/XAZw+m+t3eY6Vuq55JPAjBFFnai6L072SIXMXJNUsDCR0LfEahBpAPaBovJLyFzKYEQpYxRO91oMm1QZTpWqn053dAvh9Tq9nShOrMJb82YfAAQlRE8/fN/Ow4691vJmHkR42+eiEueFPqZCaCzaHyuOYh69Cx2tqWTcPY7ySrjGYDMubheeaMXODL13oQuaFuUG/DMT7RdbB16ojJOUgN6/GalhWGqSTrsnsmrI083+g4L0YNruFrFuYR40ozyONwFAlCunCx0tjV1hHAgPhiR53jOlaRuKjWr9qGF1oeTun9/WS9X0IHJAQ6y6d1Oq7D1IT1uEHsSE7fXAEMqt6cBc8EgOOlxC14A8nBY/ESWnGQRFQUkYWedC+UvkjR+BeCfGRY5HmJQKJwJEjkIR45AGQw08EEoEfEUhC/BGLLCUCicCRI5CEeOQBkMNPBBKBHxFIQvwRiywlAonAkSOQhHjkAZDDTwQSgR8RmAwh3uUbRn1lpq9n+Wrav+blQ2Va8l3xj1DtKvHRL9p2Sezn/nib+ejXPzaS2V7DTj6+XmZowlCN0eaQNo9TRNx7afbLl9jCEEHvt+k4vvR2x2Ghf+S87HaXu818cd38ShyFaOP7fKwN5u3Hr3vSotHhyj6tgOBY9TV+wvXHQoh+ZpTcycYv3/3K9qzmNt4xccDetTGN99JmpM0+IkRUAArs0YYw9jtSLwoIn+y5Zi9L6uzsbLlcnp6eirPEdH39SpzzbJr9Yi2O05IgzSycbknpLhkvUm7KsnPOZdkXTKFplVc+nrI2Mr569cr3KdbmgYZDVDc7hpoDEiKZC6vxQ52H6Lvx5VSv0dpYSmE+cFCz5tiN4iAQImmFL9EkPlSS4HiSouikTdOM8TaX7iL780QAilEXooOXL1/WhOjdYY9vHw7Dp40K4W7oF14LzbS1TsbsdBwNnL/Ekn60Ek5XvknOK1hq7lZIeIarEZXuUvmmf4kNJgjeUcrJwuPhQUxqCPwc6N35vdnMsQp7BJvtn3DlAQmRsGb9cRcyGchWmA+chePHBYYIDrHCz6arnJqJeE0wnUHw7t27UgrJRTjOr6mzr5JRhxMEYI0mp5TuqnX66Vj1XU5ROz093WmzDNPU0tmCwIsvmJCLxWKMnWJ2HipFRhcXF2E+y3LCgIF4v56bOIZqXLrLmdEd55o5eQHA2UR8fn5eOx39vr8eHJyqmvzF2gYIUnijvw410wENPi+o5NXEXgixdJc6ut2BoW7YpMuHIkRf0x78PET3kDYvKwRfv34tfuzi4ZoQ+47zcyUDZZ/MvvAS9Aq7MH802eoEZKAj3RKJj7F5uVzWZwtKiRMTZQzGBucdKjUzdZainB6eSdVSow7rFn2FxcMxFAlydmzTcWT02+3WT15YfnxdqAVAhBicLiJWGHDiBtZqRMHs5lmK9ek+DlGzrDVei4eeA2rMfc1rKhlTuTNDvMU5jGP6nWKbAxJi/cBFCkYO6E8xCk0FX5gSISxKd90ObpGUIl7TQBmEHpk3m43msxqMWX6DGW55kxDVXvrvTovOQcM2D5wtCDFJg6YofwGBZmHI9MvjqhoAhRrUdO8KSbXol/beTKqC49yeJqcMOx22ZSCeXdZsEoap3pv9umGhrL4U7chS8MY+a7x+fLkeQpDVeixH72wcZJ/Yz0MRIizjeLlreTSgoLktr9SnvLls6S5pbq7h3qmXPQo7HT/8l5t8wWcOhwXf2cQV1mU0hKynHpEggm6kyoc55h2iKxm2Gc0Ogjp1xmFEYXL2pYdhmO5NiKbvSKFmvz6ikB5irXjEHYfZGECNW166y50OCXpfTgpOjtIZcFZl8O/OgPF+eTFSu0ZWbTabECcawtXVVV0ve/yvD0f1vo6qC9KXPme5widcPiAhCnQt+FrS/RmB9d+b+bPJ8uPzDrL8Z0hLd8krYwix2YWCT+YRVbRs5m40awYEBvOKQIymLvi3EQfBMx0yI++FqdLs0RHwTlVfz0myMMCnJuAQJokGghT6w9D81Rtv3/zVGx+sDPQbCLEmzabjUEgI0cxdSSXmwSwBARTiuLpGpkoQVwocz7lUU/8FGX9tRwT6P695zBAequRnrT8MzV+Sqhd3KMaEgTTVPuHKAxJijRpJSn3rkdc0k5FHbnOa94AIZMA8IPh36ToJcTd6y+XSs4zdAtniuBHIgJmu/++VEKcLU1qeCCQCx4BAEuIxeDnHmAgkAqMQSEIcBVM2SgQSgWNAIAnxGLycY0wEEoFRCCQhjoIpGyUCicAxIJCEeAxezjEmAonAKASSEEfBlI0SgUTgGBCYDCHe8aNufZofPidkbwmf+7OTwVuyT+CmH/Gjjd0O9xZS422uQahl2aShXRna4eB7KnzPgxSyY8S3czgO0umCvrPCoa4trGuwcKfjalk5RRoWi4UfFeG7UNjL4btc6LfeB+KW3JvfR3bUBL+WZcjBTXXLJ1NzFISovZwvX75kd63vRfO9ruyEZfun3623kY2Jg7ApeIzIHduMt5kRIULBIXJ7SneJ5sR6HHagBUAnKUCIvhc4yNK79IO5fuovHqESKTeVu3TndxGh4HdFxJeXl82Daf2EDvXidpbuondUhWDzBg9eFqRA0WePD7P2Qp/U1OsPSIjkR6yoD3VArJzkc4A5TFbSd0Csz4fbnZ1ZEyJpBXmQZ1tOJcpQQq7BKVV9wTfS5iYIw7I+Fo4z8Jkjk3z+sIkNusTsMCf9XAy1qR8Lmjaj0Em8Hsj5+TkHpysLhtBFhbUB3h29wLnqDn/RwM+J8MoxZRJYz6Y9PJTDqmtPYKV8zOZ3Wg7nfaW72J9OrEr8qf49ICESXjCRolAeZTIweXzCeMwJeo9gRDgLpBmUwWeY4ScX6OSSgQNiS3fJNt+EH5QP/HQS4dwzHc4KCOrFlTSnohrsJERp22kzhjkIw7K6KzN4tKynijsIHwVad/LSrFutVuFw2cVisVqt1uv1drsVQTRtlj2iEnikHshXX33VPCAWLxCxPkBnDa1kPhDWNq+8CyHWXfu88Ls17IIUBGjcLDDq5l2O2BAXhxOF+0SeQP2hCNHXNA5i8QVf5fs8D7EmxHBWqEwKh63e/exM5rDCpXSXygCilzU+93j1RkYgkTF/R9oswwIIA7IOoNhQc6/OSpwQFQmLxcKXQ43C56SaCQE68gN71Lhps2PC2Vz1QESIYbye3gZCbDKRHil0IG6zX1UyBG8zpgzD8lKSIHHxYKrfGll28JsiAycKN9s/jcoDEiInrIGUu1Y54EMRomKdNVYT2Ockk0FUJVbyycOgdhbGEKKU7IsWR9rcBGFA1qcQ+MhyZ0B/vRjSwJD4B4U8z5Ke+GOvguf58+fr7lKKHfr11KweiE7MDk53AvJ/Mgq5vHs5jF23gpdvR4i8XlDvWh581mDGPRCir0bBcZjx9AqHIsQwKwScu5ZQpkAqoVlE4NaypbtUL6mbPjKrC0l5FBJnJBoe6H52prOnLOn76xrCNHOFEneIUFi6i587H5m9x9BFeA2KZkDok61nOI6rCYJbYbzOgIErPWDoy1cgZGubQca7aw5kWBbv8+KsmZ67VXTNG1XVMAQaaIDDz7NoFqTky/UBsaE7eqmzdW6FAnhS7wyoRFgnkMqYMVMMVdMtHJAQRRn+3lcPTWEd9mYOul4JcaSoM0XpLoE+hhC9CxTKzTKGuKelvxJSroGg+pV4YG3d4i/aHARNjL4a/gHKZcMs2kmI4oXQhawKhNgEoTneev64hTgOr/GepDnekJcJ/5HGNJvRr3ukHkhTFn85IdY5ETa7O+p+HZYQM4Fx6NcLUnh1dcWrG/7dL8Rq3bXWGDfPNVNmIEFhbR4tw8scVD29wgEJsQbLSa2+O7makHxNzv40+J4R4LHjnvvN7sYjkIQ4HqsfWyrVPZ5l88eRZ+lWCCgz3Zm73Up3Cu0TgXslxH0anroSgUQgEdg3AkmI+0Y09SUCicBkEUhCnKzr0vBEIBHYNwJJiPtGNPUlAonAZBFIQpys69LwRCAR2DcCSYj7RjT1JQKJwGQRmAwh3vEbRn0u2/zc2r+e5cNdb8n35P7R7xiPo+3+v7cYbzPf9y66owD9M2DG6x8bgwyfPfMxOec4+FfZTVmQcdm661rWBcN3xRoIn4jX2tw8dgrrY2ap8kqvd50aNTVYCCz04jVjouU+2+iL653fjeHinS3v0/iD9nUUhKgdUeGIOt8nC8TsOWMTle/BqndrIDhQ8D1kA832eGu8zYwIEQq+tW54CGAlthKxsoA1ZcHZ76IHKPwulRQ4EIh+Ueubmn0gNEBWdyE4lIMMNehcrVZqT78iX210awabK3nwskBoDtBtc3eAmzd4kuUDEqIv5kwSbTvjNCc2jWqJ9rhk25DyFE2w1WrlsqzGLtjnJ5/q2twW1j2fflobF91Fs7Dvra+jUO9qdSsMjVEEEFifQ66xc+uec/2AzU4KyihLKU3Zegg+Rna5eTOUe6WkuKWfbJijgPJalltND/q8bQ6ELcA+20t3uea+fqESxZs3C4MKwebKh8vKc5tBHjLiOopE7iMfR3YSYodKYYbyuDBs/9TvHpAQiW+CQ7NO5Ig/CGJfb5lj4MuM9VMAoJLbESIPSvC1FnlNm9VqtVgsFBay7WjPQ+TBsPlQCV/jaLGV6mtZdzQhIUIJ5yHWssRDICDVE0vkfbXjtMz49IZZGIivvlQSkwoJEsb5fO7jlSUOBTbfqAChO1xowBhqVLjL4Q5BleavXJDnIQZwbvzTQ5k3SjxG8YjxUMd/+Xg46EXmsaleAVEfq3d2dubiO8ueRzBRJQUgmqWkorqrZEFkvbMXbzDSZhkWzgccltXkDMsPAIoXtMysuktkIdtcVjyot7daeBQwQqBmE5eVtiYjBEK8uLjQUdi4gN3ETeLgLs8HGtF6vT4/P+e/P1G6CzOa462HoPY7/8LOrD0EicuSbXjljcpkJH1SeR5iHzK3qScEXdhdq4B+DIRIruFzkmXZ54Y/Z/m4hssBitJdEnFAYJO70+JImzVGciWxyU5Zt1+jACv91N8walWW7lJZfwGfgurrCd+J/vAEx0NcvVQ4IdYD0XmISHljqcVm94sq37x5w/OECuAWZPkJgapmzN+wtCgS3BiU1Phwa2RhJyH64TfN5WdkR9NqdthH5jqV0DOpP/YSl+IjxSvvekDTw6J0l25JKnSElBf6Fm3yAlklA6hkkugubOXs6b3UZddAxsH5piiUoA8TVaW7+LnzHaL3GI7kCa8U0cxUHJDlBQWcIpOa6wRuxWz3L5U+LRGpPRVk++YnGmQqRxQDAg2aJE7UuQF1X4DGKDyeVekaaBbAp54CSMo8xUYYuxpjKrLU3/odojMgz3Cn3bVer8dMsWDMFH8ekBDlSF9OeVDicYA5pmYO+nK5DLKQaekuwa1eXLB2g1vCRzY8m3gA0ZI3RyRuCEp/SK/qTsPQXDwMTdNJg+UzFCwJ79fVOKQnde/Kj7xTtQlzUqNQ19BcLeuOo1kTQCrxSFOWLnw9qI1pyqoZZjAuAMR39AJcjioW1u7wT3Y8PNRX6S7K6hdt3kXAPzCONIS/MibPQwyw3NvPAxJiPYZm+lM3m0oNecdUDE47HxYBHjse1ozsfQCBJMQBcHpvKXPx7Ka3ad5IBGYzZbV1spnYPDYE7pUQH9vg055EIBFIBByBJERHI8uJQCJw1AgkIR61+3PwiUAi4AgkIToaWU4EEoGjRiAJ8ajdn4NPBBIBRyAJ0dHIciKQCBw1AkmIR+3+HHwikAg4ApMhxDt+1F1vWvD9IWx7YLMEux180wIbHhzBgTLa7v8DNPZ47LSZfRqA0CerPRiuUPtS6u8xVY/CADWwsLeEls2u637ZPlTvD8Fx3gs2e6U6DRtLEK8Dhhr2n/TJqh5VYc+S1w8Ezz3fqm3uM2D5cQsZXutrOcX6oyDE09PT5XJ5dnam+aBZxC5a33bKXld2lfpdRG7kad8dfCPBWzcebzMjQoSCDuZxslsulzrDho3Ypbu8jdaPy8tLHTOjIYBqPSI/0wHMQ7PQr/jl8vJy+KBWV4IBOs9NfFqvUnjKLSndJZEwUu8iyIbTiLnrIo+nrPEGm5vm1QHTbDbdygMSYr0az+fzBzwgVk4q3RXm4dXVVSnFo1bpQHc+7IJpEDYCj/S6q8UGJUdkLp5rkPWQkoScYufhDhylp9SsnvkyowlCn6zOOHj16hU7yhkL+Pg5NBzHMpzah+7qpKPZrwiudJf4kXMcfFAM09lZlbVT/GQ2twr7vVJK/G/pLmp8XQkW0mZkwecRASNrQxR5S6Jo5OZ3lhk/sS1Y6Ngql/deQuOJ/jwgITIlCA6BqKBnqWH1ljt1tz5ixB2AiLy42WxGOoYumA/aXvru3btSCqGfB8QKKA7EdQ8OE6K7FVeuVqv1el2fUuETTOX6gFgdooVrlKmJF0p3hZm8WCxYP1hmnLI1UesAIyS8C2cT1icO4GDOu6wqQYyfm81G/FUbg56dhdJdwUKkfF5Q6UPwyrocbG420MLjs6ZuNumaQxEisaggUIx6WKt8n+chKjIUjorgcDaqTMoDYutzVZlp7kHFPQzIw7IO0GU59CNevHGY1QoYvCMerPv1SVu6S2bAVvXBtO53NeasM/3U32Db8uObsvqw6Fo8yAaO9l600oxcvxHEmO12K1ngpU1NytwaWXBsmyLNWdNsOd3KAxIiTzGg49NJS/R9EqI/aSoueQDRxPM5SS7Js3OY8AxqZyFEaukuSTkgIgg/GE1tNBmUbalm59+RNjdBqGW/+uorshtf3mSGcwFnf6mZxuJPmj5eEJYezxZFYW/evKn7/de//oVyFXCi9AS0Ven5oD+m6O4Af8kpIacLpjZ5pFmp7kp30fXOgp+Rg+yDEGIzYHbaP60GhyJExXRYCX0+sPhTEB9p5tfnX7osYTH+kblWiBJf8IkzotAnmJ/35ew57HLXENIiVyglPkzUYqpqnNlp4wXvMXQRXoOiGRAGZLUkDD8yYwZIhn+ggFycpCTlkRCOmx4DS1CCJR6KHmPewGnd65u8RmyoZVO2KUi4srz5iyDv18sAJeM1p+p4FluFGSc9OwNGzZo27wwYN/UJlA9IiPKfL+Nyv2qYGN7M3anMiE8cfEqU7hL6HiV9/vB+eZOlAJIxBCjG8B6KxA1L1EtYLZtdo81B0Pzsq+H9lMuGfxUZE988QoYEKsR3E4Q+2UCIIR8EQ0EBITYBVL9BpGmMtLn3gbp0l35iDCHkAFJJUAl/1ddEgCUeBnTh7qhlvV9ixiPQR63GzAWG5gWM2Ww2etmtu4wFF3vXDFnxRhvXTNkFsZlefLwYQ6Ci5GkUDkiINUDNsK6bTaUmJF9TMTvtfDwIiF+cvB6PbcdpSRLibfyuBX94Yb+N3pQ5JgSUiScbPiqf3yshPqqRpzGJQCKQCAQEkhADIPkzEUgEjheBJMTj9X2OPBFIBAICSYgBkPyZCCQCx4tAEuLx+j5HnggkAgGBJMQASP5MBBKB40VgMoR4x28Y64+NqfEvUfnu1L/I5ava4a9b6yBCm3/aWjc7RM14m/m+lw+Ga1n/cJePjRxAyXqz7XYLhnzSjKy3pJJmvn+RXmgGqv5tMArptP4g3AXDB/kcHgMIGINCF6eZfKfGVGJzCBgZGSoP4f1b6JRtDHZAw/LjLm/GO9B4creOghCb5yH6Hlvcxu4xNpz5VoTmJi1k+wq+Ga6vzX7rx9vMiBChUJ+H6Kd7ucFg5ZWMmp1n2jKhWQTOvi+4dJcrcc2I1GcaiqqkmYXTZWvN3i+71DklzGWJEwxgaDJVjZuyod/6YEcf7AOWNYQ8D3E2mx2QEOsV9fGch6j0gaRDseiBrkV+0V00C/veRkawq5UI2QfJAgkOx5l4ghPW7Z1b95jD4qC+/NRJQVlhKWVY1umS4TvlUVm6yw8ZdMzZiuvUg0itRLEEXGoAsBRE2avVaj6f+0BgSTT7XfiU7YZyh3O3Y+XMXsu6Zu9XKNUHSmJSX8HnkSNQR5G39O+9dwYMeIYt5MEkB4GACW2m/vOAhOjhxal2V1dXijNyExZeYkszx32vNVzHuCoc8bdil5/D/ghd6LmJJy/CV9N1tVopGSmlSJDzAYd7CXd9uoahAULpLhf04PN6DT+AExp0ynbbjGF+vF2fLM/RDrXmZOBrHWHAWUeMURiyumjJ8YEww1GoEJKL62O4IGKnac5D5G6NWMAWC4lYcmFiwyNHUNRhrJpmv1hIjAWXjfwp74QoQpapRI0K+yLEZsCEvqb+81CE6CkPr5M8GlS+z+O/NDGYkHiOg15kUp6HWJ+HCFbiBedErVWbzcZPWoZinFmurq7AlgNjSil1Asvd5XL5+vVrVlM/aAevyTZe2/l5iMuPb7sCmTpneYoKITJMX25ZEtbrtRbLpqzCTGst/UJVPgVAdWeBgfAAganIwlbU3LQAa/cJqotwimhf44nWH5AQyRGAxqNBQXmfhNi3TpIvKPrFmGQEPDvzpkkHoDKonYUQqaW7JOWAaNn3f09QG00GZR+q2fl3pM0aIzmaJu1OWSc7WQJW+jkwr0p3hfaQhcQ9wfTDZQOL8aiBlAoBbVX6Y2zoneiXWHoAAAxsSURBVLSUxwVxDbA460kbAdOUdXvUb0gOyA+85UCZ5cHfPzwIITYDZsDyKd46FCFqnaxTCRZ5pgEFxY1mPu+YwNS5o3SXbvkaTuO6UCukjQcccUalTzA/3sbZE1XNgmsIDzuuULI+TLSV7uJnH7PTwHsMXYTXoGgm4RqQJd0L7Bwoo2ZMGebNcHqgJ7XEWaChZgonjxOGTAHN1ASCdmKljQp4302t2zcHiCw6Q7+qZ0T85EUQgqGAAR7qQERjh4hKFXYGjJo1Dd4ZMKGvqf88ICHKf1p4td7y0OF5kDdzAlVmxDcxHkmluwS9R0mfM7xfzkNkefdHNozhNRaJG5aol7BaNrtGm4Pgj1SkIQyWl1Yu6xZKHMFmv302S9a1aRQyD5rj8ZNeHECa9QEYXswzEO+XSp4Bm7DwNYwHjGOFOMYQQgzNXalKhhDQc1JDIWYDS/3WRcZLbbNfOvIw5rzYpkJEUJjnIYLJ4QoHJMTa6BANdYNp1YTka1rGp7WPAQGRHST+GEw6chuSEG8TAMqYhhf22+hNmWNCQClnsuGj8vm9EuKjGnkakwgkAolAQCAJMQCSPxOBROB4EUhCPF7f58gTgUQgIJCEGADJn4lAInC8CCQhHq/vc+SJQCIQEEhCDIDkz0QgETheBJIQj9f3OfJEIBEICEyGEO/yUTff+ofdJux5YOsCLX17A/s02LkRQOz7iTZ2O/S13Hv9eJtrEJqy7Nzg60vfbUIlzXxvCZU0YwuK13CmkbupKctWHD7iwxh3HHsNwZ/dJt5FU5Z+XSEtUUgzxovTvQtvRsu9O/0uCjU0H2yftjpg+lpOsf4oCNEdw15XdqT6Fk7uspvV7yLiCneWfXfwzsZ7aTDeZkaECAVxlgjr7OxsuVyenp5q2mj9ACsOO/DTBxgIW3F9f5tk6V2NwRzZZr/a8XZ5eblarSBEneQoA3zd0p5fzhnxUx7opZZ1SxBxZFwWG6ikAETUNCHyuw9S1njzgNijOyBWq/disfA5rISolOLMpVRi0V1kMWGj+8jYdbUSIV9g6pJ6sDmXJKg+HGXnXn3mcL152W1ugrBTlg2/nC/g9FG6y3vxGlfuhKv2aHZxyn4XPq3JyJ8kmOfDhEgXyDZ5v3QXjVVoVuoWweYidTD43Wa5mXIKvbBH3ls6MjsDRv02Gd9NagaMN3gC5QNmiEQwQIt6lF+QHbCKegB5WiGUoS1Ncvyt2OVnn0tgHFIeTRKdavPu3btSCvNBUz0PiK0PxMWVwlnLBrTus5SHLxwt/7K6BELUZLu4uNAkDw71fomN0l3B46G7xWLhHOSPzIpDF0eWZ23O2lDUXVxcXF1d+TMvaxvj5cgGb0YvncmFnzctIA4IroGp5JWy3H0U7vLTQabSCyDps8YbPIHyoQgRAlJ8K1xgHL0tWq1W93keorylExnk2nDUpczjEFMReill4MDUMRFAGKlx6S6VAUQT1clCcewTUiJj/o60uQnCgKwYDarihLThQ15JW/yAWI3CCUgBw3LlR+Z4vz5pS3c5IJjkbBvwV3uOO0PcZemR5VY1ohWVA5+6ODrD8R9uPG3GFJYfT7rlAYJsA/HmMLk7prDTvGbAjNE8oTYHJESeU4CD+a/nwfV6ff+EqKX1+fPn6+46PT0l5fQ5SdDz7HzkB8QKECgbfOTcOjdpzs/SXcSDE6I/jskjYpzQr6d44YGR/3iA53dqo79OYaE7lyU4FRu8EHAOCgPxQ20ZXdDjHO1tdpadaunXjZGGJuA7lXuDnYQoX5Bs1k53bRMtH4oQYRnHxQkRNCmIjxS1vJ9C3GVLd+kWazgthwt01+n44eHFkwXijCj0OPMF39lzuEfXECaJK5QSHyZqMVU1O18JeY+hi/AaFM2A0Ccb9Lh/AznKyKYHLy8v/bxxJ0RX6DOz7lf6xS+kq9jPXQo+IirxbwgANYAE3V9YO3K8PiL+Icj/QwvqOg+IxSmPoXBAQhRl+DLO9xz+esWbEd8KpiDLaduluwTfGEJsdqGwDrkDLf2VEFkJayM5iNfU7kSbD6QemtfwjOyyfOShLnYSoqZx6BRZ19YEoR4vNa7TLcRxPNyBDM28X169Of61Mc1+wbl0F76QKleolk6I9Isx3qnL1i3dTWPGy+OtzIBP9RPbNpsNebffooyFeUAsmByucEBCrI1upj91s6nUDCQvUxlC2vmwCIjsoNeHNSZ7P+xnNzW+T4YQleoOL+z18LMmEXAElP8mGzomD16+1wzxwUebBiQCiUAiMIBAEuIAOHkrEUgEjguBJMTj8neONhFIBAYQSEIcACdvJQKJwHEhkIR4XP7O0SYCicAAAkmIA+DkrUQgETguBCZDiHf5ZIdPW/2IOv/ol6+IaekfZvM9Oc1Gxgja+Ax4pODdm423mU+p2dnWlOVD5fCxUfh2BFn/LFmVDkINPt9v6+to4e+VeMQr3Ri6djdhtr5uGdmv8A+yfmoDY6GN7zXgW3GaSaEsd/Pu7uh9aZBtgDygtg6YgcaTu3UUhOheYeteOIpKbbjL5i3fRtbcbODKm2XfKdFssPfK8TYzIkQo+N7bkecSagEQsTJqbR5/9eqV79trgg8OyFLglraLiN18PzL+8paMjsqR/frYkXVkqCzdxU8K2rkYtvMvl8tVd2mXNI0fvCD08jzEw36YTX7EdrT5fK5tZ9vtlsXTm/lHqqy9WlGVIa5WK5dl0XbBgfDyGVvPDZ9+SiUW3UUaEjYCD3Tkt1yt6sPQGIWSI8ZCOhPW7Z1b93xoAzYHQtGm2p2ybPeGm0p3aWjs3gnnUwXC8l4k6H87fT9sM6+hE1UREpCsWyVVTdk79otrsBZTqeEQkJcvXzohsjCwA9VFBso+QTy7rKPIW7qpOwNGvTcZ3w1rBow3eALlA2aIxChA66FGGQSrN0lZYCv3fdgGjwhU4u5veoXnLNgNunG+VrDmeYjyxfB5iFBe6S5g10QFZ9XXhCj2B3zEncjwWnggle+IEE3UcJair6CsKLXTm/02ZZfL5ZjzEAnjMBAdaHaXNz9+ngXgYz/rk9eovC9CZEQ6GkOniNbdTbrmUIToocyZzx4NKt//8V+kMLiNg1JkUp6H2Hf+o6a61h4WOZ+lnr6FSRgIsQafGlZKanglp645qIZzGBVsomAME/dp9a3pA6fTi/dby/p5cVAesjpNQw896IE+nKp8Crj4cJnXdryZJdtA0Luj8kYFoOuTUhfhFNG+xhOtPyAh+vOC0PFoUIzePyHWc4MHAZ9XBL3Pjb5ZPez7EKmlu2pAOKIm5FaaDJrYwx1xd6TNGiN5lvLuPlk1xjY1I8vTv1adn59zsCsAMlIeb7FTTLdarTgUa2BOlu4KamUzHpRmkYUHW3DBzn6bss5BMkbd6a+6OD8/X6/XDst2u33z5s1ms/FKMlbX0FdmAfC1x41xA/x0tT6FffUD4EukGTB92iZafyhC9FURaDzOeOylID7SzG+epsfLl9JdUiupnY/M2EB31HjAEWdU+lzy7NLZE1XNgmvw8/UEERQjWYcIbaW7+BmSL+opeI9us3rk7a1PMDKmPtmgh75cibNVmF19awk4SyHplevnxYhiAw96d1TSL4WAuTQP99uUxTbvFzvriHUkaRb8q5dIw9HLEu6hXncnq5qqdgaMzPNRY3B4B126q3mIJCKTLhyQEOU/LYxKQ/gwwl8JeTN3pzIjPpTxSMIrTBUXrP3R7IJ30k4QtPQ1nGyIZIqHOK8Z7peBiJUcFq/hnRqWhH9EUuPhfkk2vVOZF+Jbs0jGkITW46UmmC2dpbtUdhdLodfg9z7wSTD7tOFxWYLfmwOha1w8sl/eWQfwiUn6pab2yBhClJfDoqix85eh5XmIYHK4wgEJsTbaSa2+O7magaRpcmNJgx8EgYG07kHsyU6TEG8TA0o9hhf22+hNmWNCQHk3yeYxDf3xjvVeCfHxwpCWJQKJQCIwmyUhZhQkAolAInCNQBJihkIikAgkAtcIJCFmKCQCiUAicI1AEmKGQiKQCCQC1wgkIWYoJAKJQCJwjUASYoZCIpAIJALXCCQhZigkAolAInCNQBJihkIikAgkAtcIJCFmKCQCiUAicI1AEmKGQiKQCCQC1wgkIWYoJAKJQCJwjUASYoZCIpAIJALXCCQhZigkAolAInCNQBJihkIikAgkAtcIJCFmKCQCiUAicI1AEmKGQiKQCCQC1wgkIWYoJAKJQCJwjUASYoZCIpAIJALXCPwfgQ19hDMGPZYAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、调整学习率，样本数据拆分比率，观察训练结果；\n",
    "### 使用make_classification创建数据集\n",
    "(1)lr=0.01,text_size=0.2\n",
    "![alt text](image-1.png) \n",
    "\n",
    "(2)lr=0.05 ,text_size=0.2\n",
    "![alt text](image.png)\n",
    "\n",
    "(3)lr=0.10 ,text_size=0.2\n",
    "![alt text](image-2.png)\n",
    "\n",
    "(4)lr=0.01 ,text_size=0.3\n",
    "![alt text](image-3.png)\n",
    "\n",
    "(5)lr=0.01 ,text_size=0.5\n",
    "![alt text](image-4.png)\n",
    "\n",
    "(6)lr=0.01 ,text_size=0.6\n",
    "![alt text](image-5.png)\n",
    "\n",
    "### 使用irir数据集\n",
    "(1)lr=0.01,text_size=0.2\n",
    "![alt text](image-6.png)\n",
    "\n",
    "(2)lr=0.05 ,text_size=0.2\n",
    "![alt text](image-7.png)\n",
    "\n",
    "(3)lr=0.10 ,text_size=0.2\n",
    "![alt text](image-8.png)\n",
    "\n",
    "(4)lr=0.01 ,text_size=0.3\n",
    "![alt text](image-9.png)\n",
    "\n",
    "(5)lr=0.01 ,text_size=0.5\n",
    "![alt text](image-10.png)\n",
    "\n",
    "(6)lr=0.01 ,text_size=0.6\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、训练后模型参数保存到文件，在另一个代码中加载参数实现预测功能；\n",
    "图像演示如下：\n",
    "(1)将测试文件改为.py文件\n",
    "\n",
    "![alt text](image-11.png)\n",
    "\n",
    "(2)在test01中导入test00\n",
    "\n",
    "![alt text](image-12.png)\n",
    "\n",
    "(3)进行相关操作即可\n",
    "\n",
    "![alt text](image-13.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、总结逻辑回归运算及训练相关知识点\n",
    "### 为什么要学习逻辑回归？\n",
    "神经⽹络是⼈⼯智能深度学习的基础，也是⽬前主流⽹络模型应⽤最多的基础架构。通常学习神经⽹络最好的⼊⻔⽅法也是先学习逻辑回归，⽽后进⼀步认识神经元和整 体的⽹络训练。\n",
    "### 逻辑回归是什么？流程是怎样的？需要注意什么呢？\n",
    "(1)逻辑回归就是将线性回归模型映射为概率的模型,把y实数空间的输出[负无穷~正无穷]映射到取值为[0，1]的区间, 从⽽把模型的输出值转 换为概率值,本次学习的转换函数为sigmoid\n",
    "(2)流程如下：\n",
    "   1. 数据准备，参数初始化\n",
    "   可以采用sklearn.database\n",
    "   2. 前向计算 \n",
    "      - **前向运算**：从输入数据到预测概率的计算过程，包括线性变换和激活函数。\n",
    "      - **作用**：生成模型预测值，为损失计算和反向传播提供基础。\n",
    "      - **逻辑回归**：通过 Sigmoid 函数将线性输出映射为概率值，用于二分类任务\n",
    "   3. 计算损失 \n",
    "   使用损失函数计算，本次直接给出，使用的是伯努利分布，用的是其对数形式，方便减少运算量\n",
    "   4. 计算梯度\n",
    "   目的是最小化损失函数，找到最优参数\n",
    "   5. 更新参数\n",
    "   通过学习率和梯度来不断更新参数，其中学习率是经验所得，用于控制参数更新的步长，本次练习中，就是theta不断通过变化，以求得最优参数\n",
    "\n",
    "(3)练习中需要注意的点\n",
    "\n",
    "   1、导入数据时要清楚数据的大小形状，以便后面调用\n",
    "\n",
    "   2、定义函数时要把其中的参数顺序与引用时的顺序确定好，不然就会出错\n",
    "\n",
    "   3、学习率不能过大，否则会溢出，报错时，可以使用try except 来解决\n",
    "\n",
    "   4、ipynb不能导入其他文件中引用，应该改成.py形式才能进行引进用\n",
    "\n",
    "   5、一些概念和区分\n",
    "\n",
    "      (1)最⼤似然估计和损失函数\n",
    "\n",
    "         最大似然估计是一种通过最大化似然函数来估计最优模型参数的方法。\n",
    "\n",
    "         损失函数衡量模型预测值与真实值之间的差异\n",
    "\n",
    "         梯度下降法的作⽤就是：最⼩化⼀个损失函数\n",
    "\n",
    "         似然函数：衡量在给定参数下观测数据出现的可能性。\n",
    "\n",
    "         对数似然函数：简化计算，常用于实际优化。\n",
    "      (2)概率和似然的区别\n",
    "\n",
    "         概率（Probably），是在已知⼀些概率分布参数的情况下，预测观测值的结果;  **知道参数，在不同x条件下预测y**\n",
    "\n",
    "         似然（Likelihood），则是⽤于在已知某些观测值所得到的结果时，对观测结果所属的 概率分布参数进⾏估计。**知到x，在不同参数条件下预测y**\n",
    "         \n",
    "      (3)梯度与学习率的关系\n",
    "\n",
    "         梯度：指示损失函数的变化方向和速率。\n",
    "\n",
    "         学习率：一个超参数,用于控制参数更新的步长。\n",
    "\n",
    "      [^超参数（Hyperparameters）]: 是指那些在训练过程开始之前就需要**⼿动设置的参数**，它们不能通过模型从数据中学习得 到，⽽是需要通过⼈为的经验、实验或者特定的搜索⽅法来进 ⾏选择和调整。\n",
    "\n",
    "      关系：学习率决定梯度对参数更新的影响程度，合适的学习率能平衡收敛速度和稳定性。\n",
    "\n",
    "### 一些听课过程中和预习时的疑问的解答\n",
    "   1.线性回归的y值是怎么映射到【0，1】之间的？\n",
    "\n",
    "   比如说是sigmoid激活函数来进行逻辑回归，是通过sigmoid计算公式对线性回归中同一组数据的x进行运算后的概率值对应原本数据中的由x进行线性回归运算得到的y，是这样的么？\n",
    "   **不是，是线性运算得到的y是sigmoid函数中的自变量，每一个y对应一个点**\n",
    "\n",
    "   2.该怎么理解iris数据集中的x和y呢？所得出的0，1等是什么呢？\n",
    "   \n",
    "   x是x（n_sample,n_feature），shape是（150，4）,y(n_sample)，shape是（150）\n",
    "\n",
    "   3.定义损失函数时的return返回的数值放在哪呢？具体过程是什么样的？为什么要防止y-hat的值为0√\n",
    "\n",
    "   log函数自变量不能为0\n",
    "\n",
    "   4.为什么不能使用全部训练样本训练模型呢？\n",
    "\n",
    "   答：会造成过拟合问题，也就是当模型训练好了，使用新样本效果不好（泛化能力插）\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
