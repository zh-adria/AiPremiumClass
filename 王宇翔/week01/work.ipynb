mport numpy as np
import torch
#%%
a1 = np.array([[(1, 2), (4, 5), (7, 8)], [(1, 2), (4, 5), (7, 8)]])
a1
#%%
# a2 = np.array([[1, 2], [4, 5]])
# b2 = np.array([[1, 3], [6, 5]])
a2 = np.array([(1, 2), (4, 5)])
b2 = np.array([[1, 3], [6, 5]])
b2 = b2.reshape(1,2, 2)
print(a2)
print(b2)
print(a2*b2)
print(a2.dot(b2))
a3 = np.array([1,2,3,4])
b3 = np.array([1,2,3,4])
print(a3.dot(b3))
print (a2.shape)
print (a3.shape)
a4 = torch.from_numpy(a3)
print(a3)
print(a4)
# 三维点积的条件是第一个的倒数第一维数和第二个倒数第二维相同
#%% md
pytorch
#%% md
直接用数据创建
#%%
data = [[1, 2],[3, 4]]
x_data = torch.tensor(data)
x_data
#%% md
用numpy数组
#%%

np_array = np.array(data)
x_np = torch.from_numpy(np_array)
x_np
#%% md
从另一个张量，只保留矩阵形状和数据类型，若要覆盖原数据类型需要明确声明
#%%
x_ones = torch.ones_like(x_data) # 保留of x_data的属性
print(f"Ones Tensor: \n {x_ones} \n")  
x_rand = torch.rand_like(x_data, dtype=torch.float) # 覆盖 x_data的数据类型
print(f"Random Tensor: \n {x_rand} \n")
#%% md
使用随机值或常量值
#%%
shape = (2,3,)
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)
print(f"Random Tensor: \n {rand_tensor} \n")
print(f"Ones Tensor: \n {ones_tensor} \n")
print(f"Zeros Tensor: \n {zeros_tensor}")
#%% md
其它⼀些创建⽅法
#%%
# 基于现有tensor构建，但使⽤新值填充
m = torch.ones(5,3, dtype=torch.double)
n = torch.rand_like(m, dtype=torch.float)
# 获取tensor的⼤⼩
print(m.size()) # torch.Size([5,3])
print(n.size()) # torch.Size([5,3])
# 均匀分布
print(torch.rand(5,3))
# 标准正态分布
print(torch.randn(5,3))
# 离散正态分布
print(torch.normal(mean=.0,std=1.0,size=(5,3)))
# 线性间隔向量(返回⼀个1维张量，包含在区间start和end上均匀间隔的steps个点)
torch.linspace(start=1,end=10,steps=20)
#%% md
张量的属性
#%%

#%%
tensor = torch.rand(3,4)
print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
print(f"Device tensor is stored on: {tensor.device}")
print(tensor)
agg = tensor.sum()
print(agg)
agg_item = agg.item()
print(agg_item, type(agg_item))
#%% md
张量的索引和切⽚：
#%%
tensor = torch.eye(4, 4)
print('First row: ', tensor[0])
print('First column: ', tensor[:, 0])
print('Last column:', tensor[..., -1])
tensor[:,1] = 0
print(tensor)
t1 = torch.cat([tensor, tensor, tensor], dim=1)
print(t1)
#%%

#%% md

#%%
# np_array = np.array([[1,2,3],[4,5,6],[7,8,9]])
# tensor = torch.from_numpy(np_array)
tensor = torch.rand(3,3)
# 计算两个张量之间矩阵乘法的⼏种⽅式。 y1, y2, y3 最后的值是⼀样的 dot
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)
y3 = torch.rand_like(tensor)
torch.matmul(tensor, tensor.T, out=y3)
# 计算张量逐元素相乘的⼏种⽅法。 z1, z2, z3 最后的值是⼀样的。
z1 = tensor * tensor
z2 = tensor.mul(tensor)
z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)
#%% md
默认在cpu上创建张量
#%% md

#%%
import torch
tensor =torch.rand(3,4)
if torch.cuda.is_available():
    device = torch.device("cuda")
print(tensor.device)

#%%

if torch.cuda.is_available():
    device = torch.device("cuda")
    tensor =tensor.to(device)
print(tensor.device)
#%%
tensor = torch.arange(1,10,dtype = torch.float32).reshape(3,3)
print(tensor)
z1 = tensor*tensor
print(z1)
agg =tensor.sum()
print(agg)
print(agg.item())
np_array = tensor.numpy()
print(np_array)
tensor+=5
print(tensor)
#%%
a = [1,2,3]
b = np.array(a)
b
#%%
a = [1.11,2,3]
b = np.array(a,float)
b
#%%
a = np.zeros((3,4),dtype= float)
a
#%%
a = np.ones((3, 3),dtype=int)
print(a)
#%% md
等差数列
#%%
a = np.arange(1, 5.1, 0.1)
a
#%% md
生成单位阵
#%%
a = np.eye(4)
a
#%% md
指定长度的【0-1】
#%%
a = np.random.random(5)
a
#%% md
标准正态分布
#%%
import matplotlib.pyplot as plt

# 生成正态分布数据
mu, sigma = 0, 1
a = np.random.normal(mu, sigma,1000)
print(a)
# 创建散点图
plt.figure(figsize=(8, 5))
plt.scatter(range(len(a)), a, c='blue', edgecolor='black', alpha=0.7)

# 添加标题和标签
plt.title('Normal Distribution Scatter Plot (μ=0, σ=1)')
plt.xlabel('Data Point Index')
plt.ylabel('Value')
plt.grid(True, linestyle='--', alpha=0.5)

# 显示图形
plt.show()
#%%
import scipy.stats as stats # 统计直方图频数
counts, bin_edges = np.histogram(a, bins=5, density=True)
bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

# 核密度估计（KDE）
kde = stats.gaussian_kde(a)
x_range = np.linspace(min(a)-1, max(a)+1, 100)

# 绘图
plt.figure(figsize=(8, 5))

# 绘制直方图频数曲线
plt.plot(bin_centers, counts, 'r--', label='Histogram Frequency')

# 绘制KDE曲线
plt.plot(x_range, kde(x_range), 'b-', label='KDE Curve')

# 添加标注和样式
plt.title('Distribution Curve of Data Points')
plt.xlabel('Value')
plt.ylabel('Density/Frequency')
plt.legend()
plt.grid(ls='--', alpha=0.5)
plt.show()
#%%

#%% md
Numpy 数组访问（切片操作）

#%%
a = np.array([[1,2,3],[4,5,6],[7,8,9]])
print(a)
#%%
a[0]

#%%

print(a[1:])
#%%
print(a[:,1])
#%%
print(a[:,0])
#%%
print(a[:,-1])
#%%
print(a[-1,-1])
#%% md
数组遍历
#%%
for i in a:
    print(i)
    for j in i:
     print(j)
#%%
for i ,j,k in a:
    print(i,j,k)
    print(i*j*k)
#%%

#%% md
Numpy数组常用属性
#%%
a = np.array([(1.1,2,3), (4,5,6), (7,8,9)])
print("维度（秩）ndim ：",a.ndim)
print("数组的大小shape：",a.shape)
print("数组的总个数size：",a.size)
print("数组的元素类型dtype：",a.dtype)
#%%

#%% md
Numpy数组的基本操作
#%%
a = np.array([[1.1,2,3],[4,5,6],[7,8,9]])
print(3 in a)
print(1 in a)
#%%
a = np.zeros([2,3,5])
a
#%% md
数组重排列
#%%
b = a.reshape(2,15)

b#只看前三个维度
#%% md
只看前三个维度
#%%
b.T
c = a.transpose()
print(a.shape)
print(c.shape)
#%% md
多维转一维
#%%
a.flatten()
#%%

#%% md
增加维度newaxis
#%% md
会直接影响原矩阵
#%%
print(a.shape)
a = a[:,np.newaxis]
print(a.shape)
#%% md
Numpy数组的数学操作
#%%
# a2 = np.array([[1, 2], [4, 5]])
# b2 = np.array([[1, 3], [6, 5]])
a2 = np.array([(1, 2), (4, 5)])
b2 = np.array([[1, 3], [6, 5]])
b2 = b2.reshape(1, 2, 2)
print(a2)
print(a2.sum())
print(b2)
print(a2 + b2)
print(a2 * b2)
print(a2 / b2)
print(a2.dot(b2))
print(np.dot(a2,b2))
print(a2@b2)
a3 = np.array([1, 2, 3, 4])
b3 = np.array([1, 2, 3, 4])
print(a3.dot(b3))
print(a3.sum())
print(b3.prod())
print(a2.shape)
print(a3.shape)
a4 = torch.from_numpy(a3)
print(a3)
print(a4)
# 三维点积的条件是第一个的倒数第一维数和第二个倒数第二维相同

#%% md
平均数，方差，标准差，最大值，最小值
#%%
a = np.array([3,3,1])
print("mean平均数:",a.mean())
print("var方差:", a.var())
print("std标准差:", a.std())
print("max最大值:", a.max())
print("min最小值:", a.min())
#%% md
最⼤与最⼩值对应的索引值：argmax,argmin:
取元素值上限，下限，四舍五⼊：ceil, floor, rint
#%%
a = np.array([1.2, 3.8, 4.9,7.4,1])
print("argmax最大值索引:", a.argmax())
print("argmin最小值索引:", a.argmin())
print("ceil上限:", np.ceil(a))
print("floor下限:", np.floor(a))
print("rint四舍五入:", np.rint(a))
a.sort()
print("排序：",a)
#%%
m1 = np.array([[1, 2], [3, 4]] ,dtype=np.float32)
m2 = np.array([[5, 6], [7, 8]] , dtype=np.float32)
# 创建⼀个全零矩阵，⽤于存储⼿动推演的结果
# 结果矩阵的⾏数等于 matrix1 的⾏数，列数等于 matrix2 的列数
manual_result = np.zeros((m1.shape[0], m2.shape[1]), dtype=np.float32)
print(m1@ m2)
print(m1.shape[0])
print(m2.shape[1])
print(m1.shape[1])
# 外层循环：遍历 matrix1 的每⼀⾏
# i 表⽰结果矩阵的⾏索引
for i in range(m1.shape[0]):
 # 中层循环：遍历 matrix2 的每⼀列
 # j 表⽰结果矩阵的列索引
 for j in range(m2.shape[1]):
  # 初始化当前位置的结果为 0
  manual_result[i, j] = 0
 # 内层循环：计算 matrix1 的第 i ⾏与 matrix2 的第 j 列对应元素的乘积之和
 # k 表⽰参与乘法运算的元素索引
  for k in range(m1.shape[1]):
 # 打印当前正在计算的元素
   print(f"{m1[i, k]} * {m2[k, j]} = {m1[i, k] * m2[k, j]}")
 # 将 matrix1 的第 i ⾏第 k 列元素与 matrix2 的第 k ⾏第 j 列元素相乘，并累
   manual_result[i, j] += m1[i, k] * m2[k, j]
 # 打印当前位置计算完成后的结果
  print(f"结果矩阵[{i+1},{j+1}]:{manual_result[i, j]}\n")
print("⼿动推演结果:")
print(manual_result)
#%% md
NumPy ⼴播机制
#%%

#%%
a = np.array([(1,2), (2,2), (3,3), (4,4)]) # shape(4,2)
b = np.array([-1,3]) # shape(2)-> shape(1,2) -> shape(4,2) [-1,1],[-1,1],[-1,1],[-1,1]
a + b
#%%

