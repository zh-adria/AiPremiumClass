{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from  torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import KMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.2M/18.2M [00:04<00:00, 4.18MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 754kB/s]\n",
      "100%|██████████| 3.04M/3.04M [00:00<00:00, 4.62MB/s]\n",
      "100%|██████████| 5.12k/5.12k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = KMNIST(root=\"./KMNIST_date\", train=True,  download=True, transform=ToTensor())\n",
    "test_dataset = KMNIST(root=\"./KMNIST_date\", train=False,  download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset KMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./KMNIST_date\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loader = DataLoader(train_dataset,batch_size=bs, shuffle=True)\n",
    "test_dataset_loader = DataLoader(test_dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(256, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Linear(28*28, 256),\\\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.Linear(256, 128),\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.Linear(128, 10),\n",
    "#     nn.LogSoftmax(dim=1)    \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (3): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.4880958795547485\n",
      "Epoch 2/100, Loss: 1.2073620557785034\n",
      "Epoch 3/100, Loss: 1.209765076637268\n",
      "Epoch 4/100, Loss: 1.364089012145996\n",
      "Epoch 5/100, Loss: 1.314610242843628\n",
      "Epoch 6/100, Loss: 1.1464968919754028\n",
      "Epoch 7/100, Loss: 1.1569314002990723\n",
      "Epoch 8/100, Loss: 1.1701782941818237\n",
      "Epoch 9/100, Loss: 1.0125271081924438\n",
      "Epoch 10/100, Loss: 1.0552480220794678\n",
      "Epoch 11/100, Loss: 1.117464303970337\n",
      "Epoch 12/100, Loss: 1.0483914613723755\n",
      "Epoch 13/100, Loss: 1.2671620845794678\n",
      "Epoch 14/100, Loss: 1.0069644451141357\n",
      "Epoch 15/100, Loss: 0.8916693925857544\n",
      "Epoch 16/100, Loss: 0.7249325513839722\n",
      "Epoch 17/100, Loss: 0.9704926013946533\n",
      "Epoch 18/100, Loss: 1.0199651718139648\n",
      "Epoch 19/100, Loss: 0.7837730050086975\n",
      "Epoch 20/100, Loss: 1.2087364196777344\n",
      "Epoch 21/100, Loss: 0.9947627782821655\n",
      "Epoch 22/100, Loss: 0.6963659524917603\n",
      "Epoch 23/100, Loss: 0.8235871195793152\n",
      "Epoch 24/100, Loss: 0.7143955230712891\n",
      "Epoch 25/100, Loss: 0.9724471569061279\n",
      "Epoch 26/100, Loss: 0.8540990352630615\n",
      "Epoch 27/100, Loss: 0.48388898372650146\n",
      "Epoch 28/100, Loss: 0.9136603474617004\n",
      "Epoch 29/100, Loss: 1.0733389854431152\n",
      "Epoch 30/100, Loss: 0.9228320717811584\n",
      "Epoch 31/100, Loss: 1.0265238285064697\n",
      "Epoch 32/100, Loss: 0.8817539215087891\n",
      "Epoch 33/100, Loss: 0.5769065618515015\n",
      "Epoch 34/100, Loss: 0.8825881481170654\n",
      "Epoch 35/100, Loss: 1.0703125\n",
      "Epoch 36/100, Loss: 1.0498099327087402\n",
      "Epoch 37/100, Loss: 0.7088522911071777\n",
      "Epoch 38/100, Loss: 0.9187909960746765\n",
      "Epoch 39/100, Loss: 0.5796135067939758\n",
      "Epoch 40/100, Loss: 1.0199068784713745\n",
      "Epoch 41/100, Loss: 0.8768032193183899\n",
      "Epoch 42/100, Loss: 0.6843643188476562\n",
      "Epoch 43/100, Loss: 0.9212971329689026\n",
      "Epoch 44/100, Loss: 1.1223822832107544\n",
      "Epoch 45/100, Loss: 0.8400707244873047\n",
      "Epoch 46/100, Loss: 0.9999591112136841\n",
      "Epoch 47/100, Loss: 0.5617600679397583\n",
      "Epoch 48/100, Loss: 0.678960919380188\n",
      "Epoch 49/100, Loss: 0.5907944440841675\n",
      "Epoch 50/100, Loss: 1.0128161907196045\n",
      "Epoch 51/100, Loss: 0.4669386148452759\n",
      "Epoch 52/100, Loss: 0.5729056000709534\n",
      "Epoch 53/100, Loss: 0.5276334285736084\n",
      "Epoch 54/100, Loss: 0.6813231706619263\n",
      "Epoch 55/100, Loss: 0.8614234924316406\n",
      "Epoch 56/100, Loss: 1.0458340644836426\n",
      "Epoch 57/100, Loss: 0.8334009647369385\n",
      "Epoch 58/100, Loss: 0.6425929069519043\n",
      "Epoch 59/100, Loss: 0.6926200985908508\n",
      "Epoch 60/100, Loss: 0.6429229378700256\n",
      "Epoch 61/100, Loss: 0.7441548705101013\n",
      "Epoch 62/100, Loss: 0.6533246040344238\n",
      "Epoch 63/100, Loss: 0.6601847410202026\n",
      "Epoch 64/100, Loss: 0.8631665110588074\n",
      "Epoch 65/100, Loss: 0.5527603030204773\n",
      "Epoch 66/100, Loss: 0.689147412776947\n",
      "Epoch 67/100, Loss: 0.8868798017501831\n",
      "Epoch 68/100, Loss: 0.7538779377937317\n",
      "Epoch 69/100, Loss: 0.514614999294281\n",
      "Epoch 70/100, Loss: 0.7682473659515381\n",
      "Epoch 71/100, Loss: 0.6518115997314453\n",
      "Epoch 72/100, Loss: 0.5255564451217651\n",
      "Epoch 73/100, Loss: 0.7806457877159119\n",
      "Epoch 74/100, Loss: 0.6401674151420593\n",
      "Epoch 75/100, Loss: 0.9566583037376404\n",
      "Epoch 76/100, Loss: 0.3526863753795624\n",
      "Epoch 77/100, Loss: 0.6939734816551208\n",
      "Epoch 78/100, Loss: 0.47132158279418945\n",
      "Epoch 79/100, Loss: 0.7976917624473572\n",
      "Epoch 80/100, Loss: 0.652633786201477\n",
      "Epoch 81/100, Loss: 0.5577952861785889\n",
      "Epoch 82/100, Loss: 0.7427269816398621\n",
      "Epoch 83/100, Loss: 0.5975870490074158\n",
      "Epoch 84/100, Loss: 0.5187478065490723\n",
      "Epoch 85/100, Loss: 0.6384548544883728\n",
      "Epoch 86/100, Loss: 0.46721047163009644\n",
      "Epoch 87/100, Loss: 0.7504764795303345\n",
      "Epoch 88/100, Loss: 0.9713563919067383\n",
      "Epoch 89/100, Loss: 0.8557780385017395\n",
      "Epoch 90/100, Loss: 0.7173477411270142\n",
      "Epoch 91/100, Loss: 0.5082054734230042\n",
      "Epoch 92/100, Loss: 0.5404146909713745\n",
      "Epoch 93/100, Loss: 0.5702131390571594\n",
      "Epoch 94/100, Loss: 0.6345129013061523\n",
      "Epoch 95/100, Loss: 0.5790415406227112\n",
      "Epoch 96/100, Loss: 0.7239354848861694\n",
      "Epoch 97/100, Loss: 0.7116732001304626\n",
      "Epoch 98/100, Loss: 0.6850400567054749\n",
      "Epoch 99/100, Loss: 0.7494811415672302\n",
      "Epoch 100/100, Loss: 0.6153379082679749\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(epochs): \n",
    "    for data, target in train_dataset_loader:\n",
    "        # 用GPU训练\n",
    "        data = data.view(data.shape[0], -1).to(device)\n",
    "        target = target.to(device)\n",
    "        # 前向传播\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss = loss_fn(output, target)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.75\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataset_loader:\n",
    "        data = data.view(data.shape[0], -1).to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 6, 3, 2, 8, 5, 8, 7, 3, 2, 5, 2, 7, 1, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6, 3, 5, 8, 5, 8, 7, 3, 2, 5, 2, 7, 1, 4, 2], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted == target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
