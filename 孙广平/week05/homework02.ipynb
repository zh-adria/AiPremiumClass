{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fasttext训练《剑来》文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文档预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "with open('./data/jianlai.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read()\n",
    "\n",
    "\n",
    "with open('./data/jl_sprase_c.txt', 'w', encoding='utf-8') as f:\n",
    "    for line in lines.split('\\n'):\n",
    "        seg_list = jieba.cut(line, cut_all=False)\n",
    "        out = ' '.join(seg_list)\n",
    "        f.write(out + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_unsupervised('./data/jl_sprase_c.txt', model='skipgram', epoch = 25, lr = 0.1, dim = 100, ws = 5, minCount = 1, minn = 2, maxn = 6, neg = 5, thread = 4, t = 1e-4, lrUpdateRate = 100)\n",
    "\n",
    "model.save_model(\"jl_lw.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.763984739780426, '瀺'),\n",
       " (0.6732342839241028, '齐'),\n",
       " (0.6533849239349365, '茅小冬'),\n",
       " (0.6208360195159912, '周密'),\n",
       " (0.6111604571342468, '春字'),\n",
       " (0.594889223575592, '马瞻'),\n",
       " (0.5906897187232971, '赵繇'),\n",
       " (0.5896353125572205, '圣人'),\n",
       " (0.588931143283844, '老秀才'),\n",
       " (0.5858778953552246, '老头子')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = fasttext.load_model(\"./model/jl.bin\")\n",
    "\n",
    "model =  fasttext.load_model(\"./model/jl.bin\")\n",
    "\n",
    "model.get_nearest_neighbors('齐静春', k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算词汇向量相关度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext import FastText\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FastText.load_model('./model/jl_lw.bin')\n",
    "\n",
    "vocab_size = len(model.words)\n",
    "embedding_dim = model.get_dimension()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for i,word in enumerate(model.words):\n",
    "    embedding_vector = model.get_word_vector(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查词汇是否在词典中\n",
    "\n",
    "# word = '骊珠'\n",
    "# word = '齐静春'\n",
    "word = '平安'\n",
    "word_id = model.get_word_id(word)\n",
    "word_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41191810369491577\n"
     ]
    }
   ],
   "source": [
    "# 计算词汇相关度\n",
    "\n",
    "def cosine_similarity(embedding, word1, word2):\n",
    "    embed1 = embedding(torch.LongTensor([word1]))\n",
    "    embed2 = embedding(torch.LongTensor([word2]))\n",
    "    return nn.functional.cosine_similarity(embed1, embed2).item()\n",
    "\n",
    "word1 = model.get_word_id('齐静春')\n",
    "word2 = model.get_word_id('平安')\n",
    "\n",
    "print(cosine_similarity(embedding, word1, word2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard词向量可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "meta = []\n",
    "while len(meta) < 100:\n",
    "    i = len(meta)\n",
    "    meta += [model.words[i]]\n",
    "\n",
    "meta = meta[:100]   \n",
    "writer.add_embedding((embedding_matrix[:100]), metadata=meta)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
