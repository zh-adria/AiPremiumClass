{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fasttext训练cooking.stackexchange.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised(input=\"./data/cooking.stackexchange.txt\", epoch=25, dim = 200)\n",
    "\n",
    "model.save_model(\"./model/cs.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__baking',), array([0.6734696]))\n",
      "(('__label__equipment',), array([0.70369226]))\n",
      "(('__label__eggs',), array([0.57913929]))\n"
     ]
    }
   ],
   "source": [
    "# 文本分类\n",
    "model = fasttext.load_model(\"./model/cs.bin\")\n",
    "print(model.predict(\"Which baking dish is best to bake a banana bread ?\"))\n",
    "print(model.predict(\"Why not put knives in the dishwasher?\"))\n",
    "print(model.predict(\"What is the difference between white and brown eggs?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>DR BEN CARSON TARGETED BY THE IRS: “I never ha...</td>\n",
       "      <td>DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sports Bar Owner Bans NFL Games…Will Show Only...</td>\n",
       "      <td>The owner of the Ringling Bar, located south o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Latest Pipeline Leak Underscores Dangers Of Da...</td>\n",
       "      <td>FILE – In this Sept. 15, 2005 file photo, the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "5           5  About Time! Christian Group Sues Amazon and SP...   \n",
       "6           6  DR BEN CARSON TARGETED BY THE IRS: “I never ha...   \n",
       "7           7  HOUSE INTEL CHAIR On Trump-Russia Fake Story: ...   \n",
       "8           8  Sports Bar Owner Bans NFL Games…Will Show Only...   \n",
       "9           9  Latest Pipeline Leak Underscores Dangers Of Da...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "5  All we can say on this one is it s about time ...      1  \n",
       "6  DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...      1  \n",
       "7                                                         1  \n",
       "8  The owner of the Ringling Bar, located south o...      1  \n",
       "9  FILE – In this Sept. 15, 2005 file photo, the ...      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取csv文件\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"./data/WELFake_Dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "title         558\n",
       "text           39\n",
       "label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将title和text合并\n",
    "df['title_text'] = df['title'] + ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    37106\n",
      "0    35028\n",
      "Name: count, dtype: int64\n",
      "(72134, 5)\n"
     ]
    }
   ],
   "source": [
    "# 统计每个类别的数量\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# 总数据量\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删掉title_text为空的行\n",
    "df = df.dropna(subset=['title_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    36509\n",
      "0    35028\n",
      "Name: count, dtype: int64\n",
      "(71537, 5)\n"
     ]
    }
   ],
   "source": [
    "# 统计每个类别的数量\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# 总数据量\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换类别,1和0标签互换\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sgp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sgp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Pandas Apply: 100%|██████████| 71537/71537 [03:04<00:00, 388.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对title_text进行预处理\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pattern_digits = re.compile(r'\\d+')\n",
    "\n",
    "def clean_text(text):\n",
    "    # 去除英文标点符号和特殊字符\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # 去除数字\n",
    "    text = re.sub(pattern_digits, '', text)\n",
    "    # 转换为小写\n",
    "    text = text.lower()\n",
    "    # 去除两端空白\n",
    "    text = text.strip()\n",
    "    # 分词\n",
    "    tokens = word_tokenize(text)\n",
    "    # 去除停用词\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # 词形还原\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['title_text'] = df['title_text'].swifter.apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sgp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sgp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Pandas Apply: 100%|██████████| 71537/71537 [03:19<00:00, 358.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对title_text进行预处理\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import swifter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import unicodedata\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set()\n",
    "with open('./data/en_stopwords.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        stop_words.add(line.strip())\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pattern_digits = re.compile(r'\\d+')\n",
    "\n",
    "def remove_unicode_punctuation(text):\n",
    "    return ''.join(ch for ch in text if not unicodedata.category(ch).startswith('P'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # 去除英文标点符号和特殊字符\n",
    "    text = remove_unicode_punctuation(text)\n",
    "    # 去除数字\n",
    "    text = re.sub(pattern_digits, '', text)\n",
    "    # 转换为小写\n",
    "    text = text.lower()\n",
    "    # 去除两端空白\n",
    "    text = text.strip()\n",
    "    # 分词\n",
    "    tokens = word_tokenize(text)\n",
    "    # 去除停用词\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # 词形还原\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['title_text'] = df['title_text'].swifter.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存处理后的数据\n",
    "df.to_csv(\"./data/WELFake_Dataset_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>0</td>\n",
       "      <td>law enforcement alert threat cop white blackli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>0</td>\n",
       "      <td>unbelievable obama attorney charlotte rioter p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>1</td>\n",
       "      <td>bobby jindal raised hindu story christian conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>0</td>\n",
       "      <td>satan russia unvelis image terrifying supernuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>0</td>\n",
       "      <td>time christian sue amazon splc designation hat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "2           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "3           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "4           5  About Time! Christian Group Sues Amazon and SP...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  No comment is expected from Barack Obama Membe...      0   \n",
       "1   Now, most of the demonstrators gathered last ...      0   \n",
       "2  A dozen politically active pastors came here f...      1   \n",
       "3  The RS-28 Sarmat missile, dubbed Satan 2, will...      0   \n",
       "4  All we can say on this one is it s about time ...      0   \n",
       "\n",
       "                                          title_text  \n",
       "0  law enforcement alert threat cop white blackli...  \n",
       "1  unbelievable obama attorney charlotte rioter p...  \n",
       "2  bobby jindal raised hindu story christian conv...  \n",
       "3  satan russia unvelis image terrifying supernuk...  \n",
       "4  time christian sue amazon splc designation hat...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/WELFake_Dataset_clean.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fasttext词向量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存fasttext格式的数据\n",
    "with open(\"./data/WELFake_Dataset_clean_fasttext.txt\", \"w\") as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"__label__{row['label']} {row['title_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = fasttext.train_supervised(input=\"./data/WELFake_Dataset_clean_fasttext.txt\", epoch=50, dim = 100, lr = 0.3, loss = 'hs',minCount = 2, wordNgrams = 2)\n",
    "\n",
    "model.save_model(\"./model/wel.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"./model/wel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__0',), array([0.99999928]))\n"
     ]
    }
   ],
   "source": [
    "# 预测新闻文本\n",
    "with open(\"./data/test.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "text = clean_text(text)\n",
    "print(model.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IFD 词向量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(\"./data/WELFake_Dataset_clean.csv\")\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['title_text'], df['label'], test_size=0.3)\n",
    "\n",
    "# tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416643369676638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/lr.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 逻辑回归\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(clf, \"./model/lr.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "clf = joblib.load(\"./model/lr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "\n",
    "with open(\"./data/test.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "text = clean_text(text)\n",
    "text = vectorizer.transform([text])\n",
    "print(clf.predict(text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
