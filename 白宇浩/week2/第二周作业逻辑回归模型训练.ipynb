{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 基础环境\n",
    "from sklearn.datasets import load_iris #数据集选用鸢尾花模型\n",
    "from sklearn.model_selection import train_test_split  #数据拆分\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 生成数据集\n",
    "X,y = load_iris(return_X_y = True)\n",
    "X[:100] #取前一百数据\n",
    "y[:100] #取前一百标签\n",
    "#数据拆分，选取70%进行训练\n",
    "X_train,X_test,y_train,y_test = train_test_split(X[:100],y[:100],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 参数创建\n",
    "# 权重参数\n",
    "theta = np.random.randn(1,4)\n",
    "bias = 0 #截距 \n",
    "# 超参数\n",
    "lr = 0.01  #学习率0.1\n",
    "epochs = 5000 #训练次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 计算函数定义\n",
    "def forward(x,theta,bias):\n",
    "    #线性运算\n",
    "    z = np.dot(theta,x.T) + bias #shape (97,4)\n",
    "    #sigmod\n",
    "    y_hat = 1 / (1 + np.exp(-z)) #shape (97,4)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 损失函数定义\n",
    "def loss(y,y_hat):\n",
    "    e = 1e-8\n",
    "    return - y * np.log(y_hat + e) - (1 - y) * np.log(1 -y_hat + e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 梯度计算函数\n",
    "def calc_grandient(x,y,y_hat):\n",
    "    m = x.shape[-1]\n",
    "    delta_theta = np.dot((y_hat - y),x) / m\n",
    "    delta_bias = np.mean(y_hat - y) / m\n",
    "    return delta_theta,delta_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss:1.7565769246818594, acc:0.5142857142857142\n",
      "epoch: 300, loss:0.012775570739085444, acc:1.0\n",
      "epoch: 600, loss:0.0067566061720407715, acc:1.0\n",
      "epoch: 900, loss:0.004636781170300334, acc:1.0\n",
      "epoch: 1200, loss:0.003546479815326592, acc:1.0\n",
      "epoch: 1500, loss:0.002879674641763737, acc:1.0\n",
      "epoch: 1800, loss:0.0024286519252313525, acc:1.0\n",
      "epoch: 2100, loss:0.002102706264337458, acc:1.0\n",
      "epoch: 2400, loss:0.0018558379986070017, acc:1.0\n",
      "epoch: 2700, loss:0.0016621988276085652, acc:1.0\n",
      "epoch: 3000, loss:0.0015061309943424379, acc:1.0\n",
      "epoch: 3300, loss:0.0013775882076777254, acc:1.0\n",
      "epoch: 3600, loss:0.0012698243682734743, acc:1.0\n",
      "epoch: 3900, loss:0.0011781388811104346, acc:1.0\n",
      "epoch: 4200, loss:0.0010991545579165185, acc:1.0\n",
      "epoch: 4500, loss:0.001030381593678048, acc:1.0\n",
      "epoch: 4800, loss:0.0009699434825252536, acc:1.0\n"
     ]
    }
   ],
   "source": [
    "#3 模型训练\n",
    "for i in range(epochs):\n",
    "    #前向计算\n",
    "    y_hat = forward(X_train,theta,bias)\n",
    "    #计算损失\n",
    "    loss_val = loss(y_train,y_hat)\n",
    "    #计算梯度\n",
    "    delta_theta,delta_bias = calc_grandient(X_train,y_train,y_hat)\n",
    "    #参数更新\n",
    "    theta = theta -lr * delta_theta\n",
    "    bias = bias -lr * delta_bias\n",
    "    #准确率计算\n",
    "    if i % 300 ==0:\n",
    "        acc = np.mean(np.round(y_hat) == y_train) #[0,0,1,1,1,0,] 的序列\n",
    "        print(f\"epoch: {i}, loss:{np.mean(loss_val)}, acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9 3.6 1.4 0.1]\n",
      "0\n",
      "y:0,predict:[0.]\n"
     ]
    }
   ],
   "source": [
    "#模型推理\n",
    "idx = np.random.randint(len(X_test)) # 随机选择测试样本索引\n",
    "x = X_test[idx]\n",
    "y = y_test[idx]\n",
    "#预测出的结果\n",
    "print(x)\n",
    "print(y)\n",
    "predict = np.round(forward(x,theta,bias))\n",
    "print(f\"y:{y},predict:{predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学习率在0.1-0.01之间调试\n",
    "#拆分数据在0.25-0.75之间调试\n",
    "#训练次数在500-5000次之间进调试\n",
    "#可能是因为数据集数据量有限的原因 ，变更调试只影响到了第一次的训练，之后的准确率很快都会收束到 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数已保存至 zuoye1.npz\n"
     ]
    }
   ],
   "source": [
    "#对训练结果进行保存\n",
    "def zuoye1(theta, bias, zuoye1=\"zuoye1.npz\"):\n",
    "    np.savez(zuoye1, theta=theta, bias=bias)\n",
    "    print(f\"模型参数已保存至 {zuoye1}\")\n",
    "\n",
    "zuoye1(theta, bias) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
