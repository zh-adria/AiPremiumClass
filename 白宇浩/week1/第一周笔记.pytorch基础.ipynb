{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#pytorch基础\n",
    "#1.张量tensor  pytorch的基本单位 用于装数据的容器\n",
    "import torch\n",
    "data = torch.tensor([[1,2],[3,4],[5,6]],dtype=torch.int)\n",
    "data\n",
    "data.shape\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4],[5,6]])\n",
    "a \n",
    "a.shape\n",
    "b=torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#观察张量中元素的类型\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6790, 0.8630],\n",
       "        [0.1285, 0.5639],\n",
       "        [0.3299, 0.6983]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#通过已知的张量维度，创建新的张量\n",
    "torch.ones_like(b)\n",
    "torch.zeros_like(b)\n",
    "torch.rand_like(b,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random tensor:\n",
      " tensor([[[0.7078, 0.9877, 0.3076],\n",
      "         [0.4377, 0.4503, 0.3828]],\n",
      "\n",
      "        [[0.0472, 0.9050, 0.5853],\n",
      "         [0.3809, 0.4570, 0.2367]],\n",
      "\n",
      "        [[0.9042, 0.9212, 0.8794],\n",
      "         [0.9406, 0.1450, 0.5878]]])\n",
      "\n",
      "random tensor:\n",
      " tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "\n",
      "random tensor:\n",
      " tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (3,2,3)\n",
    "tensor_a = torch.rand(shape)\n",
    "tensor_b = torch.ones(shape)\n",
    "tensor_c = torch.zeros(shape)\n",
    "print(f'random tensor:\\n {tensor_a}\\n')\n",
    "print(f'random tensor:\\n {tensor_b}\\n')\n",
    "print(f'random tensor:\\n {tensor_c}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "\n",
      "tensor([[0.4670, 0.8335, 0.9887],\n",
      "        [0.5118, 0.7614, 0.7576],\n",
      "        [0.1094, 0.2368, 0.0787]])\n",
      "torch.Size([3, 3]) torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,   6.2105,  11.4211,  16.6316,  21.8421,  27.0526,  32.2632,\n",
       "         37.4737,  42.6842,  47.8947,  53.1053,  58.3158,  63.5263,  68.7368,\n",
       "         73.9474,  79.1579,  84.3684,  89.5789,  94.7895, 100.0000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于现有tensor构建，但使⽤新值填充\n",
    "a = torch.ones(3,3, dtype=torch.int)\n",
    "b = torch.rand_like(a,dtype = torch.float)\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "#张量的大小\n",
    "print(b.size(),a.size())\n",
    "#直接生成\n",
    "#torch.rand(5,5)\n",
    "#标准正态分布\n",
    "#torch.randn(5,5)\n",
    "#离散正态分布\n",
    "#torch.normal(mean=.0,std=1.0,size=(3,3))\n",
    "#线性间隔向量（返回一个1维张量，包含在区间start和end上均匀间隔的steps个点）\n",
    "torch.linspace(start = 1 ,end = 10 ,steps = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4609, 0.6349, 0.6990, 0.5637, 0.6328],\n",
      "        [0.9243, 0.0741, 0.1765, 0.0147, 0.8784],\n",
      "        [0.0042, 0.0783, 0.0163, 0.1354, 0.0982],\n",
      "        [0.9250, 0.6975, 0.7734, 0.0625, 0.0826],\n",
      "        [0.1875, 0.1241, 0.2082, 0.1762, 0.6742]])\n",
      "shape torch.Size([5, 5])\n",
      "datatype torch.float32\n",
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "#张量的属性\n",
    "tensor1 = torch.rand(5,5) \n",
    "print(tensor1)\n",
    "print(f\"shape {tensor1.shape}\")\n",
    "print(f\"datatype {tensor1.dtype}\")\n",
    "print(f\"device {tensor1.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "no\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#检查是否支持Gpu\n",
    "print(torch.cuda.is_available())\n",
    "#device = torch.device(\"cuda\")\n",
    "#tensor = tensor.to(device)\n",
    "#mac M系统芯片\n",
    "if torch.backends.mps.is_available():\n",
    "    print('yes')\n",
    "else:  print('no')\n",
    "print(tensor.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7580, 0.9786, 0.0543, 0.1356, 0.7746],\n",
      "        [0.9519, 0.0214, 0.1047, 0.2476, 0.9307],\n",
      "        [0.1590, 0.8282, 0.6923, 0.0543, 0.9360],\n",
      "        [0.6664, 0.1380, 0.5304, 0.6336, 0.4258]])\n",
      "\n",
      "tensor([0.7580, 0.9786, 0.0543, 0.1356, 0.7746])\n",
      "\n",
      "tensor([0.7580, 0.9519, 0.1590, 0.6664])\n",
      "\n",
      "tensor([[0.7580, 0.9786, 0.0543, 0.1356, 0.7746],\n",
      "        [0.9519, 0.0214, 0.1047, 0.2476, 0.9307],\n",
      "        [0.1590, 0.8282, 0.6923, 0.0543, 0.9360],\n",
      "        [0.6664, 0.1380, 0.5304, 0.6336, 0.4258]])\n",
      "\n",
      "tensor([0.9786, 0.0214, 0.8282, 0.1380])\n",
      "\n",
      "tensor([0.7746, 0.9307, 0.9360, 0.4258])\n",
      "\n",
      "tensor([0.7746, 0.9307, 0.9360, 0.4258])\n",
      "tensor([[10.0000, 10.0000, 10.0000, 10.0000, 10.0000],\n",
      "        [ 0.9519,  0.0214,  0.1047,  0.2476,  0.9307],\n",
      "        [ 0.1590,  0.8282,  0.6923,  0.0543,  0.9360],\n",
      "        [ 0.6664,  0.1380,  0.5304,  0.6336,  0.4258]])\n"
     ]
    }
   ],
   "source": [
    "#张量的索引 和切片\n",
    "tensor2 = torch.rand(4,5)\n",
    "print(tensor2) \n",
    "print()\n",
    "print(tensor2[0])\n",
    "print()\n",
    "print(tensor2[:,0])\n",
    "print()\n",
    "print(tensor2[:])\n",
    "print()\n",
    "print(tensor2[:,1])\n",
    "print()\n",
    "#取所有维最后一列\n",
    "print(tensor2[...,-1])\n",
    "print()\n",
    "print(tensor2[:,-1])\n",
    "#张量的赋值\n",
    "tensor2 [: 1] = 10\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0334, 0.5193, 0.9772],\n",
      "        [0.3785, 0.8462, 0.8689],\n",
      "        [0.5581, 0.7680, 0.0452]])\n",
      "\n",
      "tensor([[0.4178, 0.0221, 0.3290, 0.0211],\n",
      "        [0.8410, 0.7758, 0.9910, 0.8778],\n",
      "        [0.0300, 0.5317, 0.7893, 0.3292]])\n",
      "\n",
      "tensor([[0.8115, 0.5481, 0.8446],\n",
      "        [0.7672, 0.9756, 0.7471],\n",
      "        [0.5871, 0.6963, 0.9692],\n",
      "        [0.1949, 0.1939, 0.2087]])\n",
      "\n",
      "tensor([[0.0334, 0.5193, 0.9772, 0.4178, 0.0221, 0.3290, 0.0211],\n",
      "        [0.3785, 0.8462, 0.8689, 0.8410, 0.7758, 0.9910, 0.8778],\n",
      "        [0.5581, 0.7680, 0.0452, 0.0300, 0.5317, 0.7893, 0.3292]])\n",
      "\n",
      "tensor([[0.0334, 0.5193, 0.9772],\n",
      "        [0.3785, 0.8462, 0.8689],\n",
      "        [0.5581, 0.7680, 0.0452],\n",
      "        [0.8115, 0.5481, 0.8446],\n",
      "        [0.7672, 0.9756, 0.7471],\n",
      "        [0.5871, 0.6963, 0.9692],\n",
      "        [0.1949, 0.1939, 0.2087]])\n"
     ]
    }
   ],
   "source": [
    "#张量的拼接 cat(行相同进行列拼接) stack(列相同进行行拼接)\n",
    "tensor1 = torch.rand(3,3)\n",
    "tensor2 = torch.rand(3,4)\n",
    "tensor3 = torch.rand(4,3)\n",
    "print(tensor1)\n",
    "print()\n",
    "print(tensor2)\n",
    "print()\n",
    "print(tensor3)\n",
    "print()\n",
    "t1 = torch.cat([tensor1,tensor2],dim=1)\n",
    "print(t1)\n",
    "print()\n",
    "t2 = torch.cat([tensor1,tensor3],dim=0)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(1,10,dtype= torch.float32).reshape(3,3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 3],\n",
      "        [4, 0, 4],\n",
      "        [0, 3, 3]])\n",
      "\n",
      "tensor([[2, 1, 1],\n",
      "        [0, 0, 2],\n",
      "        [1, 0, 4]])\n",
      "\n",
      "tensor([[3, 5, 4],\n",
      "        [4, 0, 6],\n",
      "        [1, 3, 7]])\n",
      "\n",
      "tensor([[ 5,  1, 21],\n",
      "        [12,  4, 20],\n",
      "        [ 3,  0, 18]])\n",
      "\n",
      "tensor([[2, 0, 1],\n",
      "        [1, 0, 0],\n",
      "        [1, 2, 4]])\n",
      "\n",
      "tensor([[ 9,  6, 13],\n",
      "        [12,  8, 20],\n",
      "        [ 6,  6, 12]])\n"
     ]
    }
   ],
   "source": [
    "#张量的算数\n",
    "a = torch.randint(0,5,(3,3))\n",
    "b = torch.randint(0,5,(3,3))\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "print()\n",
    "print(a+b)\n",
    "print()\n",
    "print(a @ b)\n",
    "c = a.matmul(b.T)\n",
    "print()\n",
    "d = (b.T)\n",
    "print(d)\n",
    "print()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n"
     ]
    }
   ],
   "source": [
    "#继续乘法matmul\n",
    "tensor = torch.arange(1,10,dtype= torch.float32).reshape(3,3)\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor,tensor.T,out = y3)\n",
    "print(y1)\n",
    "print()\n",
    "print(y2)\n",
    "print()\n",
    "print(y3)\n",
    "#三种计算方式得到结果是一样的 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "\n",
      "tensor([[ 3.,  6.,  9.],\n",
      "        [12., 15., 18.],\n",
      "        [21., 24., 27.]])\n"
     ]
    }
   ],
   "source": [
    "#张量的乘法\n",
    "c1 = tensor * tensor\n",
    "c2 = tensor.mul(tensor)\n",
    "c3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor, out = c3)\n",
    "print(c1)\n",
    "print()\n",
    "print(c2)\n",
    "print()\n",
    "print(c3)\n",
    "c4 = tensor * 3 \n",
    "print()\n",
    "print(c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#将pytorch 还原python，numpy等环境 \n",
    "agg = tensor.sum()\n",
    "agg\n",
    "agg_item = agg.item()\n",
    "agg_item\n",
    "print(agg_item,type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]\n",
      " [49. 64. 81.]] (3, 3)\n"
     ]
    }
   ],
   "source": [
    "#还原高维的\n",
    "back = c1.numpy()\n",
    "back\n",
    "print(back,back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22., 23., 24.],\n",
      "        [25., 26., 27.],\n",
      "        [28., 29., 30.]]) \n",
      "\n",
      "tensor([[27., 28., 29.],\n",
      "        [30., 31., 32.],\n",
      "        [33., 34., 35.]])\n",
      "\n",
      "tensor([[30., 31., 32.],\n",
      "        [33., 34., 35.],\n",
      "        [36., 37., 38.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#in_place 直接修改tensor内部的值\n",
    "#加下划线  = 直接更新 不返回\n",
    "#只进行基本计算 不推荐模型更新 会丢失中间记录\n",
    "tensor\n",
    "print(tensor,\"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)\n",
    "print()\n",
    "tensor += 3\n",
    "print(tensor)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor和转化后的numpy用的是一个存储，修改的时候会同步变更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0748,  0.9393, -0.6226,  0.2086, -1.5493, -0.9291, -0.8037,  2.0960,\n",
      "         -0.6040,  1.0168],\n",
      "        [ 0.2579, -1.0646, -1.1564, -0.7577,  0.9609, -0.3273, -0.8793,  0.5228,\n",
      "         -1.3264,  1.7398],\n",
      "        [-2.2641,  0.9292, -0.1391,  0.4022,  0.5137, -0.7588,  0.8937, -0.0973,\n",
      "         -0.4428,  2.4694],\n",
      "        [-1.4379, -0.3474, -0.6540, -0.6844, -0.6821,  0.9562,  1.2686,  0.7180,\n",
      "          0.4079,  0.1116],\n",
      "        [-0.4487,  1.1314,  0.6974,  0.5303,  0.2558,  0.6852, -0.9963, -0.3036,\n",
      "         -0.6557,  0.3288],\n",
      "        [-0.7171,  1.5028,  0.2442, -0.6096,  0.1022,  0.0687,  0.3871, -2.1600,\n",
      "         -1.2958,  1.8958],\n",
      "        [-0.0775, -1.1793,  0.1410, -0.7562, -1.0659, -0.1444,  0.4864, -0.7882,\n",
      "          0.4314, -0.3560],\n",
      "        [ 0.9716,  0.9846, -0.2931, -1.6228,  1.8900,  0.2662, -0.4781, -0.4046,\n",
      "          2.6499, -0.0624],\n",
      "        [-1.9188,  0.3578, -1.5806,  0.2668,  1.0678,  0.4269, -1.0624, -2.0552,\n",
      "          0.0867,  0.4967],\n",
      "        [-0.0558,  0.5751,  0.5454,  0.2493,  0.9065, -2.0924, -0.2611,  0.2250,\n",
      "          0.4832, -0.9831]], requires_grad=True)\n",
      "\n",
      "tensor([ 0.0942, -0.7715,  1.2989, -1.6072, -0.3111, -0.5926, -0.6925,  0.8229,\n",
      "        -0.5853,  1.0741], requires_grad=True)\n",
      "\n",
      "tensor([-0.4744], requires_grad=True)\n",
      "\n",
      "tensor([ 0.9074, -0.2363, -1.3534,  1.5267,  0.9210,  0.0324, -0.0191, -1.2984,\n",
      "         1.3127, -1.1841], requires_grad=True)\n",
      "\n",
      "tensor([-14.0153, -10.5142, -12.2385, -10.3520,  -9.2071, -11.1384,  -7.9405,\n",
      "         -3.4151,  -3.8868,  -6.0850], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#计算图\n",
    "#深度学习 即将复杂的数学计算进行计算机流程化\n",
    "#数学中的求导 = 梯度计算 梯度下降 ,用结果作为参数继续计算以缩小差异 精确化\n",
    "#计算 x.T * A + b * x + c\n",
    "#1.定义张量，向量，常数\n",
    "#requires_grad 表示需要求导\n",
    "A = torch.randn(10,10,requires_grad=True)\n",
    "b = torch.randn(10,requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn(10,requires_grad=True)\n",
    "s = torch.matmul(A,x.T) + torch.matmul(b,x) + c\n",
    "print(A)\n",
    "print()\n",
    "print(b)\n",
    "print()\n",
    "print(c)\n",
    "print()\n",
    "print(x)\n",
    "print()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上面绘制计算图需要进行\n",
    "#import torch \n",
    "#from torchviz import make_dot\n",
    "#环境暂时不支持\n",
    "#静态计算图 编写 布置 速度快\n",
    "#动态计算图 灵活\n",
    "#矩阵乘积 a * b  <>  b * a 不能随意换位 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
