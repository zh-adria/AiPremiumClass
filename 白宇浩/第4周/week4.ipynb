{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建的神经网络，使用olivettiface数据集进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的包\n",
    "import torch\n",
    "import torch.nn as nn                           #模型工具包\n",
    "import torch.optim as optim                     #优化器\n",
    "from torchvision.transforms.v2 import ToTensor  #转换图像为张量\n",
    "from sklearn.datasets import fetch_olivetti_faces     #数据集\n",
    "from sklearn.model_selection import train_test_split  #数据拆分\n",
    "from torch.utils.data import DataLoader, TensorDataset         #数据加载器 ，优化大量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "LR = 1e-3\n",
    "epochs = 20\n",
    "BATCH_SIZE = 32 #数据批次拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "face_data = fetch_olivetti_faces(data_home = './data',shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据拆分\n",
    "X = torch.tensor(face_data.images.reshape(400,-1))\n",
    "y = torch.tensor(face_data.target, dtype=torch.long)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集创建\n",
    "face_train_data = TensorDataset(X_train, y_train)\n",
    "face_test_data = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载器\n",
    "train_loader = DataLoader(face_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(face_test_data, batch_size=BATCH_SIZE, shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#形状确认\n",
    "face_train_data[1][0].reshape(-1).shape #将图像转为1维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型调用\n",
    "from torch_week4_model import TorcFace\n",
    "model = TorcFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss() #交叉熵损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Loss:0.19826005399227142\n",
      "Epoch:0,Loss:0.11052684485912323\n",
      "Epoch:0,Loss:0.14646679162979126\n",
      "Epoch:0,Loss:0.1495869904756546\n",
      "Epoch:0,Loss:0.09262598305940628\n",
      "Epoch:0,Loss:0.1379576474428177\n",
      "Epoch:0,Loss:0.11275103688240051\n",
      "Epoch:0,Loss:0.17236575484275818\n",
      "Epoch:0,Loss:0.1532813459634781\n",
      "Epoch:0,Loss:0.13539882004261017\n",
      "Epoch:1,Loss:0.11484779417514801\n",
      "Epoch:1,Loss:0.09896522015333176\n",
      "Epoch:1,Loss:0.10863310098648071\n",
      "Epoch:1,Loss:0.16744859516620636\n",
      "Epoch:1,Loss:0.1220143511891365\n",
      "Epoch:1,Loss:0.08022427558898926\n",
      "Epoch:1,Loss:0.1624944657087326\n",
      "Epoch:1,Loss:0.11694033443927765\n",
      "Epoch:1,Loss:0.10143576562404633\n",
      "Epoch:1,Loss:0.14593233168125153\n",
      "Epoch:2,Loss:0.11930884420871735\n",
      "Epoch:2,Loss:0.13153311610221863\n",
      "Epoch:2,Loss:0.12201989442110062\n",
      "Epoch:2,Loss:0.09756243973970413\n",
      "Epoch:2,Loss:0.11900097876787186\n",
      "Epoch:2,Loss:0.06256412714719772\n",
      "Epoch:2,Loss:0.08191322535276413\n",
      "Epoch:2,Loss:0.1335870921611786\n",
      "Epoch:2,Loss:0.09735909104347229\n",
      "Epoch:2,Loss:0.18964339792728424\n",
      "Epoch:3,Loss:0.12709839642047882\n",
      "Epoch:3,Loss:0.10025615990161896\n",
      "Epoch:3,Loss:0.07491084188222885\n",
      "Epoch:3,Loss:0.09009925276041031\n",
      "Epoch:3,Loss:0.11972653865814209\n",
      "Epoch:3,Loss:0.12277667224407196\n",
      "Epoch:3,Loss:0.10117047280073166\n",
      "Epoch:3,Loss:0.10739537328481674\n",
      "Epoch:3,Loss:0.0741494670510292\n",
      "Epoch:3,Loss:0.21124707162380219\n",
      "Epoch:4,Loss:0.12236935645341873\n",
      "Epoch:4,Loss:0.09843447804450989\n",
      "Epoch:4,Loss:0.0699489563703537\n",
      "Epoch:4,Loss:0.09289397299289703\n",
      "Epoch:4,Loss:0.12111243605613708\n",
      "Epoch:4,Loss:0.11286428570747375\n",
      "Epoch:4,Loss:0.1027507558465004\n",
      "Epoch:4,Loss:0.13100486993789673\n",
      "Epoch:4,Loss:0.09557807445526123\n",
      "Epoch:4,Loss:0.3460240066051483\n",
      "Epoch:5,Loss:0.0737021267414093\n",
      "Epoch:5,Loss:0.09778469055891037\n",
      "Epoch:5,Loss:0.08333590626716614\n",
      "Epoch:5,Loss:0.08960816264152527\n",
      "Epoch:5,Loss:0.12087058275938034\n",
      "Epoch:5,Loss:0.09451868385076523\n",
      "Epoch:5,Loss:0.06608562916517258\n",
      "Epoch:5,Loss:0.06793666630983353\n",
      "Epoch:5,Loss:0.05645008385181427\n",
      "Epoch:5,Loss:0.14344839751720428\n",
      "Epoch:6,Loss:0.065986268222332\n",
      "Epoch:6,Loss:0.08046494424343109\n",
      "Epoch:6,Loss:0.1354665756225586\n",
      "Epoch:6,Loss:0.12243969738483429\n",
      "Epoch:6,Loss:0.09204600751399994\n",
      "Epoch:6,Loss:0.09159251302480698\n",
      "Epoch:6,Loss:0.047497473657131195\n",
      "Epoch:6,Loss:0.09804034978151321\n",
      "Epoch:6,Loss:0.09686577320098877\n",
      "Epoch:6,Loss:0.07238803058862686\n",
      "Epoch:7,Loss:0.09737933427095413\n",
      "Epoch:7,Loss:0.06346175074577332\n",
      "Epoch:7,Loss:0.04937395453453064\n",
      "Epoch:7,Loss:0.054495345801115036\n",
      "Epoch:7,Loss:0.05167212709784508\n",
      "Epoch:7,Loss:0.07193547487258911\n",
      "Epoch:7,Loss:0.06197066977620125\n",
      "Epoch:7,Loss:0.06682655215263367\n",
      "Epoch:7,Loss:0.12958961725234985\n",
      "Epoch:7,Loss:0.09068966656923294\n",
      "Epoch:8,Loss:0.06083165109157562\n",
      "Epoch:8,Loss:0.07844701409339905\n",
      "Epoch:8,Loss:0.09546663612127304\n",
      "Epoch:8,Loss:0.12765872478485107\n",
      "Epoch:8,Loss:0.061463695019483566\n",
      "Epoch:8,Loss:0.06461669504642487\n",
      "Epoch:8,Loss:0.06044638156890869\n",
      "Epoch:8,Loss:0.08234289288520813\n",
      "Epoch:8,Loss:0.05423922836780548\n",
      "Epoch:8,Loss:0.0778665542602539\n",
      "Epoch:9,Loss:0.07601834088563919\n",
      "Epoch:9,Loss:0.06305383145809174\n",
      "Epoch:9,Loss:0.06374070048332214\n",
      "Epoch:9,Loss:0.06338255107402802\n",
      "Epoch:9,Loss:0.04281983524560928\n",
      "Epoch:9,Loss:0.08890791982412338\n",
      "Epoch:9,Loss:0.054909441620111465\n",
      "Epoch:9,Loss:0.057084523141384125\n",
      "Epoch:9,Loss:0.09542816132307053\n",
      "Epoch:9,Loss:0.09217840433120728\n",
      "Epoch:10,Loss:0.07246603071689606\n",
      "Epoch:10,Loss:0.0806981772184372\n",
      "Epoch:10,Loss:0.05932057648897171\n",
      "Epoch:10,Loss:0.06012622267007828\n",
      "Epoch:10,Loss:0.047817159444093704\n",
      "Epoch:10,Loss:0.04949275776743889\n",
      "Epoch:10,Loss:0.05312570556998253\n",
      "Epoch:10,Loss:0.04503186419606209\n",
      "Epoch:10,Loss:0.04919594153761864\n",
      "Epoch:10,Loss:0.04372771084308624\n",
      "Epoch:11,Loss:0.045161373913288116\n",
      "Epoch:11,Loss:0.034803494811058044\n",
      "Epoch:11,Loss:0.06002023443579674\n",
      "Epoch:11,Loss:0.03356540575623512\n",
      "Epoch:11,Loss:0.05954304710030556\n",
      "Epoch:11,Loss:0.06890459358692169\n",
      "Epoch:11,Loss:0.05289134383201599\n",
      "Epoch:11,Loss:0.0553973987698555\n",
      "Epoch:11,Loss:0.03475377708673477\n",
      "Epoch:11,Loss:0.01974043808877468\n",
      "Epoch:12,Loss:0.060809917747974396\n",
      "Epoch:12,Loss:0.03778510540723801\n",
      "Epoch:12,Loss:0.0467381477355957\n",
      "Epoch:12,Loss:0.07233954966068268\n",
      "Epoch:12,Loss:0.020892268046736717\n",
      "Epoch:12,Loss:0.05721910670399666\n",
      "Epoch:12,Loss:0.059684883803129196\n",
      "Epoch:12,Loss:0.04199780151247978\n",
      "Epoch:12,Loss:0.048298634588718414\n",
      "Epoch:12,Loss:0.13248798251152039\n",
      "Epoch:13,Loss:0.05515817180275917\n",
      "Epoch:13,Loss:0.04599225893616676\n",
      "Epoch:13,Loss:0.054536424577236176\n",
      "Epoch:13,Loss:0.019464323297142982\n",
      "Epoch:13,Loss:0.04586389660835266\n",
      "Epoch:13,Loss:0.040874216705560684\n",
      "Epoch:13,Loss:0.061216238886117935\n",
      "Epoch:13,Loss:0.047936029732227325\n",
      "Epoch:13,Loss:0.03613666072487831\n",
      "Epoch:13,Loss:0.3049374222755432\n",
      "Epoch:14,Loss:0.03185713663697243\n",
      "Epoch:14,Loss:0.022013576701283455\n",
      "Epoch:14,Loss:0.06046435236930847\n",
      "Epoch:14,Loss:0.04685121774673462\n",
      "Epoch:14,Loss:0.06184648722410202\n",
      "Epoch:14,Loss:0.0786692202091217\n",
      "Epoch:14,Loss:0.09273744374513626\n",
      "Epoch:14,Loss:0.03586193919181824\n",
      "Epoch:14,Loss:0.05652131140232086\n",
      "Epoch:14,Loss:0.10614650696516037\n",
      "Epoch:15,Loss:0.035206202417612076\n",
      "Epoch:15,Loss:0.04470494017004967\n",
      "Epoch:15,Loss:0.03480987250804901\n",
      "Epoch:15,Loss:0.07020018249750137\n",
      "Epoch:15,Loss:0.07264784723520279\n",
      "Epoch:15,Loss:0.06979002803564072\n",
      "Epoch:15,Loss:0.05475460737943649\n",
      "Epoch:15,Loss:0.09495946019887924\n",
      "Epoch:15,Loss:0.05559679493308067\n",
      "Epoch:15,Loss:0.08762102574110031\n",
      "Epoch:16,Loss:0.039908841252326965\n",
      "Epoch:16,Loss:0.04152633994817734\n",
      "Epoch:16,Loss:0.06794469058513641\n",
      "Epoch:16,Loss:0.0815068930387497\n",
      "Epoch:16,Loss:0.05967998877167702\n",
      "Epoch:16,Loss:0.04698282480239868\n",
      "Epoch:16,Loss:0.061014071106910706\n",
      "Epoch:16,Loss:0.05078151822090149\n",
      "Epoch:16,Loss:0.0551031194627285\n",
      "Epoch:16,Loss:0.14361964166164398\n",
      "Epoch:17,Loss:0.03019637241959572\n",
      "Epoch:17,Loss:0.042065270245075226\n",
      "Epoch:17,Loss:0.055709872394800186\n",
      "Epoch:17,Loss:0.0767350047826767\n",
      "Epoch:17,Loss:0.038560543209314346\n",
      "Epoch:17,Loss:0.07473388314247131\n",
      "Epoch:17,Loss:0.051778122782707214\n",
      "Epoch:17,Loss:0.1344253569841385\n",
      "Epoch:17,Loss:0.01948847994208336\n",
      "Epoch:17,Loss:0.06964180618524551\n",
      "Epoch:18,Loss:0.061758071184158325\n",
      "Epoch:18,Loss:0.051500894129276276\n",
      "Epoch:18,Loss:0.04267120361328125\n",
      "Epoch:18,Loss:0.03768385201692581\n",
      "Epoch:18,Loss:0.038922879844903946\n",
      "Epoch:18,Loss:0.049307968467473984\n",
      "Epoch:18,Loss:0.04953578859567642\n",
      "Epoch:18,Loss:0.039042700082063675\n",
      "Epoch:18,Loss:0.0665772557258606\n",
      "Epoch:18,Loss:0.11039181798696518\n",
      "Epoch:19,Loss:0.05268999934196472\n",
      "Epoch:19,Loss:0.03949133679270744\n",
      "Epoch:19,Loss:0.06096615269780159\n",
      "Epoch:19,Loss:0.03092399798333645\n",
      "Epoch:19,Loss:0.03798329085111618\n",
      "Epoch:19,Loss:0.07203660905361176\n",
      "Epoch:19,Loss:0.04040786623954773\n",
      "Epoch:19,Loss:0.0635344386100769\n",
      "Epoch:19,Loss:0.043249234557151794\n",
      "Epoch:19,Loss:0.09948503226041794\n"
     ]
    }
   ],
   "source": [
    "#6.模型的训练\n",
    "for epoch in range(epochs):\n",
    "    #提取训练的数据  数据导入到模型中\n",
    "    for data,target in train_loader:\n",
    "        out_put = model(data)           #前向运算/前向传播\n",
    "        loss = loss_fn(out_put,target)  #计算损失\n",
    "        #反向传播 \n",
    "        optimizer.zero_grad()           #所有参数梯度清零\n",
    "        loss.backward()                 #计算梯度(参数，grad)\n",
    "        optimizer.step()                #更新参数\n",
    "        print(f'Epoch:{epoch},Loss:{loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.0%\n"
     ]
    }
   ],
   "source": [
    "##6.0测试\n",
    "test_dl = DataLoader(test_loader,batch_size= BATCH_SIZE)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():    #不进行梯度计算\n",
    "    for data,target in test_loader:\n",
    "        output = model(data) \n",
    "        _,predicted = torch.max(output,1)\n",
    "        total += target.size(0) #size(0) = shape[0]\n",
    "        correct+= (predicted == target).sum().item()\n",
    "print(f'{correct/total*100}%')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
