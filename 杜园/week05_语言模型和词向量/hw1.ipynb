{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 实现基于豆瓣top250图书评论的简单推荐系统（TF-IDF及BM25两种算法实现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import csv\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集处理\n",
    "def get_new_book(oldFileName, newFileName):\n",
    "    if os.path.exists(newFileName):\n",
    "        return\n",
    "    new_f = open(newFileName, 'w')\n",
    "    lines = [line for line in open(oldFileName, 'r')]\n",
    "    for i, line in enumerate(tqdm(lines)):\n",
    "        line = line.strip()\n",
    "        # 标题行\n",
    "        if i == 0:\n",
    "            new_f.write(line + '\\n')\n",
    "            pre_line = ''\n",
    "            continue\n",
    "        \n",
    "        # 记录首行 or 同一本书换行情况\n",
    "        if not pre_line:\n",
    "            pre_line = line\n",
    "            continue\n",
    "        \n",
    "        curr_lines = line.split('\\t')\n",
    "        pre_lines = pre_line.split('\\t')\n",
    "        # 同一本书 and 未换行\n",
    "        if curr_lines[0] == pre_lines[0]:\n",
    "            new_f.write(pre_line + '\\n')\n",
    "            pre_line = line\n",
    "        # 不同书 or 同一本书换行了\n",
    "        else:\n",
    "            # 不同书\n",
    "            if len(curr_lines) == 6:\n",
    "                new_f.write(pre_line + '\\n')\n",
    "                pre_line = line\n",
    "            # 同一本书换行了\n",
    "            else:\n",
    "                pre_line += line\n",
    "                \n",
    "    new_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词获取\n",
    "def get_book_comments(fileName):\n",
    "    book_comments = {}\n",
    "    with open(fileName, 'r') as f:\n",
    "        lines = csv.DictReader(f, delimiter='\\t')\n",
    "        for line in lines:\n",
    "            book_name = line.get('book', '')\n",
    "            comments = line.get('body', '')\n",
    "            \n",
    "            if not book_name or not comments : \n",
    "                continue\n",
    "            \n",
    "            comments_words = jieba.lcut(comments)\n",
    "            book_comments.setdefault(book_name, []).extend(comments_words)\n",
    "    return book_comments\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF算法-计算推荐书籍\n",
    "def tfidf_recommendation(stopWords, book_comments, in_book_name):\n",
    "    book_name_list = list(book_comments.keys())\n",
    "    # 构建IF-IDF矩阵（每个元素都是词典每个词汇在当前书籍中的TF-IDF值）\n",
    "    tfidfVectorizer = TfidfVectorizer(stop_words=stopWords)\n",
    "    tfidfVectorizer.fit\n",
    "    tfidf_matrix = tfidfVectorizer.fit_transform([' '.join(book_comments[book_name]) for book_name in book_name_list])\n",
    "\n",
    "    # 计算TF-IDF余弦相似度（每个元素都是当前书籍和其他书籍向量余弦值）\n",
    "    similaritys = cosine_similarity(tfidf_matrix)\n",
    "    book_idx = book_name_list.index(in_book_name)\n",
    "    similarity_row = similaritys[book_idx]\n",
    "    \n",
    "    top_10_similar_books = np.argsort(similarity_row)[::-1][1:11]\n",
    "    \n",
    "    top_10_similar_books = [book_name_list[i] for i in top_10_similar_books]\n",
    "    return top_10_similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25-计算推荐书籍\n",
    "def bm25_recommendation(stopWords, book_comments, in_book_name):\n",
    "    book_name_list = list(book_comments.keys())\n",
    "    all_comments = [' '.join(book_comments[book_name]) for book_name in book_name_list]\n",
    "    bm25 = BM25Okapi([word for word in all_comments if word not in stopWords])\n",
    "    \n",
    "    # 获取输入书籍的评论并分词\n",
    "    in_book_comment = ' '.join(book_comments[in_book_name])\n",
    "    in_book_tokens = [word for word in jieba.lcut(in_book_comment) if word not in stopWords]\n",
    "    \n",
    "    # 计算输入书籍与其他书籍的BM25得分\n",
    "    scores = bm25.get_scores(in_book_tokens)\n",
    "    \n",
    "    top_10_similar_books = np.argsort(scores)[::-1][1:11]\n",
    "    \n",
    "    top_10_similar_books = [book_name_list[i] for i in top_10_similar_books]\n",
    "    return top_10_similar_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\uchonor\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.164 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "d:\\dyySoftWare\\newsoftware\\envs\\py312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['able', 'about', 'above', 'abroad', 'according', 'accordingly', 'across', 'actually', 'adj', 'after', 'afterwards', 'again', 'against', 'ago', 'ahead', 'ain', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'alongside', 'already', 'also', 'although', 'always', 'am', 'amid', 'amidst', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', 'aren', 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'back', 'backward', 'backwards', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'begin', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'came', 'can', 'cannot', 'cant', 'caption', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', 'couldn', 'course', 'currently', 'dare', 'daren', 'definitely', 'described', 'despite', 'did', 'didn', 'different', 'directly', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'downwards', 'during', 'each', 'edu', 'eg', 'eight', 'eighty', 'either', 'else', 'elsewhere', 'end', 'ending', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'evermore', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'fairly', 'far', 'farther', 'few', 'fewer', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'forever', 'former', 'formerly', 'forth', 'forward', 'found', 'four', 'from', 'further', 'furthermore', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'had', 'hadn', 'half', 'happens', 'hardly', 'has', 'hasn', 'have', 'haven', 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'hundred', 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'inside', 'insofar', 'instead', 'into', 'inward', 'is', 'isn', 'it', 'its', 'itself', 'just', 'keep', 'keeps', 'kept', 'know', 'known', 'knows', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', 'like', 'liked', 'likely', 'likewise', 'little', 'll', 'look', 'looking', 'looks', 'low', 'lower', 'ltd', 'made', 'mainly', 'make', 'makes', 'many', 'may', 'maybe', 'mayn', 'me', 'mean', 'meantime', 'meanwhile', 'merely', 'might', 'mightn', 'mine', 'minus', 'miss', 'mon', 'more', 'moreover', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'mustn', 'my', 'myself', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needn', 'needs', 'neither', 'never', 'neverf', 'neverless', 'nevertheless', 'new', 'next', 'nine', 'ninety', 'no', 'nobody', 'non', 'none', 'nonetheless', 'noone', 'nor', 'normally', 'not', 'nothing', 'notwithstanding', 'novel', 'now', 'nowhere', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'opposite', 'or', 'other', 'others', 'otherwise', 'ought', 'oughtn', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'particular', 'particularly', 'past', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provided', 'provides', 'que', 'quite', 'qv', 'rather', 'rd', 're', 'really', 'reasonably', 'recent', 'recently', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 'round', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'shan', 'she', 'should', 'shouldn', 'since', 'six', 'so', 'some', 'somebody', 'someday', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 'take', 'taken', 'taking', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', 'thing', 'things', 'think', 'third', 'thirty', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'till', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'un', 'under', 'underneath', 'undoing', 'unfortunately', 'unless', 'unlike', 'unlikely', 'until', 'unto', 'up', 'upon', 'upwards', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'value', 'various', 've', 'versus', 'very', 'via', 'viz', 'vs', 'want', 'wants', 'was', 'wasn', 'way', 'we', 'welcome', 'well', 'went', 'were', 'weren', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'whichever', 'while', 'whilst', 'whither', 'who', 'whoever', 'whole', 'whom', 'whomever', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', 'won', 'wonder', 'would', 'wouldn', 'yes', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', '一切', '一则', '一方面', '一旦', '一来', '一样', '一般', '万一', '上下', '不仅', '不但', '不光', '不单', '不只', '不如', '不怕', '不惟', '不成', '不拘', '不比', '不然', '不特', '不独', '不管', '不论', '不过', '不问', '与其', '与否', '与此同时', '两者', '为了', '为什么', '为何', '为着', '乃至', '之一', '之所以', '之类', '乌乎', '也好', '也罢', '于是', '于是乎', '云云', '人家', '什么', '什么样', '从而', '他人', '他们', '以便', '以免', '以及', '以至', '以至于', '以致', '任何', '任凭', '似的', '但是', '何况', '何处', '何时', '作为', '你们', '使得', '例如', '依照', '俺们', '倘使', '倘或', '倘然', '倘若', '假使', '假如', '假若', '关于', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '再者', '再说', '况且', '几时', '凭借', '别的', '别说', '前后', '前者', '加之', '即令', '即使', '即便', '即或', '即若', '及其', '及至', '反之', '反过来', '反过来说', '另一方面', '另外', '只是', '只有', '只要', '只限', '叮咚', '可以', '可是', '可见', '各个', '各位', '各种', '各自', '同时', '向着', '否则', '吧哒', '呜呼', '呼哧', '咱们', '哈哈', '哎呀', '哎哟', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼唷', '啪达', '喔唷', '嗡嗡', '嘎登', '因为', '因此', '因而', '固然', '在下', '多少', '她们', '如上所述', '如何', '如其', '如果', '如此', '如若', '宁可', '宁愿', '宁肯', '它们', '对于', '尔后', '尚且', '就是', '就是说', '尽管', '岂但', '并且', '开外', '开始', '当着', '彼此', '怎么', '怎么办', '怎么样', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '慢说', '我们', '或是', '或者', '所以', '抑或', '按照', '换句话说', '换言之', '接着', '故此', '旁人', '无宁', '无论', '既是', '既然', '时候', '是的', '有些', '有关', '有的', '朝着', '本着', '来着', '极了', '果然', '果真', '某个', '某些', '根据', '正如', '此外', '此间', '毋宁', '每当', '比如', '比方', '沿着', '漫说', '然则', '然后', '然而', '照着', '甚么', '甚而', '甚至', '由于', '由此可见', '的话', '相对而言', '省得', '着呢', '等等', '紧接着', '纵令', '纵使', '纵然', '经过', '结果', '继而', '综上所述', '罢了', '而且', '而况', '而外', '而已', '而是', '而言', '自个儿', '自从', '自各儿', '自家', '自己', '自身', '至于', '若是', '若非', '莫若', '虽则', '虽然', '虽说', '要不', '要不是', '要不然', '要么', '要是', '设使', '设若', '诸位', '谁知', '起见', '趁着', '越是', '较之', '还是', '还有', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这边', '这里', '进而', '连同', '通过', '遵照', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那边', '那里', '鄙人', '鉴于', '除了', '除此之外', '除非', '随着', '非但', '非徒', '顺着', '首先'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF - IDF推荐结果(图书，按相关性从高到低): ['明朝那些事儿（壹）', '明朝那些事儿（1-9）', '万历十五年', '明朝那些事儿（叁）', '明朝那些事儿（柒）：大结局', '明朝那些事儿（陆）', '明朝那些事儿（肆）', '人类简史', '明朝那些事儿（伍）', '穆斯林的葬礼']\n",
      "BM25推荐结果(图书，按相关性从高到低): ['明朝那些事儿（壹）', '明朝那些事儿（1-9）', '万历十五年', '明朝那些事儿（叁）', '明朝那些事儿（柒）：大结局', '明朝那些事儿（陆）', '明朝那些事儿（肆）', '人类简史', '明朝那些事儿（伍）', '穆斯林的葬礼']\n"
     ]
    }
   ],
   "source": [
    "# 找相近书籍\n",
    "if __name__ == '__main__':\n",
    "    oldFileName = \"doubanbook_top250_comments.txt\"\n",
    "    newFileName = \"doubanbook_top250_comments_new.txt\"\n",
    "    # 书籍内容格式化\n",
    "    get_new_book(oldFileName, newFileName)\n",
    "    \n",
    "    # 加载分词数据集\n",
    "    book_comments = get_book_comments(newFileName)\n",
    "    book_name_list = list(book_comments.keys())\n",
    "    \n",
    "    # 停用词处理\n",
    "    stopWords = [word for word in open('stopwords.txt', 'r')]\n",
    "    # 查找任意一本书籍相似的排名前10的书籍\n",
    "    in_book_name = '明朝那些事儿（贰）'\n",
    "   \n",
    "   # 使用TF - IDF算法进行推荐\n",
    "    tfidf_result = tfidf_recommendation(stopWords, book_comments, in_book_name)\n",
    "    print(\"TF - IDF推荐结果(图书，按相关性从高到低):\", tfidf_result)\n",
    "    # 使用BM25算法进行推荐\n",
    "    bm25_result = bm25_recommendation(stopWords, book_comments, in_book_name)\n",
    "    print(\"BM25推荐结果(图书，按相关性从高到低):\", tfidf_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
