{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch FashionMNIST 数据集 神经网络搭建与训练\n",
    "    训练模型，实现给定图片就能识别种类\n",
    "    分析：\n",
    "        60000张图片去训练模型，每张图片获取一个最优的参数\n",
    "        1、输入层：60000-gray图片，28*28像素， X.shape=(60000,784)\n",
    "        2、隐藏层：10个神经元 参数矩阵shape=(784,64) 偏置bias shape=(64,)\n",
    "        3、输出层：参数矩阵shape=(64,10) 偏置bias-shape=(10,) Y输出shape=(,10)\n",
    "        4、损失函数：交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epochs = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集初始化（输入层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FashionMNIST(\"./data\", train=True, download=True, transform=ToTensor())\n",
    "# print(train_data[0][0].shape)\n",
    "test_data = FashionMNIST(\"./data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# 数据集分成多个批次 shuffle=True 表示打乱顺序\n",
    "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型（隐藏层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数和优化器（隐藏层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoach: 0 loss: 1.9524188041687012\n",
      "epoach: 1 loss: 1.5578504800796509\n",
      "epoach: 2 loss: 1.3717269897460938\n",
      "epoach: 3 loss: 1.1581310033798218\n",
      "epoach: 4 loss: 1.1286684274673462\n",
      "epoach: 5 loss: 0.9818857312202454\n",
      "epoach: 6 loss: 0.9169284701347351\n",
      "epoach: 7 loss: 0.9693338871002197\n",
      "epoach: 8 loss: 0.7670623660087585\n",
      "epoach: 9 loss: 0.9085621237754822\n"
     ]
    }
   ],
   "source": [
    "# 分多轮训练\n",
    "for epoch in range(epochs):\n",
    "    # 提取训练数据\n",
    "    for x, y in train_dl:\n",
    "        # torch.Size([1000, 1, 28, 28]) torch.Size([1000])\n",
    "        # print(x.shape, y.shape)\n",
    "        # ① 前向传播\n",
    "        y_hat = model(x.reshape(-1, 784))\n",
    "        # ② 计算损失\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # ③ 反向传播\n",
    "        optimizer.zero_grad() # 清空参数\n",
    "        loss.backward() # 计算参数(参数保存在每个参数的grad属性中)\n",
    "        optimizer.step() # 更新参数\n",
    "    print(f\"epoach: {epoch} loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7368\n"
     ]
    }
   ],
   "source": [
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():  # 不计算梯度，节省内存\n",
    "    for data, target in test_dl:  # data: 128*1*28*28（128张图片，1个通道，28*28），target: 128*1 （128个标签）\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        # print(output.shape)  # 128*10\n",
    "        max_out,max_idx = torch.max(output, dim=1) # 返回每行最大值和索引\n",
    "        total += target.size(0) # 第0维的大小，即128 = shape(0)\n",
    "        correct += (max_idx == target).sum().item() # 求和得到正确的个数\n",
    "\n",
    "print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9755e+00,  1.4738e+00, -9.4906e-01,  3.9483e+00,  1.2450e-01,\n",
       "         -6.6696e-01,  1.0293e+00, -1.8182e+00, -2.5819e-01, -1.9695e+00],\n",
       "        [ 8.4259e-01,  5.7607e-01,  9.6443e-01,  1.4058e+00,  1.6267e+00,\n",
       "         -6.5534e-01,  1.6045e+00, -1.9628e+00, -2.7740e-01, -1.7215e+00],\n",
       "        [-3.0917e+00, -1.8240e+00, -1.6697e+00, -9.2715e-01, -1.7685e+00,\n",
       "          3.9932e+00, -1.2153e+00,  5.5386e+00,  1.8424e+00,  2.3527e+00],\n",
       "        [-1.0389e+00, -1.9952e+00, -7.7800e-01, -9.5157e-01, -1.5831e+00,\n",
       "          3.9125e+00, -5.2330e-02,  1.3266e+00,  1.1331e+00,  2.0917e+00],\n",
       "        [-2.2465e+00, -2.9196e+00,  1.1203e-01, -1.4813e+00,  3.3248e-03,\n",
       "          2.3692e+00,  2.5569e-01,  2.0034e+00,  3.9706e+00,  9.4605e-01],\n",
       "        [ 7.4512e-01, -9.6655e-01,  3.4576e+00, -2.7982e-01,  3.4936e+00,\n",
       "         -1.0004e+00,  3.0458e+00, -3.8110e+00,  4.0171e-01, -3.1317e+00],\n",
       "        [ 6.8878e-01, -2.4629e+00, -1.3227e-01, -1.1828e+00, -1.8675e+00,\n",
       "          3.7269e+00,  6.4393e-01, -6.3120e-02, -2.3078e-01,  2.4577e+00],\n",
       "        [ 1.8542e+00, -1.0778e+00,  2.6784e+00,  2.2470e-01,  2.0634e+00,\n",
       "         -5.8955e-01,  2.8689e+00, -3.2287e+00,  4.1976e-01, -2.8849e+00],\n",
       "        [-1.2371e+00, -2.7993e+00,  2.8925e-01,  1.1754e-01,  9.3320e-01,\n",
       "          6.8428e-01,  9.1925e-01, -2.6701e-01,  4.1503e+00,  1.3028e-01],\n",
       "        [-1.9814e+00, -3.5837e+00, -1.3312e+00, -1.1510e+00, -1.5557e+00,\n",
       "          2.8304e+00, -7.6258e-01,  2.1370e+00,  1.8270e+00,  5.7025e+00],\n",
       "        [ 8.1316e-01,  5.7153e+00, -8.1981e-01,  3.3899e+00,  1.0821e+00,\n",
       "         -4.3646e-01,  3.2289e-01, -1.6541e+00, -2.7012e+00, -3.2290e+00],\n",
       "        [-1.7925e+00, -3.5451e+00, -1.1270e+00, -1.2391e+00, -1.3580e+00,\n",
       "          2.7016e+00, -5.9220e-01,  1.7527e+00,  1.6984e+00,  5.5779e+00],\n",
       "        [ 9.2304e-01,  4.0847e+00, -4.2900e-01,  2.7798e+00,  6.1689e-01,\n",
       "          1.4397e-01,  5.7558e-01, -1.3111e+00, -2.1426e+00, -2.9076e+00],\n",
       "        [ 1.5402e+00, -1.4659e+00, -8.1868e-01,  1.8439e+00, -3.0966e-01,\n",
       "          5.6529e-01,  1.1436e+00, -1.5143e+00,  2.1371e+00, -4.8084e-01],\n",
       "        [ 7.9404e-01,  4.9109e+00, -9.9973e-01,  3.7417e+00,  7.8266e-01,\n",
       "         -4.7200e-01,  2.9873e-01, -1.4581e+00, -2.4548e+00, -2.6508e+00],\n",
       "        [-2.1516e+00, -1.8004e+00, -5.9328e-01, -1.0074e+00, -8.3591e-01,\n",
       "          3.2800e+00, -2.9264e-01,  2.9614e+00,  1.6131e+00,  1.5137e+00]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
