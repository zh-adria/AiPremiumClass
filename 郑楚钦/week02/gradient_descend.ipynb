{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 10), (100,))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 收集数据\n",
    "X, y = make_classification(n_features=10)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 10), (20, 10), (80,), (20,))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据准备\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "train_X.shape, test_X.shape, train_y.shape, test_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.14534374, -0.17575804, -0.0853157 , -0.798899  , -0.09461756,\n",
       "         -0.33810223,  0.37753045,  0.3705328 ,  0.67034586, -1.11896986]]),\n",
       " 0,\n",
       " 0.001,\n",
       " 1000)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化参数\n",
    "theta = np.random.randn(1, 10)\n",
    "bias = 0\n",
    "lr = 1e-3\n",
    "epoch = 1000\n",
    "theta, bias, lr, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正向传播\n",
    "def forward(x, theta, bias):\n",
    "    z =  (theta @ x.T) + bias\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def cost_function(y, y_hat):\n",
    "    e = 1e-8\n",
    "    lost = -y * np.log(y_hat + e) - (1 - y) * np.log(1-y_hat+e)\n",
    "    return np.mean(lost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度 和伯努利分布有关\n",
    "def gradient(x,y,y_hat):\n",
    "    m = x.shape[-1]\n",
    "    delta_w = np.dot(y_hat-y,x)/m\n",
    "    delta_b = np.mean(y_hat-y)\n",
    "    return delta_w,delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0; loss: 0.9813508033270455\n",
      "step: 50; loss: 0.7489823625259874\n",
      "step: 100; loss: 0.5936759195149565\n",
      "step: 150; loss: 0.4911821609347703\n",
      "step: 200; loss: 0.4219617504660606\n",
      "step: 250; loss: 0.3734520821166816\n",
      "step: 300; loss: 0.3381446506752712\n",
      "step: 350; loss: 0.31155678877416015\n",
      "step: 400; loss: 0.2909418032504362\n",
      "step: 450; loss: 0.2745571876047325\n",
      "step: 500; loss: 0.2612577667747588\n",
      "step: 550; loss: 0.25026607702092507\n",
      "step: 600; loss: 0.24103888181635674\n",
      "step: 650; loss: 0.23318690516961418\n",
      "step: 700; loss: 0.22642494618485123\n",
      "step: 750; loss: 0.22053992332500796\n",
      "step: 800; loss: 0.2153698419338636\n",
      "step: 850; loss: 0.21078961273200197\n",
      "step: 900; loss: 0.20670128089743614\n",
      "step: 950; loss: 0.2030271619289043\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "for i in range(epoch):\n",
    "    y_hat = forward(train_X, theta,bias)\n",
    "    loss = cost_function(train_y , y_hat)\n",
    "    if i % 50 == 0:\n",
    "        print(f'step: {i}; loss: {loss}')\n",
    "    dw,db = gradient(train_X,train_y,y_hat)\n",
    "    theta -= lr * dw\n",
    "    bias -= lr * db\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
