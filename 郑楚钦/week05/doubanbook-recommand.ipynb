{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11135675,"sourceType":"datasetVersion","datasetId":6942952}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:25.978083Z","iopub.execute_input":"2025-03-27T12:10:25.978459Z","iopub.status.idle":"2025-03-27T12:10:25.986047Z","shell.execute_reply.started":"2025-03-27T12:10:25.978434Z","shell.execute_reply":"2025-03-27T12:10:25.985116Z"}},"outputs":[{"name":"stdout","text":"/kaggle/lib/kaggle/gcp.py\n/kaggle/input/doubanbook-top250/doubanbook_top250_comments.txt\n/kaggle/input/doubanbook-top250/doubanbook_top250_introduction.txt\n/kaggle/input/doubanbook-top250/stopwords.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"\ndef handle_data(handle, cells):\n    global headers\n    if len(cells) != 6:\n        pass\n    elif headers == None:\n        headers = cells\n        print(headers)\n    else:\n        item = {}\n        for i in range(6):\n            item[headers[i]] = cells[i]\n        handle(item)\n\ndef load_data(handle):\n    global headers\n    headers = None\n    with open('/kaggle/input/doubanbook-top250/doubanbook_top250_comments.txt', 'r') as in_file:\n        pre_line = [None]\n        while True:\n            line = in_file.readline()\n            if not line:\n                handle_data(handle,pre_line)\n                break\n            cells = line.strip().split('\\t', 5)\n            if pre_line[0] != cells[0] and len(cells) != 6 and len(pre_line) == 6:\n                pre_line[5] += line\n            else:\n                handle_data(handle,pre_line)\n                pre_line = cells\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:25.998280Z","iopub.execute_input":"2025-03-27T12:10:25.998639Z","iopub.status.idle":"2025-03-27T12:10:26.006219Z","shell.execute_reply.started":"2025-03-27T12:10:25.998612Z","shell.execute_reply":"2025-03-27T12:10:26.005347Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# 基于图书评论的推荐系统\n# TF-IDF\nimport jieba\n\nbook_comments = {}\ndef assemble(item):\n    book = item['book']\n    if book == '': return\n    global book_comments\n    comments = book_comments.get(book)\n    if comments == None:\n        comments = []\n        book_comments[book] = comments\n    words = jieba.lcut(item['body'])\n    comments.extend(words)\n        \n\nload_data(assemble)\nprint(len(book_comments))\nprint(book_comments.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:26.007503Z","iopub.execute_input":"2025-03-27T12:10:26.007837Z","iopub.status.idle":"2025-03-27T12:10:42.161884Z","shell.execute_reply.started":"2025-03-27T12:10:26.007809Z","shell.execute_reply":"2025-03-27T12:10:42.160907Z"}},"outputs":[{"name":"stdout","text":"['book', 'id', 'star', 'time', 'likenum', 'body']\n233\ndict_keys(['天才在左 疯子在右', '1Q84 BOOK 1', '悲伤逆流成河', '恶意', 'Harry Potter and the Deathly Hallows', '长安乱', '苏菲的世界', '许三观卖血记', '1995-2005夏至未至', '盗墓笔记', '霍乱时期的爱情', '三生三世 十里桃花', '基督山伯爵', '小时代1.0折纸时代', '洛丽塔', '1Q84 BOOK 2', '第一次的亲密接触', '神雕侠侣', '一座城池', '茶花女', '当我谈跑步时我谈些什么', '明朝那些事儿（贰）', '人类简史', '一個人住第5年', '明朝那些事儿（肆）', '寻路中国', '我们台湾这些年', '1Q84 BOOK 3', '摆渡人', '明朝那些事儿（伍）', '骆驼祥子', '盗墓笔记3', '麦琪的礼物', '格林童话全集', '水仙已乘鲤鱼去', '历史深处的忧虑', '金锁记', '草样年华', '刀锋', '飞鸟集', '七夜雪', '最初的爱情 最后的仪式', '拆掉思维里的墙', '明朝那些事儿（陆）', '追风筝的人', '小王子', '围城', '解忧杂货店', '活着', '白夜行', '挪威的森林', '嫌疑人X的献身', '三体', '不能承受的生命之轻', '红楼梦', '梦里花落知多少', '达·芬奇密码', '看见', '百年孤独', '1988：我想和这个世界谈谈', '何以笙箫默', '平凡的世界（全三部）', '简爱', '哈利·波特与魔法石', '三体Ⅱ', '飘', '送你一颗子弹', '三体Ⅲ', '傲慢与偏见', '倾城之恋', '三重门', '杜拉拉升职记', '明朝那些事儿（壹）', '哈利·波特与阿兹卡班的囚徒', '目送', '情人', '哈利·波特与密室', '万历十五年', '我们仨', '幻城', '致我们终将逝去的青春', '狼图腾', '微微一笑很倾城', '莲花', '哈利·波特与火焰杯', '边城', '月亮和六便士', '向左走·向右走', '穆斯林的葬礼', '从你的全世界路过', '天龙八部', '放学后', '哈利·波特与混血王子', '一个人的好天气', '哈利·波特与凤凰社', '喜宝', '岛上书店', '海边的卡夫卡', '文化苦旅', '窗边的小豆豆', '三国演义（全二册）', '黄金时代', '悟空传', '兄弟（上）', '呼啸山庄', '笑傲江湖（全四册）', '少有人走的路', '民主的细节', '亲爱的安德烈', '灿烂千阳', '老人与海', '遇见未知的自己', '一九八四·动物农场', '牧羊少年奇幻之旅', '福尔摩斯探案全集（上中下）', '素年锦时', '情书', '他的国', '彼岸花', '西决', '东方快车谋杀案', '这些都是你给我的爱', '这些人，那些事', '八月未央', '清醒纪', '一个陌生女人的来信', '蔡康永的说话之道', '偷影子的人', '陪安东尼度过漫长岁月', '沉默的大多数', '白鹿原', '芒果街上的小屋', '羊脂球', '鲁滨逊漂流记', '灌篮高手31', '撒哈拉的故事', '巴黎圣母院', '肖申克的救赎', '麦田里的守望者', '无声告白', '山楂树之恋', '华胥引（全二册）', '地下铁', '且听风吟', '钢铁是怎样炼成的', '红玫瑰与白玫瑰', '人生若只如初见', '人间失格', '鬼吹灯之精绝古城', '安徒生童话故事集', '呐喊', '小团圆', '泡沫之夏', '会有天使替我爱你', '1984', '年华是无效信', '幻夜', '在路上', '射雕英雄传（全四册）', '明朝那些事儿（1-9）', '月亮忘記了', '明朝那些事儿（叁）', '哭泣的骆驼', '原来你还在这里', '半生缘', '此间的少年', '货币战争', '佳期如梦', '无人生还', '了不起的盖茨比', '时间旅行者的妻子', '告别薇安', '常识', '爱你就像爱生命', '步步惊心', '皮囊', '二三事', '兄弟（下）', '孤独六讲', '乌合之众', '盗墓笔记2', '失恋33天', '动物农场', '左耳', '鹿鼎记（全五册）', '荆棘鸟', '左手倒影，右手年华。', '零下一度', '像少年啦飞驰', '被窝是青春的坟墓', '关于莉莉周的一切', '机器猫哆啦A梦23', '阿Q正传', '乖，摸摸头', '大地之灯', '如何阅读一本书', '当我们谈论爱情时我们在谈论什么', '尘埃落定', '东霓', '海贼王', '那些回不去的年少时光', '孩子你慢慢来', '橙', '悲惨世界（上中下）', '盗墓笔记4', '巴别塔之犬', '香水', '一只特立独行的猪', '局外人', '一个人的朝圣', '史蒂夫·乔布斯传', '看不见的城市', '长恨歌', '匆匆那年（上下）', '蔷薇岛屿', '我的路', '菊与刀', '球状闪电', '谁动了我的奶酪？', '曾有一个人，爱我如生命', '那些年，我们一起追的女孩', '伊豆的舞女', '世界尽头与冷酷仙境', '鬼吹灯之云南虫谷', '明朝那些事儿（柒）：大结局', '把时间当作朋友', '秘密', '天使与魔鬼', '佛祖在一号线', '倚天屠龙记(共四册)', '阿狸·梦之城堡', '杜拉拉2华年似水', '不朽'])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"with open('/kaggle/input/doubanbook-top250/stopwords.txt', 'r') as f:\n    stop_words = [line.strip() for line in f]\nprint(len(stop_words))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:42.163546Z","iopub.execute_input":"2025-03-27T12:10:42.163816Z","iopub.status.idle":"2025-03-27T12:10:42.170040Z","shell.execute_reply.started":"2025-03-27T12:10:42.163793Z","shell.execute_reply":"2025-03-27T12:10:42.169113Z"}},"outputs":[{"name":"stdout","text":"1165\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nbooks = []\ncomments = []\nfor b, c in book_comments.items():\n    books.append(b)\n    comments.append(' '.join(c))\nvectorizer = TfidfVectorizer(stop_words=stop_words)\ntfidf_matrix = vectorizer.fit_transform(comments)\nsimilarity_matrix = cosine_similarity(tfidf_matrix)\nprint(similarity_matrix[:5, :5], similarity_matrix.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:42.171401Z","iopub.execute_input":"2025-03-27T12:10:42.171713Z","iopub.status.idle":"2025-03-27T12:10:43.669468Z","shell.execute_reply.started":"2025-03-27T12:10:42.171687Z","shell.execute_reply":"2025-03-27T12:10:43.668473Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'aren', 'couldn', 'daren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mayn', 'mightn', 'mon', 'mustn', 'needn', 'oughtn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[[1.         0.12268639 0.13782096 0.09936095 0.07679552]\n [0.12268639 1.         0.12971906 0.1025389  0.09683428]\n [0.13782096 0.12971906 1.         0.11494365 0.11565774]\n [0.09936095 0.1025389  0.11494365 1.         0.07941307]\n [0.07679552 0.09683428 0.11565774 0.07941307 1.        ]] (233, 233)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\n\nbook_name = '杜拉拉升职记'\nbook_idx = books.index(book_name)\nrecommend_indices = np.argsort(-similarity_matrix[book_idx])[1:11]\nfor idx in recommend_indices:\n    print(f'《{books[idx]}》\\t\\t\\t相似度 {similarity_matrix[book_idx, idx]:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:43.670360Z","iopub.execute_input":"2025-03-27T12:10:43.670619Z","iopub.status.idle":"2025-03-27T12:10:43.677228Z","shell.execute_reply.started":"2025-03-27T12:10:43.670596Z","shell.execute_reply":"2025-03-27T12:10:43.675656Z"}},"outputs":[{"name":"stdout","text":"《杜拉拉2华年似水》\t\t\t相似度 0.7592\n《拆掉思维里的墙》\t\t\t相似度 0.1435\n《把时间当作朋友》\t\t\t相似度 0.1202\n《致我们终将逝去的青春》\t\t\t相似度 0.1141\n《如何阅读一本书》\t\t\t相似度 0.1110\n《达·芬奇密码》\t\t\t相似度 0.1103\n《遇见未知的自己》\t\t\t相似度 0.1103\n《时间旅行者的妻子》\t\t\t相似度 0.1085\n《失恋33天》\t\t\t相似度 0.1084\n《小时代1.0折纸时代》\t\t\t相似度 0.1015\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import numpy as np\n\n# bm25算法实现，输入为评论列表集合，k,b为超参数。输出所有评论的bm25结果矩阵\n# 输入：comments = [['a','b','c'],['a','b','d'],['a','b','e']]\n# 其中bm25[0] = [0.0, 0.0, 0.0, 0.0, 0.0]表示第一个评论的bm25值\n# 其中bm25[0][0] = 0.0表示a的bm25值为0.0\ndef bm25(comments, k=1.5, b=0.75):\n    # 计算文档总数\n    N = len(comments)\n    # 初始化文档长度列表和词频字典\n    doc_lengths = []\n    word_doc_freq = {}\n    doc_term_dict = [{} for _ in range(N)]\n\n    for i, comment in enumerate(comments):\n        # 记录文档长度\n        doc_lengths.append(len(comment))\n        unique_words = set()\n        for word in comment:\n            # 统计词频\n            doc_term_dict[i][word] = doc_term_dict[i].get(word, 0) + 1\n            unique_words.add(word)\n        # 统计包含该词的文档数量\n        for word in unique_words:\n            word_doc_freq[word] = word_doc_freq.get(word, 0) + 1\n\n    # 计算每个单词的平均文档长度\n    avg_doc_len = sum(doc_lengths) / N\n\n    # 构建词汇表\n    vocabulary = list(word_doc_freq.keys())\n    word_index = {word: idx for idx, word in enumerate(vocabulary)}\n\n    # 构建文档 - 词频矩阵\n    doc_term_matrix = np.zeros((N, len(vocabulary)))\n    for i in range(N):\n        for word, freq in doc_term_dict[i].items():\n            idx = word_index.get(word)\n            if idx is not None:\n                doc_term_matrix[i, idx] = freq\n\n    # 计算 idf 值\n    idf_numerator = N - np.array([word_doc_freq[word] for word in vocabulary]) + 0.5\n    idf_denominator = np.array([word_doc_freq[word] for word in vocabulary]) + 0.5\n    idf = np.log(idf_numerator / idf_denominator)\n    idf[idf_numerator <= 0] = 0  # 避免出现 nan 值\n\n    # 计算 bm25 值\n    doc_lengths = np.array(doc_lengths)\n    bm25_matrix = np.zeros((N, len(vocabulary)))\n    for i in range(N):\n        tf = doc_term_matrix[i]\n        bm25 = idf * (tf * (k + 1)) / (tf + k * (1 - b + b * doc_lengths[i] / avg_doc_len))\n        bm25_matrix[i] = bm25\n\n    # 根据原始评论顺序重新排列 bm25 值\n    final_bm25_matrix = []\n    for i, comment in enumerate(comments):\n        bm25_comment = []\n        for word in comment:\n            idx = word_index.get(word)\n            if idx is not None:\n                bm25_comment.append(bm25_matrix[i, idx])\n        final_bm25_matrix.append(bm25_comment)\n\n    # 找到最长的子列表长度\n    max_length = max(len(row) for row in final_bm25_matrix)\n    # 填充所有子列表到相同的长度\n    padded_matrix = [row + [0] * (max_length - len(row)) for row in final_bm25_matrix]\n    # 转换为 numpy 数组\n    final_bm25_matrix = np.array(padded_matrix)\n\n    return final_bm25_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:43.678071Z","iopub.execute_input":"2025-03-27T12:10:43.678388Z","iopub.status.idle":"2025-03-27T12:10:43.691867Z","shell.execute_reply.started":"2025-03-27T12:10:43.678365Z","shell.execute_reply":"2025-03-27T12:10:43.690918Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nbooks = []\ncomments = []\nfor b, c in book_comments.items():\n    books.append(b)\n    comments.append(c)\ntfidf_matrix = bm25(comments)\nsimilarity_matrix = cosine_similarity(tfidf_matrix)\nprint(similarity_matrix[:5, :5], similarity_matrix.shape)\n\nbook_name = '杜拉拉升职记'\nbook_idx = books.index(book_name)\nrecommend_indices = np.argsort(-similarity_matrix[book_idx])[1:11]\nfor idx in recommend_indices:\n    print(f'《{books[idx]}》\\t\\t\\t相似度 {similarity_matrix[book_idx, idx]:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T12:10:43.692922Z","iopub.execute_input":"2025-03-27T12:10:43.693250Z","iopub.status.idle":"2025-03-27T12:10:46.749448Z","shell.execute_reply.started":"2025-03-27T12:10:43.693217Z","shell.execute_reply":"2025-03-27T12:10:46.748607Z"}},"outputs":[{"name":"stdout","text":"[[1.         0.36988009 0.30820447 0.36946186 0.28358742]\n [0.36988009 1.         0.33040334 0.35787864 0.30823497]\n [0.30820447 0.33040334 1.         0.30906108 0.33358904]\n [0.36946186 0.35787864 0.30906108 1.         0.29413391]\n [0.28358742 0.30823497 0.33358904 0.29413391 1.        ]] (233, 233)\n《年华是无效信》\t\t\t相似度 0.4018\n《1995-2005夏至未至》\t\t\t相似度 0.3948\n《悲伤逆流成河》\t\t\t相似度 0.3871\n《幻城》\t\t\t相似度 0.3814\n《一座城池》\t\t\t相似度 0.3800\n《哈利·波特与魔法石》\t\t\t相似度 0.3794\n《草样年华》\t\t\t相似度 0.3784\n《当我们谈论爱情时我们在谈论什么》\t\t\t相似度 0.3764\n《一个人的好天气》\t\t\t相似度 0.3753\n《苏菲的世界》\t\t\t相似度 0.3741\n","output_type":"stream"}],"execution_count":18}]}