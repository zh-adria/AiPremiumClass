{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作业目标：\n",
    "# 使用sklearn数据集训练逻辑回归模型\n",
    "# 调整学习率，样本数据拆分比率，观察训练结果\n",
    "# 把模型训练参数保存到文件，在另一个代码中加载参数实现预测功能\n",
    "# 写代码的时候，先写注释，最好记住步骤和流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 训练数据与参数初始化\n",
    "# 经典鸢尾花数据集 ,每个样本 4个特征（花萼长度，花萼宽度，花瓣长度，花瓣宽度）\n",
    "X,y = load_iris(return_X_y=True)\n",
    "X = X[:100]  # 取前100个数据\n",
    "y = y[:100]  # 取前100个标签(0,1)\n",
    "# 数据拆分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数初始化\n",
    "# 权重参数\n",
    "theta = np.random.randn(1,4)  # shape (1, 4)\n",
    "bias = 0\n",
    "# 超参数\n",
    "lr = 0.25  # 学习率\n",
    "epochs = 4000  # 训练次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 模型推理函数\n",
    "def forward(x, theta, bias):\n",
    "    # 线性运算\n",
    "    z = np.dot(theta, x.T) + bias # shape (80,4)\n",
    "    # sigmoid\n",
    "    y_hat = 1 / (1 + np.exp(-z))  # shape (80,4)\n",
    "    return y_hat\n",
    "\n",
    "# 3. 计算损失函数\n",
    "def loss(y, y_hat):\n",
    "    e = 1e-8\n",
    "    return - y * np.log(y_hat + e) - (1 - y) * np.log(1 - y_hat + e)\n",
    "\n",
    "# 4. 计算梯度\n",
    "def calc_gradient(x,y,y_hat):\n",
    "    # 计算梯度\n",
    "    m = x.shape[-1]\n",
    "    # theta梯度计算\n",
    "    delta_theta = np.dot((y_hat - y), x) / m\n",
    "    # bias梯度计算\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    # 返回梯度\n",
    "    return delta_theta, delta_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.7975654717364464, acc: 0.5\n",
      "epoch: 100, loss: 4.609730538813763e-05, acc: 1.0\n",
      "epoch: 200, loss: 2.3127232217758366e-05, acc: 1.0\n",
      "epoch: 300, loss: 1.543941820931623e-05, acc: 1.0\n",
      "epoch: 400, loss: 1.158806978289327e-05, acc: 1.0\n",
      "epoch: 500, loss: 9.274493264829511e-06, acc: 1.0\n",
      "epoch: 600, loss: 7.73081811648163e-06, acc: 1.0\n",
      "epoch: 700, loss: 6.627499981063855e-06, acc: 1.0\n",
      "epoch: 800, loss: 5.799601561335777e-06, acc: 1.0\n",
      "epoch: 900, loss: 5.155420497289321e-06, acc: 1.0\n",
      "epoch: 1000, loss: 4.639901461038745e-06, acc: 1.0\n",
      "epoch: 1100, loss: 4.2179914251025094e-06, acc: 1.0\n",
      "epoch: 1200, loss: 3.866311670430055e-06, acc: 1.0\n",
      "epoch: 1300, loss: 3.5686709566829994e-06, acc: 1.0\n",
      "epoch: 1400, loss: 3.3135003898328165e-06, acc: 1.0\n",
      "epoch: 1500, loss: 3.0923137042239646e-06, acc: 1.0\n",
      "epoch: 1600, loss: 2.8987445885153453e-06, acc: 1.0\n",
      "epoch: 1700, loss: 2.7279235781866513e-06, acc: 1.0\n",
      "epoch: 1800, loss: 2.576062530376272e-06, acc: 1.0\n",
      "epoch: 1900, loss: 2.440170243244881e-06, acc: 1.0\n",
      "epoch: 2000, loss: 2.3178533423653908e-06, acc: 1.0\n",
      "epoch: 2100, loss: 2.2071740259711e-06, acc: 1.0\n",
      "epoch: 2200, loss: 2.1065465864415764e-06, acc: 1.0\n",
      "epoch: 2300, loss: 2.0146609119534183e-06, acc: 1.0\n",
      "epoch: 2400, loss: 1.9304251032692174e-06, acc: 1.0\n",
      "epoch: 2500, loss: 1.8529218552925085e-06, acc: 1.0\n",
      "epoch: 2600, loss: 1.7813748995712972e-06, acc: 1.0\n",
      "epoch: 2700, loss: 1.715122900555529e-06, acc: 1.0\n",
      "epoch: 2800, loss: 1.653598942570794e-06, acc: 1.0\n",
      "epoch: 2900, loss: 1.5963142590252596e-06, acc: 1.0\n",
      "epoch: 3000, loss: 1.5428452142902725e-06, acc: 1.0\n",
      "epoch: 3100, loss: 1.4928228039717894e-06, acc: 1.0\n",
      "epoch: 3200, loss: 1.4459241230681416e-06, acc: 1.0\n",
      "epoch: 3300, loss: 1.4018653847124594e-06, acc: 1.0\n",
      "epoch: 3400, loss: 1.3603961701295408e-06, acc: 1.0\n",
      "epoch: 3500, loss: 1.3212946642708518e-06, acc: 1.0\n",
      "epoch: 3600, loss: 1.2843636848596162e-06, acc: 1.0\n",
      "epoch: 3700, loss: 1.2494273551658695e-06, acc: 1.0\n",
      "epoch: 3800, loss: 1.2163283020095144e-06, acc: 1.0\n",
      "epoch: 3900, loss: 1.1849252845835681e-06, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 5. 模型训练\n",
    "for i in range(epochs):\n",
    "    # 前向计算\n",
    "    y_hat = forward(X_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(X_train, y_train, y_hat)\n",
    "    # 更新参数\n",
    "    theta = theta - lr * delta_theta\n",
    "    bias = bias - lr * delta_bias\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # [False,True,...,False] -> [0,1,...,0]\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08\n"
     ]
    }
   ],
   "source": [
    "# 6. 模型参数保存到另外一个文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
