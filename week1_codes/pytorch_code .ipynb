{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyNaNxxEOlKc",
        "outputId": "a498aa81-e23a-481a-81b4-20fd7ecf0dd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb 27 11:46:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             34W /   70W |     170MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLK8WIK9kGgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**梯度检查\n",
        "题目：检查模型中某些层的梯度是否正常更新。**"
      ],
      "metadata": {
        "id": "p7hozMtoOrxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 创建一个简单的模型\n",
        "model = nn.Linear(10, 1)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 创建输入和目标\n",
        "input = torch.randn(1, 10, requires_grad=True)\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "# 前向传播\n",
        "output = model(input)\n",
        "loss = criterion(output, target)\n",
        "\n",
        "# 反向传播\n",
        "loss.backward()\n",
        "\n",
        "# 检查梯度\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"参数 {name} 的梯度：\", param.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a56hCw6cOvq3",
        "outputId": "f08fe4e3-9d33-4af7-a67b-06ae5d4c1170"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "参数 weight 的梯度： tensor([[-2.7934,  3.3818, -7.3518,  0.8378,  2.2146, -0.0750, -3.9112,  3.3398,\n",
            "         -0.3331,  2.5052]])\n",
            "参数 bias 的梯度： tensor([-3.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**动态图操作\n",
        "题目：使用 torch.autograd 动态计算梯度。**"
      ],
      "metadata": {
        "id": "VVsvcNzpOyNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2 + 3 * x + 1\n",
        "\n",
        "# 计算梯度\n",
        "y.backward()\n",
        "\n",
        "# 查看梯度\n",
        "print(\"x 的梯度：\", x.grad)  # 输出 7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FRoeUe1O_s_",
        "outputId": "882d63fa-8ab2-44b5-97b1-71d29105250c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x 的梯度： tensor(7.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**模型调试与检查\n",
        "题目：检查模型的每一层输出的形状。**"
      ],
      "metadata": {
        "id": "A_iPcEcNPEU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 10, kernel_size=5),  # 输出尺寸：[batch, 10, 24, 24]\n",
        "    nn.MaxPool2d(2),                  # 输出尺寸：[batch, 10, 12, 12]\n",
        "    nn.Flatten(),                     # 展平后尺寸：[batch, 10 * 12 * 12] = [batch, 1440]\n",
        "    nn.Linear(1440, 50),              # 修正输入维度为 1440\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(50, 10)\n",
        ")\n",
        "\n",
        "# 创建一个虚拟输入\n",
        "input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "# 检查每一层的输出形状\n",
        "with torch.no_grad():\n",
        "    for layer in model:\n",
        "        input = layer(input)\n",
        "        print(f\"层 {layer.__class__.__name__} 的输出形状：\", input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IyJVpniPF2x",
        "outputId": "a99bd9a8-ba9d-4d19-b604-6243a71944ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "层 Conv2d 的输出形状： torch.Size([1, 10, 24, 24])\n",
            "层 MaxPool2d 的输出形状： torch.Size([1, 10, 12, 12])\n",
            "层 Flatten 的输出形状： torch.Size([1, 1440])\n",
            "层 Linear 的输出形状： torch.Size([1, 50])\n",
            "层 ReLU 的输出形状： torch.Size([1, 50])\n",
            "层 Linear 的输出形状： torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**自定义优化器\n",
        "题目：实现一个简单的自定义优化器（如梯度下降）。\n",
        "**"
      ],
      "metadata": {
        "id": "UQMT9iScPbRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class CustomOptimizer:\n",
        "    def __init__(self, params, lr=0.01):\n",
        "        self.params = list(params)\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for param in self.params:\n",
        "                param -= self.lr * param.grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for param in self.params:\n",
        "            if param.grad is not None:\n",
        "                param.grad.zero_()\n",
        "\n",
        "# 使用自定义优化器\n",
        "model = nn.Linear(10, 1)\n",
        "optimizer = CustomOptimizer(model.parameters(), lr=0.01)\n",
        "\n",
        "input = torch.randn(1, 10)\n",
        "target = torch.tensor([[1.0]])\n",
        "\n",
        "output = model(input)\n",
        "loss = F.mse_loss(output, target)\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "slu01ldTPcTq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**练习 1: 自定义 Autograd Function\n",
        "目标: 实现一个自定义的激活函数 LeakySwish：f(x) = x * sigmoid(x) + 0.1*x**"
      ],
      "metadata": {
        "id": "70hMR2oULmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "\n",
        "class LeakySwish(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        sigmoid = 1 / (1 + torch.exp(-x))\n",
        "        ctx.save_for_backward(x, sigmoid)\n",
        "        return x * sigmoid + 0.1 * x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, sigmoid = ctx.saved_tensors\n",
        "        sigmoid_grad = sigmoid * (1 - sigmoid)\n",
        "        dx = sigmoid + x * sigmoid_grad + 0.1\n",
        "        return grad_output * dx\n",
        "\n",
        "# 测试\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = LeakySwish.apply(x)\n",
        "y.backward(torch.ones_like(y))\n",
        "print(x.grad)  # 应显示自动计算的梯度"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coeuci_OLtrZ",
        "outputId": "4aff2330-d49d-44f3-aac6-0a3c295386b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0019, 0.9535, 0.8470])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**练习 2: 混合精度训练\n",
        "目标: 实现自动混合精度训练循环**"
      ],
      "metadata": {
        "id": "Cg8Oy1E8L3iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# 定义设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # 将图片转换为Tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 归一化\n",
        "])\n",
        "\n",
        "# 加载数据集\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 定义一个简单的模型\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # 展平\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNet().to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 混合精度训练\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# 训练循环\n",
        "model.train()\n",
        "for epoch in range(5):  # 训练 5 个 epoch\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():  # 使用混合精度\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()  # 缩放损失并反向传播\n",
        "        scaler.unscale_(optimizer)  # 取消缩放\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 梯度裁剪\n",
        "        scaler.step(optimizer)  # 更新优化器\n",
        "        scaler.update()  # 更新缩放器\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/5] completed.\")\n",
        "\n",
        "print(\"训练完成！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8paRxMhL5hQ",
        "outputId": "f6263a10-0005-4c00-c6a0-a79f7a354c06"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 472kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.19MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-51336c75c4e3>:40: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "<ipython-input-23-51336c75c4e3>:50: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # 使用混合精度\n",
            "/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] completed.\n",
            "Epoch [2/5] completed.\n",
            "Epoch [3/5] completed.\n",
            "Epoch [4/5] completed.\n",
            "Epoch [5/5] completed.\n",
            "训练完成！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**练习 3: 自定义内存高效的注意力机制\n",
        "目标: 实现一个分块的注意力计算**"
      ],
      "metadata": {
        "id": "ojQcgiYxM4dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def memory_efficient_attention(Q, K, V, chunk_size=64):\n",
        "    batch, heads, seq_len, dim = Q.shape\n",
        "    out = torch.zeros_like(V)\n",
        "    for i in range(0, seq_len, chunk_size):\n",
        "        Q_chunk = Q[:, :, i:i+chunk_size]\n",
        "        attn = torch.einsum('bhid,bhjd->bhij', Q_chunk, K)\n",
        "        attn = torch.softmax(attn / dim**0.5, dim=-1)\n",
        "        out[:, :, i:i+chunk_size] = torch.einsum('bhij,bhjd->bhid', attn, V)\n",
        "    return out\n",
        "\n",
        "# 测试\n",
        "Q = torch.randn(2, 4, 1024, 64).cuda()\n",
        "K = V = torch.randn_like(Q)\n",
        "output = memory_efficient_attention(Q, K, V)"
      ],
      "metadata": {
        "id": "C3OLxYijM9JQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**练习 4: 动态计算图操作\n",
        "目标: 在训练过程中动态修改计算图**"
      ],
      "metadata": {
        "id": "-fuP63cINZyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicGate(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.threshold = 0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        mask = (x > self.threshold).float()\n",
        "        # 动态修改反向传播行为\n",
        "        def backward_hook(grad):\n",
        "            # 梯度超过阈值时放大梯度\n",
        "            return grad * (1 + mask)\n",
        "        x.register_hook(backward_hook)\n",
        "        return x * mask\n",
        "\n",
        "# 测试\n",
        "gate = DynamicGate()\n",
        "x = torch.rand(3, requires_grad=True)\n",
        "y = gate(x)\n",
        "loss = y.sum()\n",
        "loss.backward()\n",
        "print(x.grad)  # 观察自定义梯度行为"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_YsnWOuNbEn",
        "outputId": "4a974b95-c706-498b-d0a9-7238327802e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**练习 5: 梯度裁剪的高级形式**"
      ],
      "metadata": {
        "id": "06Ipqo26NnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 定义一个简单的模型\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 10, kernel_size=5),  # 输出尺寸：24x24\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 输出尺寸：12x12\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1440, 50),  # 修正输入维度为 1440\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# 创建模型\n",
        "model = CustomModel()\n",
        "\n",
        "# 定义优化器\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 定义梯度裁剪参数\n",
        "params = [\n",
        "    {\"params\": model.features.parameters(), \"max_norm\": 1.0},\n",
        "    {\"params\": model.classifier.parameters(), \"max_norm\": 0.5}\n",
        "]\n",
        "\n",
        "# 模拟训练过程\n",
        "input = torch.randn(64, 1, 28, 28)  # 假设输入是 MNIST 数据集\n",
        "target = torch.randint(0, 10, (64,))  # 随机生成目标标签\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 前向传播\n",
        "output = model(input)\n",
        "loss = criterion(output, target)\n",
        "\n",
        "# 反向传播\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "# 对每个参数组分别进行梯度裁剪\n",
        "for group in params:\n",
        "    torch.nn.utils.clip_grad_norm_(group[\"params\"], max_norm=group[\"max_norm\"], norm_type=2)\n",
        "\n",
        "# 更新优化器\n",
        "optimizer.step()\n",
        "\n",
        "print(\"梯度裁剪完成！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnC_gHzNroS",
        "outputId": "790d5c97-3d92-4577-ac45-d0f63281fc24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "梯度裁剪完成！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVF0lPzyLVJE",
        "outputId": "3361fc8f-79a1-471a-84ea-7d90838d174b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgLqfUEkLVJH",
        "outputId": "db02f39e-e8be-421c-e9ec-cc8067f187ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array([[1,2],[3,4]])\n",
        "data2 = torch.from_numpy(np_array)\n",
        "data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ5CmZs4LVJH",
        "outputId": "8e134aab-19d3-47f5-d2b3-ee0290aa81e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data2.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzHRbZ5kLVJH",
        "outputId": "6c95d4bb-e830-47fd-9e1c-c87013b9c25b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7126, 0.7690],\n",
              "        [0.1867, 0.5486]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 通过已知张量维度，创建新张量\n",
        "data3 = torch.rand_like(data2, dtype=torch.float)\n",
        "data3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgvbG9cgLVJI",
        "outputId": "dde07483-8bbc-4185-bb48-725ebce2f8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8193, 0.4476, 0.9758],\n",
            "        [0.2281, 0.4020, 0.9419]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5L5uXJTLVJI",
        "outputId": "51c442c7-d132-4790-8693-10b7ab56a638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "tensor([[0.6518, 0.2467, 0.4258],\n",
            "        [0.6910, 0.5011, 0.0290],\n",
            "        [0.0081, 0.4381, 0.4377],\n",
            "        [0.3568, 0.6890, 0.5959],\n",
            "        [0.1497, 0.2263, 0.6815]])\n",
            "tensor([[-0.2172, -0.4301,  1.1281],\n",
            "        [ 0.8829,  1.7818, -0.4615],\n",
            "        [ 0.3353, -0.8969, -1.9054],\n",
            "        [-1.6914, -0.5239,  0.4264],\n",
            "        [-1.6923,  0.9537,  1.3282]])\n",
            "tensor([[ 0.1141, -1.4953, -1.2681],\n",
            "        [-1.7484, -0.1983, -0.3544],\n",
            "        [-1.1363,  0.1545, -1.4512],\n",
            "        [ 0.1336, -0.4788,  1.0420],\n",
            "        [ 1.7160, -0.7597,  0.3555]])\n",
            "tensor([ 1.0000,  1.4500,  1.9000,  2.3500,  2.8000,  3.2500,  3.7000,  4.1500,\n",
            "         4.6000,  5.0500,  5.5000,  5.9500,  6.4000,  6.8500,  7.3000,  7.7500,\n",
            "         8.2000,  8.6500,  9.1000,  9.5500, 10.0000])\n"
          ]
        }
      ],
      "source": [
        "# 基于现有tensor构建，但使用新值填充\n",
        "m = torch.ones(5,3, dtype=torch.double)\n",
        "n = torch.rand_like(m, dtype=torch.float)\n",
        "\n",
        "# 获取tensor的大小\n",
        "print(m.size()) # torch.Size([5,3])\n",
        "\n",
        "# 均匀分布\n",
        "print(torch.rand(5,3))\n",
        "# 标准正态分布\n",
        "print(torch.randn(5,3))\n",
        "# 离散正态分布\n",
        "print(torch.normal(mean=.0,std=1.0,size=(5,3)))\n",
        "# 线性间隔向量(返回一个1维张量，包含在区间start和end上均匀间隔的steps个点)\n",
        "print(torch.linspace(start=1,end=10,steps=21))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTma37QdLVJI",
        "outputId": "8ea2cc14-164a-4566-816c-c123a585dcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0O23uALVJI",
        "outputId": "877d16d1-8d05-4acc-f283-3e3967cb964f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8972, 0.8837, 0.5895, 0.3331],\n",
            "        [0.3943, 0.7598, 0.6205, 0.2740],\n",
            "        [0.3034, 0.0081, 0.7375, 0.7037]])\n",
            "cpu\n",
            "tensor([[0.8972, 0.8837, 0.5895, 0.3331],\n",
            "        [0.3943, 0.7598, 0.6205, 0.2740],\n",
            "        [0.3034, 0.0081, 0.7375, 0.7037]])\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# 检查pytorch是否支持GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    tensor = tensor.to(device)\n",
        "\n",
        "print(tensor)\n",
        "print(tensor.device)\n",
        "\n",
        "# mac上没有GPU，使用M系列芯片\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    tensor = tensor.to(device)\n",
        "\n",
        "print(tensor)\n",
        "print(tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5KVx8V3LVJI",
        "outputId": "15680f9f-fbf4-44f4-b7cf-f5cec2737818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ', tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "print('Last column:', tensor[..., -1])\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufK377xsLVJJ",
        "outputId": "3239f5d0-f7c0-475f-ebba-afa067a25112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
            "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
            "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
            "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.]])\n",
            "torch.Size([4, 12])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1 * 3)\n",
        "print(t1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPk2w9KnLVJJ",
        "outputId": "0404376c-21bf-4082-e882-e20fab811735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  4.,  9.],\n",
            "        [16., 25., 36.],\n",
            "        [49., 64., 81.]])\n",
            "tensor([[ 1.,  4.,  9.],\n",
            "        [16., 25., 36.],\n",
            "        [49., 64., 81.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "tensor = torch.arange(1,10, dtype=torch.float32).reshape(3, 3)\n",
        "\n",
        "# 计算两个张量之间矩阵乘法的几种方式。 y1, y2, y3 最后的值是一样的 dot\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "# print(y1)\n",
        "# print(y2)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "# print(y3)\n",
        "\n",
        "\n",
        "# 计算张量逐元素相乘的几种方法。 z1, z2, z3 最后的值是一样的。\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)\n",
        "\n",
        "print(z1)\n",
        "print(z3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u07ofVqSLVJJ",
        "outputId": "e667e786-9920-4bdb-e7ca-1d3185fc1a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXexXJWKLVJJ",
        "outputId": "a616b44e-1cc5-446e-96fc-6678f40bd9d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.],\n",
              "       [49., 64., 81.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "np_arr = z1.numpy()\n",
        "np_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLYHl6QBLVJJ",
        "outputId": "c4339f04-74db-4073-d24c-72d2a75d1633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]]) \n",
            "\n",
            "tensor([[ 6.,  7.,  8.],\n",
            "        [ 9., 10., 11.],\n",
            "        [12., 13., 14.]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "# tensor = tensor + 5\n",
        "# tensor += 5\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7D6_l-LVJJ",
        "outputId": "5abe1ca8-be35-4894-f0fb-67fa37356f6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  7.,  8.],\n",
              "        [ 9., 10., 11.],\n",
              "        [12., 13., 14.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lu3-frI-LcR_"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}