{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch搭建神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单实现\n",
    "import torch\n",
    "import torch.nn as nn  # 常用模块\n",
    "\n",
    "# X输入 shape(,784)\n",
    "# 隐藏层 shape(784,64)  # 参数矩阵 # 784个特征 64个神经元\n",
    "# 隐藏层 shape(64,)  # 偏置bias\n",
    "# 输出层 shape(64,10)  # 参数矩阵 # 64个神经元 10个类别\n",
    "# 输出层 shape(10,)  # 偏置bias\n",
    "# Y输出 shape(,10)  # 10个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### 隐藏层\n",
    "# 线性层\n",
    "linear = nn.Linear(in_features=784, out_features=64, bias=True)\n",
    "# 激活函数\n",
    "act = nn.Sigmoid()\n",
    "\n",
    "### 输出层\n",
    "linear2 = nn.Linear(in_features=64, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "# 模拟输入\n",
    "x = torch.randn(10, 784)\n",
    "out = linear(x)\n",
    "# print(out)\n",
    "out2 = act(out)\n",
    "# print(out2)\n",
    "out3 = linear2(out2)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "final = softmax(out3)\n",
    "print(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有结构串联\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "# 优化器（模型参数更新）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0114,  0.0268, -0.0140,  ...,  0.0265, -0.0329, -0.0336],\n",
       "         [ 0.0261, -0.0144,  0.0240,  ...,  0.0271,  0.0256,  0.0061],\n",
       "         [-0.0121,  0.0188, -0.0135,  ..., -0.0178,  0.0069,  0.0053],\n",
       "         ...,\n",
       "         [-0.0242,  0.0291,  0.0137,  ...,  0.0315, -0.0320, -0.0093],\n",
       "         [ 0.0153,  0.0081,  0.0100,  ..., -0.0181, -0.0296, -0.0011],\n",
       "         [ 0.0290, -0.0049, -0.0004,  ...,  0.0222,  0.0255, -0.0035]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0306, -0.0149, -0.0114,  0.0187,  0.0108, -0.0355, -0.0139,  0.0348,\n",
       "          0.0229, -0.0282, -0.0157, -0.0345, -0.0207, -0.0315, -0.0112, -0.0351,\n",
       "         -0.0173,  0.0277, -0.0129, -0.0338, -0.0070,  0.0008,  0.0080,  0.0009,\n",
       "          0.0243,  0.0274, -0.0071, -0.0178,  0.0087, -0.0354, -0.0038, -0.0120,\n",
       "         -0.0138,  0.0245, -0.0322,  0.0082,  0.0065, -0.0316, -0.0121, -0.0292,\n",
       "          0.0147, -0.0248, -0.0229, -0.0066, -0.0171, -0.0257,  0.0034, -0.0014,\n",
       "         -0.0153,  0.0070, -0.0030, -0.0344,  0.0059,  0.0061,  0.0033, -0.0262,\n",
       "         -0.0001, -0.0155, -0.0195, -0.0102, -0.0306,  0.0003,  0.0349,  0.0056],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0243,  0.0649,  0.0010, -0.0972, -0.0938, -0.0754, -0.0345,  0.0472,\n",
       "          -0.0642,  0.0773,  0.0172,  0.0539, -0.0439, -0.1065, -0.0598, -0.0935,\n",
       "          -0.1216, -0.1205, -0.0097,  0.0620,  0.0862,  0.0482,  0.1195,  0.1145,\n",
       "           0.1238,  0.0980,  0.0318,  0.0932,  0.0868, -0.1200,  0.0736, -0.0128,\n",
       "           0.0701, -0.0236,  0.0165, -0.1050, -0.0667, -0.1077,  0.0761,  0.0598,\n",
       "           0.0556, -0.0612,  0.0160,  0.0344,  0.0044,  0.0751, -0.1178,  0.0092,\n",
       "          -0.0952, -0.1140,  0.1104,  0.0242, -0.0399, -0.0743, -0.0869,  0.0643,\n",
       "          -0.0720, -0.0452, -0.1149,  0.0559, -0.0270, -0.0893, -0.1133, -0.0995],\n",
       "         [-0.0581, -0.0421,  0.0324, -0.0753,  0.0888,  0.0127, -0.0512,  0.0262,\n",
       "          -0.0033,  0.0886, -0.0978, -0.0509,  0.0994, -0.1165, -0.0453, -0.0240,\n",
       "           0.0055, -0.1145, -0.0867,  0.1025,  0.0584, -0.0728, -0.1126,  0.0265,\n",
       "           0.0743, -0.0158,  0.0360,  0.0388, -0.1067, -0.0783, -0.0017,  0.1085,\n",
       "          -0.0534,  0.0184, -0.0797, -0.1024,  0.0638,  0.0624,  0.0564,  0.0130,\n",
       "           0.1203, -0.0028, -0.0363, -0.0098, -0.0101,  0.0641, -0.1117, -0.1057,\n",
       "          -0.0109, -0.1179,  0.1055,  0.1070,  0.0183, -0.0332,  0.0305, -0.0686,\n",
       "           0.1188, -0.0201,  0.0100,  0.0517,  0.0970,  0.0321, -0.0630, -0.0298],\n",
       "         [ 0.0665, -0.1052, -0.0473, -0.0960, -0.1202, -0.0557,  0.0607, -0.0667,\n",
       "           0.0789, -0.0332,  0.1015, -0.0999,  0.1160, -0.0681,  0.0381, -0.0377,\n",
       "           0.1085, -0.0058, -0.0601, -0.0225, -0.0587,  0.0896, -0.0587,  0.0309,\n",
       "           0.0417,  0.0580,  0.0700,  0.0178,  0.0185, -0.0491,  0.0846, -0.0541,\n",
       "           0.1189,  0.1203, -0.1035, -0.0316,  0.0108, -0.0872,  0.0626,  0.0968,\n",
       "           0.0811,  0.0034, -0.1107, -0.1107,  0.0997, -0.0737, -0.0515,  0.1137,\n",
       "           0.0545,  0.0094, -0.0008,  0.0503, -0.0551,  0.1082,  0.0701, -0.0592,\n",
       "          -0.0913, -0.0664, -0.1116, -0.1051,  0.0089, -0.0617,  0.0386, -0.1175],\n",
       "         [ 0.0799, -0.0471,  0.0146,  0.0670,  0.0687,  0.0521,  0.0441,  0.1117,\n",
       "           0.0605,  0.0362,  0.0101, -0.0454,  0.0316,  0.0809,  0.0982,  0.0466,\n",
       "          -0.0008, -0.0170,  0.0982, -0.0155, -0.0231, -0.0633,  0.1074, -0.1223,\n",
       "           0.0870, -0.0823, -0.0890,  0.0176, -0.0427,  0.0362,  0.0274, -0.0656,\n",
       "          -0.0324, -0.0264,  0.0975,  0.0516, -0.0935,  0.0975, -0.0833, -0.1072,\n",
       "           0.0097,  0.0869,  0.0668, -0.0331, -0.1161, -0.1106,  0.0290,  0.0352,\n",
       "           0.0426, -0.0937, -0.0157,  0.1099,  0.0964,  0.0859, -0.0313,  0.0424,\n",
       "           0.0862, -0.1009, -0.0262, -0.1089,  0.0831,  0.0627, -0.0123, -0.1023],\n",
       "         [ 0.0064, -0.0806,  0.0945, -0.1096, -0.0148,  0.1236, -0.0078, -0.0914,\n",
       "          -0.0328, -0.0455, -0.0973,  0.1153,  0.0152, -0.1248, -0.0721,  0.0085,\n",
       "           0.1018,  0.1245,  0.0446,  0.1128,  0.0976,  0.0222, -0.1020,  0.0726,\n",
       "           0.0419, -0.0543,  0.0887,  0.0720,  0.0395,  0.0180,  0.0858, -0.0017,\n",
       "          -0.0992,  0.0018, -0.0412,  0.0714,  0.1157,  0.0317,  0.1044, -0.0622,\n",
       "           0.0559,  0.0487, -0.0087, -0.0894,  0.1120,  0.0806, -0.1248, -0.0954,\n",
       "           0.0583, -0.0580, -0.0091, -0.1017,  0.0713,  0.0373, -0.0193, -0.0733,\n",
       "           0.0759,  0.1148, -0.0616,  0.0408, -0.1194,  0.0952, -0.0542, -0.0423],\n",
       "         [-0.1143,  0.0673,  0.0373, -0.0769, -0.1140,  0.1127, -0.1123,  0.0914,\n",
       "           0.0521, -0.1236,  0.1110, -0.0994,  0.0937,  0.0785, -0.0345, -0.0019,\n",
       "          -0.0677,  0.0132, -0.0702,  0.0893, -0.1047,  0.0079, -0.0515,  0.0942,\n",
       "          -0.0673,  0.0921, -0.0465,  0.0864,  0.0463,  0.0841,  0.0696, -0.0659,\n",
       "          -0.0051, -0.0610, -0.0057,  0.0777,  0.0315, -0.0786,  0.1235,  0.0757,\n",
       "           0.0376, -0.0154, -0.0504,  0.0630, -0.0687, -0.0750, -0.0244,  0.0433,\n",
       "          -0.0886,  0.0592,  0.1100,  0.1106,  0.0187,  0.1020, -0.0976,  0.0677,\n",
       "          -0.0304,  0.0451, -0.0977,  0.0349,  0.0747, -0.1120,  0.0200,  0.0179],\n",
       "         [ 0.0424,  0.0221, -0.1029,  0.0693, -0.0339,  0.0477, -0.0417, -0.0438,\n",
       "           0.0391,  0.0428,  0.0085, -0.0062, -0.0042,  0.0844,  0.0132, -0.0148,\n",
       "           0.0784, -0.0335, -0.0239,  0.0612,  0.1053,  0.0472, -0.1123,  0.0033,\n",
       "          -0.0155,  0.1044,  0.0726, -0.0831, -0.1140, -0.0043,  0.0187,  0.1054,\n",
       "           0.0153,  0.0649,  0.0788,  0.0548, -0.0152,  0.0139,  0.0954, -0.0312,\n",
       "           0.1218, -0.0141, -0.1089,  0.0833, -0.0048, -0.0330,  0.0085, -0.0856,\n",
       "           0.0673, -0.1241, -0.0205,  0.0127,  0.0666,  0.0539,  0.0290, -0.0026,\n",
       "          -0.0126, -0.0988,  0.0471, -0.0669, -0.1198,  0.1130, -0.0126, -0.0652],\n",
       "         [ 0.0845, -0.0183,  0.0750, -0.0771,  0.0935,  0.0983, -0.0024, -0.0903,\n",
       "          -0.0314,  0.0889,  0.0591, -0.0853, -0.0091,  0.0076,  0.0053,  0.0250,\n",
       "          -0.0696,  0.0460,  0.0085,  0.1224,  0.1066,  0.0638, -0.0310, -0.0352,\n",
       "          -0.0189, -0.1053,  0.0556, -0.0870, -0.0261, -0.0432,  0.0161, -0.0688,\n",
       "          -0.0969, -0.0731, -0.0680, -0.0993, -0.0417,  0.0941, -0.0786, -0.0806,\n",
       "          -0.0740,  0.0616,  0.0784, -0.0957,  0.1051,  0.0391,  0.0761,  0.0191,\n",
       "          -0.0977,  0.0313, -0.0624, -0.1203, -0.0361, -0.1130, -0.0994, -0.0269,\n",
       "          -0.0113, -0.0854, -0.0006,  0.0141, -0.0497, -0.0532,  0.0975,  0.0739],\n",
       "         [ 0.0483, -0.1070,  0.0348, -0.0401, -0.0533,  0.1117,  0.1096, -0.0747,\n",
       "          -0.0583, -0.0860, -0.0857,  0.0008, -0.0108, -0.1036,  0.0538,  0.1135,\n",
       "          -0.0793,  0.0709,  0.0973, -0.0090,  0.0914, -0.0227, -0.0729,  0.0468,\n",
       "          -0.0091, -0.0654, -0.0510, -0.0266,  0.1142, -0.0709,  0.0891,  0.1162,\n",
       "          -0.1025, -0.0478,  0.1100,  0.0946, -0.0018, -0.0359, -0.0514,  0.0403,\n",
       "          -0.0646, -0.0243, -0.0036, -0.0616, -0.1050, -0.1219, -0.0934,  0.0527,\n",
       "           0.0629, -0.0493, -0.0504,  0.0908,  0.0820, -0.0405,  0.0043,  0.1144,\n",
       "           0.0589,  0.1169, -0.1156,  0.0115,  0.0019, -0.0949, -0.0173,  0.0257],\n",
       "         [ 0.0336, -0.0454, -0.0912, -0.0151,  0.0775,  0.0991, -0.0757,  0.0912,\n",
       "           0.0040,  0.0590, -0.0756,  0.1064, -0.0303,  0.0911,  0.0906, -0.1215,\n",
       "          -0.0083, -0.0590, -0.0580, -0.0716, -0.0885, -0.1249,  0.0988, -0.0059,\n",
       "          -0.0077, -0.0178, -0.0458, -0.1076,  0.0738, -0.0325, -0.1117,  0.1111,\n",
       "           0.1096,  0.0954, -0.0352,  0.1108, -0.0857,  0.0795,  0.0106,  0.0393,\n",
       "          -0.0235, -0.0687,  0.0422, -0.1042,  0.0510, -0.0391,  0.0900,  0.0096,\n",
       "           0.0395,  0.0563, -0.0862, -0.0460, -0.0225,  0.0556,  0.0910,  0.1236,\n",
       "           0.0305,  0.0993, -0.0860, -0.0668, -0.0529,  0.0410, -0.1018,  0.0054]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1249,  0.0695,  0.0851, -0.0507, -0.0955, -0.0868,  0.0251, -0.0973,\n",
       "         -0.0175,  0.1017], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in model.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
