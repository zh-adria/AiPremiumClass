{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy基础练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 7., 8.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([2,3,7,8])\n",
    "arr\n",
    "brr = np.array([2,3,7,8],float)\n",
    "brr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([(1, 2, 3),(4,5,6),(7,8,9)])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.zeros((4,6), dtype=np.float32)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. ,\n",
       "       7.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成等差数列\n",
    "a2 = np.arange(1,8, 0.5) \n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成单位矩阵\n",
    "a3 = np.eye(3)\n",
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47205081, 0.19003876, 0.05467443])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4 = np.random.random(3)  # 模型运算参数初始值\n",
    "a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33299428,  0.27168729, -0.06387473, -0.05242816, -0.16083272])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正态分布的随机值\n",
    "a5 = np.random.normal(0, 0.2, 5)\n",
    "a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n"
     ]
    }
   ],
   "source": [
    "a6 = np.array([(1,2), (3,4), (5,6)])\n",
    "print(a6[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "3 4\n",
      "5 6\n"
     ]
    }
   ],
   "source": [
    "a7 = np.array([(1,2), (3,4), (5,6)])\n",
    "# i,j = a7[0]\n",
    "for i,j in a7:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 2\n",
      "shape: (3, 3)\n",
      "size 9\n",
      "dtype int32\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 创建一个二维数组\n",
    "a = np.array([(1,2,3), (4,5,6), (7,8,9)])\n",
    "\n",
    "# 打印数组的维度信息\n",
    "print(\"ndim:\", a.ndim)\n",
    "# 打印数组的形状信息\n",
    "print(\"shape:\", a.shape)\n",
    "# 打印数组的元素总数\n",
    "print(\"size\", a.size)\n",
    "# 打印数组元素的数据类型\n",
    "print(\"dtype\", a.dtype)\n",
    "print((1,2,3) in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "(9,)\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]\n",
      "\n",
      " [[7]\n",
      "  [8]\n",
      "  [9]]]\n",
      "(3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "a7 = np.arange(1,10)\n",
    "print(a7)\n",
    "print(a7.shape)\n",
    "\n",
    "a7 = a7.reshape(3,3,1)  # 维度大小乘积 == 元素个数\n",
    "print(a7)\n",
    "\n",
    "print(a7.shape)  # 高维矩阵，每个维度都有含义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "# 数组的转置（行转列）\n",
    "print(a)\n",
    "a = a.T\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 7 2 5 8 3 6 9]\n"
     ]
    }
   ],
   "source": [
    "# 展平\n",
    "a = a.flatten()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新增维度\n",
    "a8 = np.array([(1,2), (3,4), (5,6)])\n",
    "a8 = a8[:,:,np.newaxis]\n",
    "a8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[-1  1]\n",
      " [-1  1]]\n",
      "\n",
      "[[0. 2.]\n",
      " [0. 2.]]\n",
      "\n",
      "[[2. 0.]\n",
      " [2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 数组运算\n",
    "a = np.ones((2,2))\n",
    "b = np.array([(-1,1),(-1,1)])\n",
    "print(a)\n",
    "print(b)\n",
    "print()\n",
    "print(a+b)\n",
    "print()\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum() # 所有元素之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有元素之积\n",
    "a.prod() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.0\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "# 均值、方差、标准差\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(np.mean(a))\n",
    "print(np.var(a))\n",
    "print(np.std(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argmax: 2\n",
      "argmin: 0\n",
      "ceil: [2. 3. 6.]\n",
      "floor: [1. 2. 5.]\n",
      "rint: [2. 3. 6.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1.5, 2.8, 5.9])\n",
    "print(\"argmax:\", a.argmax()) # 最大值的索引\n",
    "print(\"argmin:\", a.argmin()) # 最小值的索引\n",
    "\n",
    "print(\"ceil:\", np.ceil(a))  # 向上取整\n",
    "print(\"floor:\", np.floor(a)) # 向下取整\n",
    "print(\"rint:\", np.rint(a))  # 四舍五入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 16, 22, 28, 31, 31, 48])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([16,31,12,28,22,31,48])\n",
    "a.sort()  # 排序\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵 1:\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "矩阵 2:\n",
      "[[5. 6.]\n",
      " [7. 8.]]\n",
      "使用 np.dot 得到的矩阵乘法结果:\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n",
      "使用 @ 运算符得到的矩阵乘法结果:\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n",
      "1.0 * 5.0 = 5.0\n",
      "2.0 * 7.0 = 14.0\n",
      "结果矩阵[1,1]:19.0\n",
      "\n",
      "1.0 * 6.0 = 6.0\n",
      "2.0 * 8.0 = 16.0\n",
      "结果矩阵[1,2]:22.0\n",
      "\n",
      "3.0 * 5.0 = 15.0\n",
      "4.0 * 7.0 = 28.0\n",
      "结果矩阵[2,1]:43.0\n",
      "\n",
      "3.0 * 6.0 = 18.0\n",
      "4.0 * 8.0 = 32.0\n",
      "结果矩阵[2,2]:50.0\n",
      "\n",
      "手动推演结果:\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义两个简单的矩阵\n",
    "m1 = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
    "m2 = np.array([[5, 6], [7, 8]], dtype=np.float32)\n",
    "\n",
    "# 使用 np.dot 进行矩阵乘法\n",
    "result_dot = np.dot(m1, m2)\n",
    "\n",
    "# 使用 @ 运算符进行矩阵乘法\n",
    "result_at = m1 @ m2\n",
    "\n",
    "print(\"矩阵 1:\")\n",
    "print(m1)\n",
    "print(\"矩阵 2:\")\n",
    "print(m2)\n",
    "print(\"使用 np.dot 得到的矩阵乘法结果:\")\n",
    "print(result_dot)\n",
    "print(\"使用 @ 运算符得到的矩阵乘法结果:\")\n",
    "print(result_at)\n",
    "\n",
    "# 创建一个全零矩阵，用于存储手动推演的结果\n",
    "# 结果矩阵的行数等于 matrix1 的行数，列数等于 matrix2 的列数\n",
    "manual_result = np.zeros((m1.shape[0], m2.shape[1]), dtype=np.float32)\n",
    "\n",
    "# 外层循环：遍历 matrix1 的每一行\n",
    "# i 表示结果矩阵的行索引\n",
    "for i in range(m1.shape[0]):\n",
    "    # 中层循环：遍历 matrix2 的每一列\n",
    "    # j 表示结果矩阵的列索引\n",
    "    for j in range(m2.shape[1]):\n",
    "        # 初始化当前位置的结果为 0\n",
    "        manual_result[i, j] = 0\n",
    "        # 内层循环：计算 matrix1 的第 i 行与 matrix2 的第 j 列对应元素的乘积之和\n",
    "        # k 表示参与乘法运算的元素索引\n",
    "        for k in range(m1.shape[1]):\n",
    "            # 打印当前正在计算的元素\n",
    "            print(f\"{m1[i, k]} * {m2[k, j]} = {m1[i, k] * m2[k, j]}\")\n",
    "            # 将 matrix1 的第 i 行第 k 列元素与 matrix2 的第 k 行第 j 列元素相乘，并累加到结果矩阵的相应位置\n",
    "            manual_result[i, j] += m1[i, k] * m2[k, j]\n",
    "        # 打印当前位置计算完成后的结果\n",
    "        print(f\"结果矩阵[{i+1},{j+1}]:{manual_result[i, j]}\\n\")\n",
    "\n",
    "print(\"手动推演结果:\")\n",
    "print(manual_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件操作\n",
    "np.save('result.npy',a)\n",
    "np.savetxt('rt.txt',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12. 16. 22. 28. 31. 31. 48.]\n",
      "[12 16 22 28 31 31 48]\n"
     ]
    }
   ],
   "source": [
    "# 读取\n",
    "print(np.loadtxt('rt.txt'))\n",
    "print(np.load('result.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy广播机制\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [1, 3],\n",
       "       [2, 4],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([(1,2), (2,2), (3,3), (4,4)])  # shape(4,2)\n",
    "b = np.array([-1,1]) # shape(2,)\n",
    "# b = b.reshape((1,2))\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch基础\n",
    "https://pytorch.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array([[1,2],[3,4]])\n",
    "data2 = torch.from_numpy(np_array)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2031, 0.3945],\n",
       "        [0.8128, 0.0370]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过已知张量维度，创建新张量\n",
    "data3 = torch.rand_like(data2, dtype=torch.float)\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3257, 0.0502, 0.1339],\n",
      "        [0.0546, 0.8730, 0.6689]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[0.5632, 0.2424, 0.3779],\n",
      "        [0.7391, 0.8392, 0.3213],\n",
      "        [0.5462, 0.1749, 0.9052],\n",
      "        [0.0591, 0.5994, 0.9861],\n",
      "        [0.2490, 0.4822, 0.8544]])\n",
      "tensor([[-2.3712,  0.0187,  1.5363],\n",
      "        [-0.6087,  1.2279,  0.8016],\n",
      "        [ 0.2634,  0.3633,  0.9317],\n",
      "        [-0.5238,  1.4638, -1.3183],\n",
      "        [-0.2456,  1.9411,  1.6753]])\n",
      "tensor([[-0.7125, -0.0407, -0.0273],\n",
      "        [ 1.3431,  0.0566,  2.0050],\n",
      "        [-1.0421,  0.2504,  0.4675],\n",
      "        [ 0.5320, -0.9218,  0.6438],\n",
      "        [-0.0193,  1.1104,  2.8057]])\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    }
   ],
   "source": [
    "# 基于现有tensor构建，但使用新值填充\n",
    "m = torch.ones(5,3, dtype=torch.double)\n",
    "n = torch.rand_like(m, dtype=torch.float)\n",
    "\n",
    "# 获取tensor的大小\n",
    "print(m.size()) # torch.Size([5,3])\n",
    "\n",
    "# 均匀分布\n",
    "print(torch.rand(5,3))\n",
    "# 标准正态分布\n",
    "print(torch.randn(5,3))\n",
    "# 离散正态分布\n",
    "print(torch.normal(mean=.0,std=1.0,size=(5,3)))\n",
    "# 线性间隔向量(返回一个1维张量，包含在区间start和end上均匀间隔的steps个点)\n",
    "print(torch.linspace(start=1,end=10,steps=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9090, 0.9235, 0.8127, 0.1726],\n",
      "        [0.5807, 0.2368, 0.9741, 0.8804],\n",
      "        [0.1892, 0.3420, 0.2204, 0.0870]])\n",
      "cpu\n",
      "tensor([[0.9090, 0.9235, 0.8127, 0.1726],\n",
      "        [0.5807, 0.2368, 0.9741, 0.8804],\n",
      "        [0.1892, 0.3420, 0.2204, 0.0870]])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 检查pytorch是否支持GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor = tensor.to(device)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.device)\n",
    "\n",
    "# mac上没有GPU，使用M系列芯片\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    tensor = tensor.to(device)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3., 3., 0., 3., 3.]])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1 * 3)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.],\n",
      "        [49., 64., 81.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.arange(1,10, dtype=torch.float32).reshape(3, 3)\n",
    "\n",
    "# 计算两个张量之间矩阵乘法的几种方式。 y1, y2, y3 最后的值是一样的 dot\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "# print(y1)\n",
    "# print(y2)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "# print(y3)\n",
    "\n",
    "\n",
    "# 计算张量逐元素相乘的几种方法。 z1, z2, z3 最后的值是一样的。\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(z1)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "45.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.],\n",
       "       [49., 64., 81.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr = z1.numpy()\n",
    "np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]]) \n",
      "\n",
      "tensor([[ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.],\n",
      "        [12., 13., 14.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "# tensor = tensor + 5\n",
    "# tensor += 5\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juncheng\\AppData\\Local\\Temp\\ipykernel_31208\\995729796.py:14: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\Users\\dev-admin\\Desktop\\build42\\libtorch_1738271764196\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3687.)\n",
      "  result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 机器上需要安装https://graphviz.org/download/ 否则报错\n",
    "# pytorch计算图可视化\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 定义矩阵 A，向量 b 和常数 c\n",
    "A = torch.randn(10, 10,requires_grad=True)  # requires_grad=True 表示我们要对 A 求导\n",
    "b = torch.randn(10,requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn(10, requires_grad=True)\n",
    "\n",
    "\n",
    "# 计算 x^T * A + b * x + c\n",
    "result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n",
    "\n",
    "# 生成计算图节点\n",
    "dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})\n",
    "# 绘制计算图\n",
    "dot.render('expression', format='png', cleanup=True, view=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
