{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "(1, 4)\n",
      "epoch: 0, loss: 7.415085268065284, acc: 0.5\n",
      "epoch: 5, loss: 0.0027282498942554846, acc: 1.0\n",
      "epoch: 10, loss: 0.0012884882109703549, acc: 1.0\n",
      "epoch: 15, loss: 0.0009285480500266564, acc: 1.0\n",
      "epoch: 20, loss: 0.0007813701891594791, acc: 1.0\n",
      "epoch: 25, loss: 0.0007102128671853819, acc: 1.0\n",
      "epoch: 30, loss: 0.0006725369103249859, acc: 1.0\n",
      "epoch: 35, loss: 0.0006510568951970722, acc: 1.0\n",
      "epoch: 40, loss: 0.000637776396136068, acc: 1.0\n",
      "epoch: 45, loss: 0.0006287497491211307, acc: 1.0\n",
      "epoch: 50, loss: 0.0006219672035539338, acc: 1.0\n",
      "epoch: 55, loss: 0.0006163888478594489, acc: 1.0\n",
      "epoch: 60, loss: 0.0006114720757570055, acc: 1.0\n",
      "epoch: 65, loss: 0.0006069322018715038, acc: 1.0\n",
      "epoch: 70, loss: 0.0006026190988791004, acc: 1.0\n",
      "epoch: 75, loss: 0.0005984530967617968, acc: 1.0\n",
      "epoch: 80, loss: 0.0005943915299647656, acc: 1.0\n",
      "epoch: 85, loss: 0.0005904112286245324, acc: 1.0\n",
      "epoch: 90, loss: 0.0005864993313874833, acc: 1.0\n",
      "epoch: 95, loss: 0.0005826484518099221, acc: 1.0\n",
      "[[-0.87007866 -3.34173697  4.50236343  3.50181249]]\n",
      "-0.01680663922095228\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "x_train = X[:100]\n",
    "y_train = y[:100]\n",
    "# 样本集\n",
    "print(x_train.shape)\n",
    "# 分类集\n",
    "print(y_train.shape)\n",
    "\n",
    "# 权重参数\n",
    "theta = np.random.randn(1,4)\n",
    "print(theta.shape)\n",
    "bias = 0\n",
    "# 超参数\n",
    "lr = 0.1\n",
    "epochs = 100  # 训练次数\n",
    "\n",
    "# 模型计算函数\n",
    "def forward(x, theta, bias):\n",
    "    # 进行线性运算\n",
    "    z = np.dot(theta, x.T) + bias\n",
    "    # sigmoid 转为伯努利函数\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    return y_hat\n",
    "\n",
    "# 损失函数\n",
    "def loss(y, y_hat):\n",
    "    e = 1e-8\n",
    "    return - y * np.log(y_hat + e) - (1 - y) * np.log(1 - y_hat + e)\n",
    "\n",
    "# 计算梯度\n",
    "def calc_gradient(x, y, y_hat):\n",
    "    # 计算梯度\n",
    "    # 取出单行数据中的样本数量\n",
    "    m = x.shape[-1]\n",
    "    # theta 梯度计算\n",
    "    delta_theta = np.dot((y_hat - y), x) / m\n",
    "    # bias 梯度计算\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    # 将梯度返回\n",
    "    return delta_theta, delta_bias\n",
    "\n",
    "# 训练模型\n",
    "for i in range(epochs):\n",
    "    # 向前计算y_hat\n",
    "    y_hat = forward(x_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(x_train, y_train, y_hat)\n",
    "    # 更新 theta\n",
    "    theta = theta - lr * delta_theta\n",
    "    # 更新 bias\n",
    "    bias = bias - lr * delta_bias\n",
    "    if i % 5 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # [False,True,...,False] -> [0,1,...,0]\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")\n",
    "print(theta)\n",
    "print(bias)\n",
    "np.savez('modelArgs', theta = theta, bias = bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
