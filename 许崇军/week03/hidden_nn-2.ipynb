{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##增加隐藏层，观察结果变化\\\n",
    "linear(784,128)--(128,64)--(64,32)--(32,10) 效果不好，重新调整隐藏层观察\\\n",
    "1、linear(784,128)--(128,128)--(128,64)--(32,10) 逐步增加层数，观察loss变化---无明显变化，准确率10%\\\n",
    "2、linear(784,128)--(128,128)--(128,64)--(32,10)   使用ReLU替换Sigmoid 观察变化---下降明显收敛快，准确率79.47%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1导包\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim\n",
    "from  torch.utils.data import DataLoader\n",
    "import torch.utils.data.dataset as dataset\n",
    "from torchvision.transforms  import ToTensor    \n",
    "from torchvision.datasets import KMNIST  \n",
    "\n",
    "#2定义超参数\n",
    "batch_size = 128 \n",
    "epochs = 20\n",
    "learnrate = 0.01\n",
    "\n",
    "#3加载数据集\n",
    "train_data =KMNIST(root='./KMNIST_data',train=True,transform=ToTensor(),download=True)\n",
    "test_data = KMNIST(root='./KMNIST_data',train=False,transform=ToTensor(),download=True)\n",
    "#4创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#5定义神经网络模型（使用Sequential容器）\n",
    "# model =nn.Sequential(\n",
    "#     nn.Linear(784,128),   # 输入层 → 第一隐藏层\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.Linear(128,128),   # 第一隐藏层 → 第二隐藏层\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.Linear(128,64),  # 第二隐藏层 → 第三隐藏层\n",
    "#     nn.Sigmoid(),\n",
    "#     nn.Linear(64,10),  # 第三隐藏层 → 输出层\n",
    "# )\n",
    "\n",
    "model =nn.Sequential(\n",
    "    nn.Linear(784,128),   # 输入层 → 第一隐藏层\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,128),   # 第一隐藏层 → 第二隐藏层\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),  # 第二隐藏层 → 第三隐藏层\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,10),  # 第三隐藏层 → 输出层\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 定义损失函数和优化器\n",
    "loss_func =nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learnrate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,loss:2.269808769226074\n",
      "Epoch:1,loss:1.9512723684310913\n",
      "Epoch:2,loss:1.3330949544906616\n",
      "Epoch:3,loss:0.9335116744041443\n",
      "Epoch:4,loss:0.8945534825325012\n",
      "Epoch:5,loss:0.8162932991981506\n",
      "Epoch:6,loss:0.684267520904541\n",
      "Epoch:7,loss:0.5806081891059875\n",
      "Epoch:8,loss:0.38710787892341614\n",
      "Epoch:9,loss:0.4797968566417694\n",
      "Epoch:10,loss:0.43800923228263855\n",
      "Epoch:11,loss:0.35088837146759033\n",
      "Epoch:12,loss:0.3451828062534332\n",
      "Epoch:13,loss:0.37287139892578125\n",
      "Epoch:14,loss:0.325838565826416\n",
      "Epoch:15,loss:0.34721359610557556\n",
      "Epoch:16,loss:0.2092784196138382\n",
      "Epoch:17,loss:0.42420077323913574\n",
      "Epoch:18,loss:0.3437977135181427\n",
      "Epoch:19,loss:0.26054903864860535\n"
     ]
    }
   ],
   "source": [
    "#7 模型训练\n",
    "for epoch in range(epochs):\n",
    "    for data,target in train_loader:\n",
    "        result = model(data.reshape(-1,784))\n",
    "        loss = loss_func(result,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch:{epoch},loss:{loss.item()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#第一种情况的loss变化\\\n",
    "Epoch:0,loss:2.302455186843872\n",
    "Epoch:1,loss:2.301239252090454\n",
    "Epoch:2,loss:2.3043417930603027\n",
    "Epoch:3,loss:2.301656484603882\n",
    "Epoch:4,loss:2.2993898391723633\n",
    "Epoch:5,loss:2.304699182510376\n",
    "Epoch:6,loss:2.2984282970428467\n",
    "Epoch:7,loss:2.301520347595215\n",
    "Epoch:8,loss:2.302445888519287\n",
    "Epoch:9,loss:2.3022239208221436\n",
    "Epoch:10,loss:2.301645278930664\n",
    "Epoch:11,loss:2.3001387119293213\n",
    "Epoch:12,loss:2.3018133640289307\n",
    "Epoch:13,loss:2.3029184341430664\n",
    "Epoch:14,loss:2.301494836807251\n",
    "Epoch:15,loss:2.300532341003418\n",
    "Epoch:16,loss:2.3011887073516846\n",
    "Epoch:17,loss:2.3011252880096436\n",
    "Epoch:18,loss:2.3002233505249023\n",
    "Epoch:19,loss:2.3051090240478516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:79.47%\n"
     ]
    }
   ],
   "source": [
    "#8 模型测试\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data,targets in test_loader:\n",
    "        # print(f\"Current batch size: {data.shape}\")\n",
    "        result1 =model(data.reshape(-1,784))\n",
    "        _,predicted = torch.max(result1,1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted ==targets).sum().item()\n",
    "print(f'Accuracy:{correct/total*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一种情况准确率Accuracy:10.0%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
