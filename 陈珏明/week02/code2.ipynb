{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.31658345  0.87092106  1.72036359 ... -0.28212368  0.77832315\n",
      "  -0.16641202]\n",
      " [ 0.48189943  1.26210965 -1.40206437 ... -0.11111693 -0.79872534\n",
      "   0.35582928]\n",
      " [-1.21453459  0.79779439  2.9754249  ...  0.96374661  0.86832195\n",
      "   2.96900007]\n",
      " ...\n",
      " [ 0.01863029  0.39830199 -1.73632074 ... -0.86054033 -0.20338872\n",
      "   0.79253298]\n",
      " [ 0.56703893 -0.56902346 -1.01423473 ...  1.24853653 -0.98966718\n",
      "   1.93697777]\n",
      " [ 0.70178344 -0.50543912 -1.08393009 ... -0.87151729 -0.52862277\n",
      "   1.65421597]]\n",
      "[1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1\n",
      " 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 1. 生成训练数据\n",
    "X,y = make_classification(n_samples=150, n_features=10)  # shape (150, 10)\n",
    "print(X)\n",
    "print(y)\n",
    "# 数据拆分\n",
    "# 局部样本训练模型（过拟合模型）测试预测不好\n",
    "# 新样本数据模型表现不好（泛化能力差）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.43638340e-01 -2.80640017e-01  7.24198996e-02 -2.19483915e+00\n",
      "   1.63558097e+00 -2.10871943e-01  6.35865372e-01  5.59873067e-01\n",
      "   7.19125134e-04 -2.64267961e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 权重参数\n",
    "theta = np.random.randn(1,10) \n",
    "print(theta) # shape (1, 10)\n",
    "bias = 0\n",
    "# 超参数\n",
    "lr = 0.1\n",
    "epochs = 3000  # 训练次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.297352334506715, acc: 0.34285714285714286\n",
      "epoch: 100, loss: 0.08374452636880864, acc: 0.9619047619047619\n",
      "epoch: 200, loss: 0.07255333871959328, acc: 0.9714285714285714\n",
      "epoch: 300, loss: 0.06754801809054843, acc: 0.9714285714285714\n",
      "epoch: 400, loss: 0.06449877990859586, acc: 0.9714285714285714\n",
      "epoch: 500, loss: 0.062368734943330985, acc: 0.9714285714285714\n",
      "epoch: 600, loss: 0.0607630509057534, acc: 0.9714285714285714\n",
      "epoch: 700, loss: 0.05949294632975553, acc: 0.9809523809523809\n",
      "epoch: 800, loss: 0.05845439676386497, acc: 0.9809523809523809\n",
      "epoch: 900, loss: 0.057584271030483934, acc: 0.9809523809523809\n",
      "epoch: 1000, loss: 0.056841500459221636, acc: 0.9809523809523809\n",
      "epoch: 1100, loss: 0.056197941362152004, acc: 0.9809523809523809\n",
      "epoch: 1200, loss: 0.05563351388562263, acc: 0.9809523809523809\n",
      "epoch: 1300, loss: 0.05513342431348965, acc: 0.9809523809523809\n",
      "epoch: 1400, loss: 0.05468648484949068, acc: 0.9809523809523809\n",
      "epoch: 1500, loss: 0.05428404906128161, acc: 0.9809523809523809\n",
      "epoch: 1600, loss: 0.053919311030733115, acc: 0.9809523809523809\n",
      "epoch: 1700, loss: 0.05358682884802757, acc: 0.9809523809523809\n",
      "epoch: 1800, loss: 0.05328219163707554, acc: 0.9809523809523809\n",
      "epoch: 1900, loss: 0.05300178132744596, acc: 0.9809523809523809\n",
      "epoch: 2000, loss: 0.052742598684167405, acc: 0.9809523809523809\n",
      "epoch: 2100, loss: 0.05250213395855762, acc: 0.9809523809523809\n",
      "epoch: 2200, loss: 0.05227826917424858, acc: 0.9809523809523809\n",
      "epoch: 2300, loss: 0.05206920325835541, acc: 0.9809523809523809\n",
      "epoch: 2400, loss: 0.05187339394325904, acc: 0.9809523809523809\n",
      "epoch: 2500, loss: 0.05168951216254959, acc: 0.9809523809523809\n",
      "epoch: 2600, loss: 0.05151640587990328, acc: 0.9809523809523809\n",
      "epoch: 2700, loss: 0.05135307112627722, acc: 0.9809523809523809\n",
      "epoch: 2800, loss: 0.05119862860648366, acc: 0.9809523809523809\n",
      "epoch: 2900, loss: 0.051052304652500685, acc: 0.9809523809523809\n"
     ]
    }
   ],
   "source": [
    "# 假设 X 是 shape (3, 3)\n",
    "# [[x1,x2,x3],\n",
    "#  [x4,x5,x6],\n",
    "#  [x7,x8,x9]]\n",
    "# X.T 是 shape (3, 3) \n",
    "# [[x1,x4,x7],\n",
    "#  [x2,x5,x8],\n",
    "#  [x3,x6,x9]]\n",
    "\n",
    "# 假设 theta 模型参数 shape (1, 3)\n",
    "# [[w1, w2, w3]]\n",
    "# theta * X.T shape (1, 3)\n",
    "#  y1 = w1 * x1 + w2 * x2 + w3 * x3 \n",
    "#  y2 = w1 * x4 + w2 * x5 + w3 * x6\n",
    "#  y3 = w1 * x7 + w2 * x8 + w3 * x9\n",
    "#  [[y1, y2, y3]]\n",
    "\n",
    "# 2. 模型计算函数\n",
    "def forward(x, theta, bias):\n",
    "    # 线性运算\n",
    "    z = np.dot(theta, x.T) + bias # shape (105,10)\n",
    "    # sigmoid\n",
    "    y_hat = 1 / (1 + np.exp(-z))  # shape (105,10)\n",
    "    return y_hat\n",
    "\n",
    "# 3. 计算损失函数\n",
    "def loss(y, y_hat):\n",
    "    e = 1e-8\n",
    "    return - y * np.log(y_hat + e) - (1 - y) * np.log(1 - y_hat + e)\n",
    "\n",
    "# 4. 计算梯度\n",
    "def calc_gradient(x,y,y_hat):\n",
    "    # 计算梯度\n",
    "    m = x.shape[-1]\n",
    "    # theta梯度计算\n",
    "    delta_theta = np.dot((y_hat - y), x) / m\n",
    "    # bias梯度计算\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    # 返回梯度\n",
    "    return delta_theta, delta_bias\n",
    "\n",
    "# 5. 模型训练\n",
    "for i in range(epochs):\n",
    "    # 前向计算\n",
    "    y_hat = forward(X_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(X_train, y_train, y_hat)\n",
    "    # 更新参数\n",
    "    theta = theta - lr * delta_theta\n",
    "    bias = bias - lr * delta_bias\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # [False,True,...,False] -> [0,1,...,0]\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 1, predict: [1.]\n"
     ]
    }
   ],
   "source": [
    "# 模型推理\n",
    "idx = np.random.randint(len(X_test)) # 随机选择一个测试样本索引\n",
    "x = X_test[idx]\n",
    "y = y_test[idx]\n",
    "\n",
    "predict = np.round(forward(x, theta, bias))\n",
    "print(f\"y: {y}, predict: {predict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
