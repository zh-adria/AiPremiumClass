{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.v2 import ToTensor     # 转换图像数据为张量\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader  # 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1162, 0.0586, 0.0620, 0.1089, 0.0717, 0.1041, 0.1188, 0.1208, 0.0766,\n",
      "         0.1623],\n",
      "        [0.1227, 0.0668, 0.0514, 0.1073, 0.0754, 0.1033, 0.1187, 0.1264, 0.0764,\n",
      "         0.1515],\n",
      "        [0.1224, 0.0625, 0.0664, 0.1125, 0.0734, 0.1244, 0.0947, 0.1151, 0.0825,\n",
      "         0.1461],\n",
      "        [0.1168, 0.0620, 0.0654, 0.1120, 0.0717, 0.1094, 0.1212, 0.1230, 0.0774,\n",
      "         0.1410],\n",
      "        [0.1222, 0.0605, 0.0509, 0.0922, 0.0727, 0.1205, 0.1169, 0.1396, 0.0767,\n",
      "         0.1478],\n",
      "        [0.1211, 0.0713, 0.0561, 0.1074, 0.0786, 0.1060, 0.1155, 0.1180, 0.0863,\n",
      "         0.1398],\n",
      "        [0.1273, 0.0700, 0.0570, 0.1007, 0.0779, 0.1184, 0.1146, 0.1219, 0.0669,\n",
      "         0.1453],\n",
      "        [0.1256, 0.0637, 0.0583, 0.1084, 0.0769, 0.1186, 0.1078, 0.1144, 0.0805,\n",
      "         0.1459],\n",
      "        [0.1223, 0.0651, 0.0578, 0.1048, 0.0817, 0.1204, 0.1069, 0.1354, 0.0769,\n",
      "         0.1287],\n",
      "        [0.1249, 0.0750, 0.0588, 0.0954, 0.0737, 0.1272, 0.1096, 0.1234, 0.0756,\n",
      "         0.1363]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "linear=nn.Linear(in_features=784,out_features=64,bias=True)\n",
    "\n",
    "x=torch.randn(10,784)\n",
    "out=linear(x)\n",
    "\n",
    "# 激活函数\n",
    "act=nn.Sigmoid()\n",
    "out2=act(out)\n",
    "# print(out2)\n",
    "\n",
    "linear2=nn.Linear(in_features=64,out_features=10,bias=True)\n",
    "act2=nn.Softmax(dim=1)\n",
    "out3=act2(linear2(out2))\n",
    "print(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(\n",
    "    nn.Linear(784,64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义超参数\n",
    "LR = 1e-3\n",
    "epochs = 20\n",
    "BATCH_SIZE = 128\n",
    "#优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集加载\n",
    "train_data = FashionMNIST(root='./fashion_data', train=True, download=True, \n",
    "                          transform=ToTensor())\n",
    "test_data = FashionMNIST(root='./fashion_data', train=False, download=True,\n",
    "                         transform=ToTensor())\n",
    "trian_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True表示打乱数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss: 1.458194613456726\n",
      "Epoch:1 Loss: 1.3974618911743164\n",
      "Epoch:2 Loss: 1.2555060386657715\n",
      "Epoch:3 Loss: 1.4087005853652954\n",
      "Epoch:4 Loss: 1.3276654481887817\n",
      "Epoch:5 Loss: 1.2465075254440308\n",
      "Epoch:6 Loss: 1.2457581758499146\n",
      "Epoch:7 Loss: 1.1377290487289429\n",
      "Epoch:8 Loss: 1.2697504758834839\n",
      "Epoch:9 Loss: 1.2725342512130737\n",
      "Epoch:10 Loss: 1.2306056022644043\n",
      "Epoch:11 Loss: 1.274585247039795\n",
      "Epoch:12 Loss: 1.119412899017334\n",
      "Epoch:13 Loss: 1.0556224584579468\n",
      "Epoch:14 Loss: 1.16698157787323\n",
      "Epoch:15 Loss: 1.175491452217102\n",
      "Epoch:16 Loss: 1.2189797163009644\n",
      "Epoch:17 Loss: 1.1181633472442627\n",
      "Epoch:18 Loss: 1.107205867767334\n",
      "Epoch:19 Loss: 1.07485830783844\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 提取训练数据\n",
    "    for data, target in trian_dl:\n",
    "        # 前向运算\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        # 计算损失\n",
    "        loss = loss_fn(output, target)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # 所有参数梯度清零\n",
    "        loss.backward()     # 计算梯度（参数.grad）\n",
    "        optimizer.step()    # 更新参数\n",
    "\n",
    "    print(f'Epoch:{epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.11%\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for data, target in test_dl:\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        _, predicted = torch.max(output, 1)  # 返回每行最大值和索引\n",
    "        total += target.size(0)  # size(0) 等效 shape[0]\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f'Accuracy: {correct/total*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
