{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "pytorch 模型定义\n",
   "id": "4758f4219e61341b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:13:05.737334Z",
     "start_time": "2025-03-13T15:13:05.730687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# 简单实现\n",
    "import torch.nn as nn\n",
    "# X输入 shape(,784)\n",
    "# 隐藏层 shape(784, 64) 参数矩阵\n",
    "# 隐藏层 shape(64,) 偏置项bias\n",
    "# 输出层 shape(64, 10) # 参数矩阵\n",
    "# 输出层 shape(10,) 偏置bias\n",
    "# Y输出 shape(,10) 10个类别"
   ],
   "id": "c024f1b7d21dec19",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:13:05.775827Z",
     "start_time": "2025-03-13T15:13:05.768998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 线性层\n",
    "linear = nn.Linear(in_features=784,out_features=64, bias=True) # bias 默认是true\n",
    "# 非线性(激活函数)\n",
    "act = nn.Sigmoid()\n",
    "# 输出层\n",
    "linear2 = nn.Linear(in_features=64,out_features=10,bias=True)\n",
    "\n",
    "# 模拟输入\n",
    "x = torch.randn(10, 784) # 十个样本，784 个特征\n",
    "out = linear(x)\n",
    "out2 = act(out)\n",
    "out3 = linear2(out2)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "print(softmax(out3))"
   ],
   "id": "ed875944fa83636",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0835, 0.0975, 0.1001, 0.0662, 0.1073, 0.1467, 0.1398, 0.0791, 0.0930,\n",
      "         0.0868],\n",
      "        [0.0895, 0.1007, 0.1034, 0.0611, 0.1198, 0.1339, 0.1360, 0.0866, 0.0871,\n",
      "         0.0820],\n",
      "        [0.0865, 0.1030, 0.0939, 0.0754, 0.1309, 0.1263, 0.1321, 0.0837, 0.0901,\n",
      "         0.0782],\n",
      "        [0.0890, 0.0942, 0.1001, 0.0687, 0.1169, 0.1286, 0.1465, 0.0750, 0.0994,\n",
      "         0.0816],\n",
      "        [0.0907, 0.0794, 0.0982, 0.0848, 0.1190, 0.1350, 0.1366, 0.0856, 0.0900,\n",
      "         0.0805],\n",
      "        [0.0836, 0.0858, 0.1029, 0.0738, 0.1255, 0.1291, 0.1400, 0.0896, 0.0898,\n",
      "         0.0798],\n",
      "        [0.0824, 0.0941, 0.0989, 0.0747, 0.1273, 0.1277, 0.1158, 0.0895, 0.0981,\n",
      "         0.0914],\n",
      "        [0.0874, 0.1098, 0.0869, 0.0800, 0.1376, 0.1161, 0.1266, 0.0879, 0.0852,\n",
      "         0.0826],\n",
      "        [0.0873, 0.0905, 0.1017, 0.0783, 0.1359, 0.1236, 0.1270, 0.0817, 0.0969,\n",
      "         0.0771],\n",
      "        [0.0859, 0.0969, 0.0951, 0.0696, 0.1462, 0.1399, 0.1183, 0.0855, 0.0861,\n",
      "         0.0765]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:13:05.784089Z",
     "start_time": "2025-03-13T15:13:05.775827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 模型定义, 所有机构串联在一起\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=784,out_features=64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(in_features=64,out_features=10)\n",
    ")"
   ],
   "id": "875c08a9ef4602e4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:13:05.803124Z",
     "start_time": "2025-03-13T15:13:05.800695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定制损失函数\n",
    "loss_fun = nn.CrossEntropyLoss() # 交叉熵损失"
   ],
   "id": "87f05c256f648726",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:13:05.842078Z",
     "start_time": "2025-03-13T15:13:05.833411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "[param for param in model.parameters()]"
   ],
   "id": "3f8c557318243970",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0015,  0.0041,  0.0075,  ..., -0.0063, -0.0014,  0.0225],\n",
       "         [-0.0102,  0.0229,  0.0131,  ..., -0.0299, -0.0239,  0.0263],\n",
       "         [-0.0342,  0.0287, -0.0027,  ..., -0.0219, -0.0199, -0.0342],\n",
       "         ...,\n",
       "         [-0.0309, -0.0153, -0.0297,  ..., -0.0128,  0.0077, -0.0231],\n",
       "         [-0.0239, -0.0177, -0.0235,  ...,  0.0098, -0.0313, -0.0123],\n",
       "         [-0.0229,  0.0134,  0.0082,  ...,  0.0340, -0.0162, -0.0343]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0011,  0.0124, -0.0318,  0.0028,  0.0002, -0.0182, -0.0004, -0.0155,\n",
       "         -0.0276,  0.0019,  0.0259,  0.0185, -0.0354,  0.0355, -0.0233,  0.0232,\n",
       "         -0.0114,  0.0258,  0.0007,  0.0229,  0.0309,  0.0036, -0.0040,  0.0316,\n",
       "         -0.0160,  0.0050,  0.0340, -0.0014, -0.0166,  0.0200, -0.0184, -0.0354,\n",
       "          0.0316,  0.0151,  0.0166,  0.0188,  0.0099, -0.0289,  0.0319,  0.0106,\n",
       "          0.0016, -0.0250, -0.0078,  0.0244,  0.0002,  0.0057, -0.0239, -0.0024,\n",
       "          0.0019,  0.0193,  0.0349, -0.0155, -0.0066,  0.0104,  0.0040, -0.0238,\n",
       "         -0.0167, -0.0315,  0.0103, -0.0101,  0.0094,  0.0091,  0.0233, -0.0033],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0557, -0.1121,  0.0305,  0.0452, -0.0587, -0.0154, -0.0614,  0.0158,\n",
       "          -0.1097,  0.1138, -0.0657, -0.0224, -0.0250,  0.0716,  0.1143,  0.0511,\n",
       "          -0.0112,  0.0665,  0.0147, -0.0475, -0.0874, -0.0024,  0.0273,  0.0680,\n",
       "           0.0881,  0.0458, -0.0315, -0.0319,  0.0703,  0.0991, -0.0705, -0.0693,\n",
       "          -0.1015,  0.0329, -0.0669, -0.1087,  0.0325,  0.0814,  0.0585, -0.0487,\n",
       "           0.0061, -0.0677,  0.0958,  0.0812, -0.0848, -0.1147, -0.0350,  0.0491,\n",
       "          -0.0674, -0.0545,  0.0599,  0.1104,  0.0988,  0.1024,  0.0048, -0.0692,\n",
       "           0.1108,  0.0744,  0.0592,  0.0516,  0.1086,  0.1182,  0.1091,  0.0396],\n",
       "         [-0.0149,  0.0540,  0.0877,  0.0627,  0.0272,  0.0916,  0.0728,  0.0177,\n",
       "          -0.0385,  0.0031,  0.1176, -0.1023,  0.0661, -0.0439,  0.0448,  0.0570,\n",
       "          -0.0968, -0.0891, -0.0730, -0.0152,  0.0992, -0.0739,  0.0602,  0.1026,\n",
       "          -0.0531, -0.0432,  0.0136,  0.0574,  0.0971, -0.0434, -0.0158,  0.0412,\n",
       "           0.0770, -0.0656,  0.0748,  0.0655,  0.1199,  0.0339, -0.0755, -0.0501,\n",
       "          -0.0414,  0.0788,  0.0755, -0.1128,  0.0600, -0.0090, -0.0670, -0.0305,\n",
       "          -0.0553, -0.0750, -0.0303, -0.1006,  0.0899,  0.1011,  0.0486, -0.0155,\n",
       "          -0.0627,  0.0019,  0.1240,  0.0313, -0.0691, -0.0081, -0.1176,  0.0273],\n",
       "         [ 0.0299,  0.0204,  0.0878, -0.0464,  0.0414, -0.0653,  0.0771,  0.0136,\n",
       "           0.1150,  0.0332, -0.0361,  0.0340,  0.0838,  0.0384, -0.0285, -0.1054,\n",
       "           0.0201,  0.0041,  0.0505, -0.0284,  0.1206, -0.0638,  0.0689, -0.0870,\n",
       "          -0.0504,  0.0565, -0.0782, -0.0080, -0.0664,  0.1095, -0.0006,  0.1098,\n",
       "          -0.0278, -0.0904,  0.1227,  0.0350, -0.0673, -0.0345,  0.1100,  0.0352,\n",
       "           0.0572, -0.1152,  0.0328, -0.0580,  0.0410,  0.0737, -0.0455,  0.0194,\n",
       "           0.0982, -0.0205, -0.1051,  0.0351, -0.0370,  0.1085, -0.0329,  0.0283,\n",
       "          -0.0182, -0.0802,  0.0561,  0.0825,  0.0899,  0.1125,  0.0267, -0.0944],\n",
       "         [-0.0845,  0.0578, -0.0980, -0.0612,  0.0184,  0.0028, -0.0852, -0.0719,\n",
       "           0.0903,  0.0549, -0.0958, -0.0748, -0.0100, -0.0081, -0.1024,  0.0486,\n",
       "          -0.0203, -0.0703, -0.0807, -0.0472, -0.0587,  0.0555, -0.0611, -0.0320,\n",
       "          -0.0125,  0.0753,  0.0139, -0.0746,  0.0624,  0.0911,  0.0440, -0.0508,\n",
       "          -0.0533, -0.0907,  0.0373,  0.0518,  0.0005,  0.0713,  0.0987,  0.0133,\n",
       "           0.0557, -0.0571, -0.0072, -0.0257,  0.1194,  0.0932,  0.0908, -0.1122,\n",
       "           0.0898,  0.0117, -0.0953,  0.0939,  0.0422,  0.0871,  0.0008, -0.0172,\n",
       "           0.0827, -0.0843, -0.0405, -0.0282,  0.0509, -0.0467,  0.1127,  0.0467],\n",
       "         [-0.1143,  0.0597,  0.0101, -0.0081, -0.0521, -0.0805, -0.0860,  0.0955,\n",
       "           0.0839,  0.0351, -0.1174, -0.0622, -0.0429, -0.0299,  0.0370,  0.1227,\n",
       "           0.0006, -0.0455,  0.1237, -0.0088,  0.0414, -0.0109,  0.0871, -0.0994,\n",
       "           0.0094,  0.0879, -0.1158,  0.0738, -0.0964,  0.0724, -0.0247, -0.0575,\n",
       "           0.0872, -0.0640,  0.0375,  0.0949,  0.0523, -0.0552,  0.1230,  0.0381,\n",
       "          -0.1146, -0.1112,  0.0899,  0.0820,  0.1182, -0.0645,  0.0208,  0.0013,\n",
       "           0.0740, -0.0145, -0.0446, -0.0794,  0.0930, -0.0753,  0.0475, -0.0647,\n",
       "          -0.0797,  0.0373, -0.0676,  0.0509,  0.0153,  0.1127, -0.0118,  0.0813],\n",
       "         [ 0.0537, -0.1063, -0.0865, -0.0287, -0.0801,  0.1099, -0.1232, -0.0137,\n",
       "          -0.0427,  0.0387, -0.0840, -0.0986, -0.0049, -0.0223, -0.1199,  0.0023,\n",
       "           0.0288, -0.0011,  0.0577, -0.0626, -0.0477, -0.0583, -0.0532,  0.0324,\n",
       "           0.0098, -0.0635, -0.0613, -0.0293,  0.1159,  0.0952,  0.0615, -0.0960,\n",
       "          -0.0255,  0.0642, -0.0264, -0.0492,  0.0777, -0.0713, -0.0022,  0.0870,\n",
       "          -0.0133,  0.0567, -0.0127,  0.0848,  0.0832,  0.0802,  0.1028,  0.0485,\n",
       "          -0.0863, -0.0883, -0.0223, -0.0818, -0.0800,  0.0947, -0.0653, -0.0396,\n",
       "           0.0943, -0.0170, -0.0979,  0.0863,  0.0777,  0.0945, -0.0100,  0.1160],\n",
       "         [-0.0783, -0.0265,  0.0928,  0.0195, -0.0618, -0.0063,  0.0818, -0.1035,\n",
       "          -0.0156,  0.0271,  0.0228,  0.0857, -0.0258, -0.0999, -0.0690, -0.0713,\n",
       "          -0.1217,  0.0698,  0.0592,  0.1002, -0.0476, -0.0569,  0.0122,  0.0820,\n",
       "           0.0320, -0.0638,  0.1148,  0.1236, -0.0396, -0.0259, -0.0482,  0.0603,\n",
       "           0.0555, -0.0254, -0.0364,  0.0304, -0.0601,  0.0754,  0.0555, -0.0798,\n",
       "           0.0317,  0.1098, -0.0633,  0.0924,  0.0641, -0.0503, -0.0910,  0.1249,\n",
       "           0.0655,  0.0392, -0.0450, -0.1159, -0.0219, -0.0477, -0.1222, -0.0306,\n",
       "          -0.1138, -0.0719,  0.1183,  0.0507, -0.1187,  0.0319,  0.0490, -0.0501],\n",
       "         [ 0.0666, -0.0520, -0.1059, -0.1125,  0.0115,  0.0070,  0.0327, -0.0962,\n",
       "          -0.0322,  0.1119,  0.0551, -0.0875,  0.1232,  0.0710,  0.1073, -0.0927,\n",
       "          -0.1013, -0.0717,  0.1216, -0.0737, -0.0343,  0.0057, -0.0634, -0.0903,\n",
       "          -0.0126, -0.1051, -0.0061, -0.0390,  0.0445, -0.1046,  0.1107,  0.1210,\n",
       "           0.0283,  0.0299, -0.0854, -0.0027,  0.1028, -0.0265,  0.1202, -0.1123,\n",
       "           0.1243,  0.0096,  0.0388, -0.0292, -0.0808,  0.0165, -0.0316,  0.0769,\n",
       "          -0.0252, -0.1171, -0.1072,  0.0704,  0.0974,  0.1222,  0.0458,  0.0928,\n",
       "          -0.0355, -0.0169, -0.1066, -0.0553, -0.0368, -0.0764, -0.0089, -0.0381],\n",
       "         [ 0.1017, -0.0468, -0.1196, -0.0825,  0.0510, -0.0301, -0.0957,  0.0602,\n",
       "           0.0554,  0.0106,  0.1244,  0.0157, -0.0794,  0.1236, -0.0689,  0.0865,\n",
       "          -0.0699, -0.1219,  0.0763,  0.1206, -0.1017, -0.0221, -0.0178, -0.0866,\n",
       "          -0.0204,  0.0643, -0.0664,  0.0769, -0.0123, -0.0146, -0.0389, -0.0484,\n",
       "           0.0603,  0.1043, -0.0511,  0.0934,  0.0299,  0.0345, -0.0699, -0.0942,\n",
       "          -0.0573, -0.0315, -0.0640,  0.1064,  0.0436,  0.0414,  0.0687,  0.0312,\n",
       "          -0.0860,  0.1247, -0.0213, -0.0853,  0.1020, -0.0052, -0.1060,  0.0191,\n",
       "          -0.0021, -0.0460,  0.1035, -0.0864, -0.0723,  0.0317, -0.1110, -0.1248],\n",
       "         [-0.0292,  0.0986, -0.1058, -0.0406,  0.1089, -0.0747,  0.0181, -0.1022,\n",
       "           0.1146, -0.0585,  0.1124, -0.1181, -0.0852, -0.0827,  0.0131,  0.0993,\n",
       "           0.0367, -0.1032, -0.1177,  0.0087,  0.0225, -0.0235,  0.0626, -0.0125,\n",
       "          -0.1094, -0.0886, -0.0559,  0.0031,  0.0522, -0.0263,  0.0907,  0.0233,\n",
       "           0.0237,  0.0089,  0.0044,  0.0217,  0.0825,  0.0407, -0.0899,  0.0070,\n",
       "           0.0702, -0.0231, -0.0279, -0.1072,  0.0339,  0.0076,  0.0077,  0.1128,\n",
       "          -0.0185,  0.0806,  0.0292,  0.1196,  0.0152, -0.0561, -0.0972, -0.0866,\n",
       "          -0.1246, -0.0399, -0.0572,  0.0581, -0.0343, -0.0885,  0.0608,  0.0698]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0900,  0.0654,  0.1218, -0.0695, -0.0355,  0.0208,  0.0336, -0.0171,\n",
       "         -0.0988,  0.0611], requires_grad=True)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
