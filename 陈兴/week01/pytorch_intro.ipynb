{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "标量、向量、矩阵 和 张量 分别具有零、一、二和任意数量的轴。\n",
    "1. 张量 tensor\n",
    "2. 矩阵 matrix \n",
    "3. 向量 vector\n",
    "4. 标量 scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "numpy array:  [[1 2]\n",
      " [3 4]]\n",
      "\n",
      "numpy array 的形状:  (2, 2)\n",
      "\n",
      "把numpy array 转换成 tensor:  tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "把numpy array 转换成 tensor 的形状:  torch.Size([2, 2])\n",
      "\n",
      "创建二阶张量:  tensor([[1., 2., 3.],\n",
      "        [3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# 什么是张量 tensor?\n",
    "# 张量是一个多维数组, 张量的维度是张量的阶数, 张量的形状是张量的维度的长度\n",
    "\n",
    "np_array = np.array([[1,2],[3,4]])\n",
    "print(\"\\nnumpy array: \",np_array) \n",
    "print(\"\\nnumpy array 的形状: \",np_array.shape)\n",
    "# 把numpy array 转换成 tensor\n",
    "data = torch.from_numpy(np_array)\n",
    "print(\"\\n把numpy array 转换成 tensor: \",data) \n",
    "print(\"\\n把numpy array 转换成 tensor 的形状: \",data.shape)\n",
    "\n",
    "# 创建二阶张量, 数据类型为float32\n",
    "data = torch.tensor([[1,2,3],[3,4,5]], dtype=torch.float32)\n",
    "print(\"\\n创建二阶张量: \",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.rand_like:  tensor([[0.2538, 0.6233, 0.2574],\n",
      "        [0.8358, 0.7575, 0.3916]])\n"
     ]
    }
   ],
   "source": [
    "# rand_like 函数: 创建一个与给定张量形状相同的张量，其元素是随机生成的。\n",
    "#\n",
    "# 语法: torch.rand_like(input, dtype=None)\n",
    "# 参数:\n",
    "# input: 输入张量。\n",
    "# dtype: 数据类型。\n",
    "\n",
    "\n",
    "# 通过已知张量维度，创建新张量\n",
    "data3 = torch.rand_like(data, dtype=torch.float)\n",
    "print(\"\\ntorch.rand_like: \", data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机初始化 torch.rand: \n",
      " tensor([[0.3699, 0.8394, 0.7078],\n",
      "        [0.9751, 0.1148, 0.4316]]) \n",
      "\n",
      "全 1 初始化 torch.ones: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "全 0 初始化 torch.zeros: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n",
      "rand_tensor.shape: torch.Size([2, 3])\n",
      "rand_tensor.dtype: torch.float32\n",
      "rand_tensor.device: cpu\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,) # 元组类型\n",
    "\n",
    "rand_tensor = torch.rand(shape) # 随机初始化\n",
    "ones_tensor = torch.ones(shape) # 全 1 初始化\n",
    "zeros_tensor = torch.zeros(shape) # 全 0 初始化\n",
    "\n",
    "print(f\"随机初始化 torch.rand: \\n {rand_tensor} \\n\")\n",
    "print(f\"全 1 初始化 torch.ones: \\n {ones_tensor} \\n\")\n",
    "print(f\"全 0 初始化 torch.zeros: \\n {zeros_tensor} \\n\")\n",
    "\n",
    "print(f\"rand_tensor.shape: {rand_tensor.shape}\")\n",
    "print(f\"rand_tensor.dtype: {rand_tensor.dtype}\")\n",
    "print(f\"rand_tensor.device: {rand_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.rand(2,3):\n",
      " tensor([[0.9473, 0.1332, 0.7462],\n",
      "        [0.4419, 0.0996, 0.4389]])\n",
      "\n",
      "torch.randn(2,3):\n",
      " tensor([[-0.6224, -0.4634, -0.0183],\n",
      "        [ 1.2603, -0.0949, -1.1625]])\n",
      "\n",
      "torch.normal(mean=0.0,std=1.0,size=(2,3)):\n",
      " tensor([[-1.3863, -1.1715,  1.2062],\n",
      "        [-0.2880, -0.7726,  1.5295]])\n",
      "\n",
      "torch.linspace(0,10,steps=4):\n",
      " tensor([ 0.0000,  3.3333,  6.6667, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# rand 函数:\n",
    "# 函数原型: torch.rand(*sizes) → Tensor\n",
    "# 功能: 返回一个张量，包含了从区间[0, 1)的 均匀分布 中抽取一组随机数。张量的形状由参数sizes定义。\n",
    "print(f'\\ntorch.rand(2,3):\\n {torch.rand(2,3)}')\n",
    "\n",
    "# randn 函数:\n",
    "# 函数原型: torch.randn(*sizes) → Tensor\n",
    "# 功能: 返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取一组随机数。张量的形状由参数sizes定义。\n",
    "print(f'\\ntorch.randn(2,3):\\n {torch.randn(2,3)}')\n",
    "\n",
    "# normal 函数:\n",
    "# 函数原型: torch.normal(mean, std, size) → Tensor\n",
    "# 功能: 返回一个张量，包含了从给定参数mean,std的离散正态分布中抽取一组随机数。mean,std形状不要求一致。\n",
    "# mean=.0 的意思是: 均值为0\n",
    "# std=1.0 的意思是: 标准差为1\n",
    "# size=(2,3) 的意思是: 张量的形状为2行3列\n",
    "print(f'\\ntorch.normal(mean=0.0,std=1.0,size=(2,3)):\\n {torch.normal(mean=0.0,std=1.0,size=(2,3))}')  \n",
    "\n",
    "# linspace 函数:\n",
    "# 函数原型: torch.linspace(start, end, steps) → Tensor\n",
    "# 功能: 返回一个1维张量，包含在区间start和end上均匀间隔的steps个点。输出张量的长度由steps决定。 \n",
    "print(f'\\ntorch.linspace(0,10,steps=4):\\n {torch.linspace(0,10,steps=4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(5)\n",
      "第一行:  tensor([1, 2, 3])\n",
      "第一行:  tensor([1, 2, 3])\n",
      "第一列:  tensor([ 1,  4,  7, 10])\n",
      "第一列:  tensor([ 1,  4,  7, 10])\n",
      "最后一列: tensor([ 3,  6,  9, 12])\n",
      "最后一列: tensor([ 3,  6,  9, 12])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([4, 3, 2])\n",
      "arr[1] 结果:  tensor([[0.8736, 0.5376],\n",
      "        [0.9717, 0.6956],\n",
      "        [0.7228, 0.4483]])\n",
      "arr[1, ...] 结果:  tensor([[0.8736, 0.5376],\n",
      "        [0.9717, 0.6956],\n",
      "        [0.7228, 0.4483]])\n",
      "arr[1, :, :] 结果:  tensor([[0.8736, 0.5376],\n",
      "        [0.9717, 0.6956],\n",
      "        [0.7228, 0.4483]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "# 使用下标 tensor[i, j] 来访问单个元素。\n",
    "print(tensor[0, 0], tensor[1,1])\n",
    "\n",
    "# 使用 : 来进行切片，获取行或列。\n",
    "# ... 表示“省略其他维度”\n",
    "print('第一行: ', tensor[0]) \n",
    "print('第一行: ', tensor[0, :])\n",
    "\n",
    "print('第一列: ', tensor[..., 0])\n",
    "print('第一列: ', tensor[:, 0]) \n",
    "\n",
    "print('最后一列:', tensor[:, -1])\n",
    "print('最后一列:', tensor[..., -1])\n",
    "\n",
    "# 切片: 前两行，前三列\n",
    "sub_tensor = tensor[:2, :3]\n",
    "print(sub_tensor)\n",
    "\n",
    "# 创建一个 3D 数组，形状为 (4, 3, 2)\n",
    "arr = torch.rand(4, 3, 2)  \n",
    "print(arr.shape)\n",
    "# 使用 ... 来获取 arr 的第二行\n",
    "print('arr[1] 结果: ', arr[1])  \n",
    "# arr[1, ...] 就相当于 arr[1, :, :]\n",
    "print('arr[1, ...] 结果: ', arr[1, ...]) \n",
    "print('arr[1, :, :] 结果: ', arr[1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0482, 0.1962, 0.8828, 0.0482, 0.1962, 0.8828, 0.0482, 0.1962, 0.8828],\n",
      "        [0.8042, 0.9774, 0.7429, 0.8042, 0.9774, 0.7429, 0.8042, 0.9774, 0.7429]])\n",
      "torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# cat 函数:\n",
    "# 功能：将多个张量连接起来\n",
    "tensor = torch.rand(2,3)\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1) # dim=0 按行连接，dim=1 按列连接\n",
    "print(t1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor.T:\n",
      " tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n",
      "tensor([[ 14.,  32.,  50.],\n",
      "        [ 32.,  77., 122.],\n",
      "        [ 50., 122., 194.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# arange 函数\n",
    "# 生成一个从 start 到 end 的张量，步长为 step。\n",
    "tensor = torch.arange(1,10, dtype=torch.float32).reshape(3, 3)\n",
    "print(f\"tensor: \\n {tensor}\")\n",
    "print(f'tensor.T:\\n {tensor.T}') # 转置\n",
    "\n",
    "# 矩阵乘法的两种方法。 y1, y2 结果是一样的。\n",
    "y1 = tensor @ tensor.T # @ 运算符: 矩阵乘法\n",
    "y2 = tensor.matmul(tensor.T) # matmul 函数: 矩阵乘法\n",
    "\n",
    "# y3 结果也是一样\n",
    "y3 = torch.zeros_like(tensor)\n",
    "# out 是输出张量给 y3, 用out可以节省内存。\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  4.],\n",
      "        [ 9., 16., 25.]])\n",
      "tensor([[ 0.,  1.,  4.],\n",
      "        [ 9., 16., 25.]])\n",
      "tensor([[ 0.,  1.,  4.],\n",
      "        [ 9., 16., 25.]])\n",
      "15.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]], dtype=torch.float32)\n",
    "# 逐个元素相乘 也叫 Hadamard积\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "print(z1)\n",
    "print(z2)\n",
    "\n",
    "\n",
    "z3 = torch.zeros_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "\n",
    "print(z3)\n",
    "\n",
    "agg = tensor.sum() # 求和\n",
    "\n",
    "agg_item = agg.item() # 转换成python的数字类型, 只有一个元素的tensor可以转换成python的数字类型\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.]])\n",
      "tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]])\n",
      "tensor([[9., 9., 9., 9.],\n",
      "        [9., 9., 9., 9.],\n",
      "        [9., 9., 9., 9.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(tensor, \"\\n\")\n",
    "# 原地更新: 减少内存使用\n",
    "tensor.add_(2) \n",
    "print(tensor)\n",
    "\n",
    "# 非原地更新\n",
    "tensor = tensor + 2\n",
    "print(tensor)\n",
    "\n",
    "# 原地更新\n",
    "tensor += 2\n",
    "print(tensor)\n",
    "\n",
    "# [:] 的作用: 对 tensor 中的元素进行修改, 原地更新\n",
    "tensor[:] = tensor + 2\n",
    "print(tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/fy3s8rzx7cdfb19k40rx8_zc0000gn/T/ipykernel_22568/286211319.py:11: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3729.)\n",
      "  result = torch.matmul(A, x.T) + torch.dot(b, x) + c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 定义矩阵 A，向量 b 和常数 c\n",
    "A = torch.randn(10, 10, requires_grad=True)  # requires_grad=True 表示我们要对 A 求导\n",
    "b = torch.randn(10, requires_grad=True)\n",
    "c = torch.randn(1, requires_grad=True)\n",
    "x = torch.randn(10, requires_grad=True)\n",
    "\n",
    "# 计算 x^T * A + b * x + c\n",
    "result = torch.matmul(A, x.T) + torch.dot(b, x) + c\n",
    "\n",
    "# 生成计算图节点\n",
    "dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})\n",
    "# 绘制计算图\n",
    "dot.render('expression', format='png', cleanup=True, view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
