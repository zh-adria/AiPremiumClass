{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 搭建神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现神经网络模型\n",
    "import torch.nn as nn\n",
    "\n",
    "# X输入 shape(, 28*28) \n",
    "# 隐藏层 shape(28*28,64) \n",
    "# 隐藏层 shape(64,)\n",
    "# 输出层 shape(64, 10)\n",
    "# 输出层 shape(10 ,)\n",
    "# Y输出 shape(, 10)\n",
    "\n",
    "# 所有结构串联起来\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "输入形状: torch.Size([4, 784])\n",
      "输出形状: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实现神经网络模型\n",
    "import torch.nn as nn\n",
    "\n",
    "# X输入 shape(, 28*28) \n",
    "# 隐藏层 shape(28*28,64) \n",
    "# 隐藏层 shape(64,)\n",
    "# 输出层 shape(64, 10)\n",
    "# 输出层 shape(10 ,)\n",
    "# Y输出 shape(, 10)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义神经网络模型\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # 输入层 -> 隐藏层\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # 隐藏层 -> 输出层\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入层 -> 隐藏层\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        # 隐藏层 -> 输出层\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 定义模型参数\n",
    "input_size = 28 * 28  # 输入特征维度（MNIST 图像大小为 28x28）\n",
    "hidden_size = 64       # 隐藏层维度\n",
    "num_classes = 10       # 输出类别数（MNIST 有 10 个类别）\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleMLP(input_size, hidden_size, num_classes)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "# 定义输入数据\n",
    "batch_size = 4\n",
    "x = torch.randn(batch_size, 28 * 28)  # 随机生成输入数据，形状为 (4, 784)\n",
    "\n",
    "# 前向传播\n",
    "output = model(x)\n",
    "\n",
    "# 打印输出\n",
    "print(f\"输入形状: {x.shape}\")  # 输出: torch.Size([4, 784])\n",
    "print(f\"输出形状: {output.shape}\")  # 输出: torch.Size([4, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "在 PyTorch 中，损失函数用于衡量模型预测结果与真实标签之间的差距。常见的损失函数包括：\n",
    "\n",
    "- `nn.CrossEntropyLoss()`：交叉熵损失函数，常用于多分类问题。\n",
    "- `nn.MSELoss()`：均方误差损失函数，常用于回归问题。\n",
    "\n",
    "优化器的作用是更新模型参数，使得损失函数的值最小化。常见的优化器包括：\n",
    "\n",
    "- `torch.optim.Adam()`：Adam 优化器，一种自适应学习率的优化器。\n",
    "- `torch.optim.SGD()`：SGD 优化器，即随机梯度下降优化器。\n",
    "\n",
    "**SGD 和 Adam 优化器的区别**\n",
    "\n",
    "- **收敛速度**：Adam 通常比 SGD 收敛速度更快。\n",
    "- **学习率**：Adam 具有自适应学习率的特性，而 SGD 通常需要手动调整学习率。\n",
    "- **局部最优解**：Adam 有时可能会陷入局部最优解，而 SGD 相对来说更容易跳出局部最优解。\n",
    "- **内存占用**：Adam 需要保存更多的中间变量，因此内存占用比 SGD 高。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "# 优化器    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # SGD 优化器\n",
    "print(optimizer)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
