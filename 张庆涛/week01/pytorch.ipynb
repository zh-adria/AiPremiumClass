{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = [[1,2],[3,4]]\n",
    "x_data= torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1390, 0.4455],\n",
       "        [0.8489, 0.3798]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "x_ones\n",
    "x_rand = torch.rand_like(x_data,dtype=torch.float32) #覆盖x_data的数据类型\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7261, 0.9440, 0.4538],\n",
      "        [0.9412, 0.1122, 0.3581]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "rand_tensor,ones_tensor,zeros_tensor\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9069,  0.8733,  1.4251],\n",
       "        [ 1.2052,  0.2578,  0.4423],\n",
       "        [-0.8137, -0.4854,  0.5000],\n",
       "        [-0.0886, -0.7007, -0.8063],\n",
       "        [-1.1262,  0.3225, -0.3218]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于现有tensor构建，但使⽤新值填充\n",
    "m = torch.ones(5,3, dtype=torch.double)\n",
    "n = torch.rand_like(m, dtype=torch.float)\n",
    "\n",
    "# 获取tensor的大小\n",
    "print(m.size()) # 输出：torch.Size([5, 3])\n",
    "\n",
    "# 均匀分布\n",
    "z = torch.rand(5,3)\n",
    "# 标准正态分布\n",
    "z = torch.randn(5,3)\n",
    "# 离散正态分布\n",
    "z = torch.normal(mean= .0, std=1.0,size=(5,3) )\n",
    "z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor ：torch.Size([3, 4])\n",
      "Datatype of tensor : torch.float32\n",
      "device of tensor : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f'shape of tensor ：{tensor.shape}')\n",
    "print(f'Datatype of tensor : {tensor.dtype}')\n",
    "print(f'device of tensor : {tensor.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")          # a CUDA device object\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row tensor([0.7006, 0.3871, 0.8329, 0.1644])\n",
      "First column tensor([0.7006, 0.3481, 0.9978, 0.2918])\n",
      "Last column tensor([0.1644, 0.2232, 0.7124, 0.0647])\n",
      "tensor([[0.7006, 0.3871, 0.8329, 0.1644],\n",
      "        [0.3481, 0.7049, 0.5887, 0.2232],\n",
      "        [0.9978, 0.6475, 0.9350, 0.7124],\n",
      "        [0.2918, 0.5288, 0.9663, 0.0647]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4,4)\n",
    "tensor\n",
    "print('First row',tensor[0])\n",
    "print('First column',tensor[:,0])\n",
    "print('Last column',tensor[:,-1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3615, 1.0437, 1.8456, 1.2246],\n",
      "        [1.0437, 1.0145, 1.5132, 1.0577],\n",
      "        [1.8456, 1.5132, 2.7965, 1.5832],\n",
      "        [1.2246, 1.0577, 1.5832, 1.3028]])\n",
      "tensor([[1.3615, 1.0437, 1.8456, 1.2246],\n",
      "        [1.0437, 1.0145, 1.5132, 1.0577],\n",
      "        [1.8456, 1.5132, 2.7965, 1.5832],\n",
      "        [1.2246, 1.0577, 1.5832, 1.3028]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4909, 0.1498, 0.6937, 0.0270],\n",
       "        [0.1211, 0.4969, 0.3466, 0.0498],\n",
       "        [0.9956, 0.4192, 0.8743, 0.5075],\n",
       "        [0.0852, 0.2796, 0.9338, 0.0042]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor的运算 \n",
    "# 计算两个张量之间矩阵乘法的几种方法 y1,y2,y3 最后的值是一样的dot \n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y1)\n",
    "print(y2)\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor,tensor.T,out=y3)\n",
    "\n",
    "# 计算张量逐元素相乘的几种方法， ,z1,z2,z3 最后的值是一样的\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.715234756469727 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4,4)\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item,type(agg_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0073, 0.9727, 0.8256, 0.5737],\n",
      "        [0.1975, 0.8490, 0.8843, 0.6112],\n",
      "        [0.1523, 0.8226, 0.8213, 0.2509],\n",
      "        [0.6733, 0.0476, 0.0803, 0.9458]]) \n",
      "\n",
      "tensor([[5.0073, 5.9727, 5.8256, 5.5737],\n",
      "        [5.1975, 5.8490, 5.8843, 5.6112],\n",
      "        [5.1523, 5.8226, 5.8213, 5.2509],\n",
      "        [5.6733, 5.0476, 5.0803, 5.9458]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor,\"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n,1,out = n )\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_41352\\3594221820.py:10: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 定义矩阵 A，向量 b 和常数 c\n",
    "A = torch.randn(10, 10,requires_grad=True)\n",
    "b = torch.randn(10,requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn(10, requires_grad=True)\n",
    "# 计算 x^T * A + b * x + c\n",
    "result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n",
    "# ⽣成计算图节点\n",
    "dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})\n",
    "# 绘制计算图\n",
    "dot.render('expression', format='png', cleanup=True, view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8807970779778823\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "  \n",
    "print(sigmoid(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
