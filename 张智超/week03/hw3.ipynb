{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调试超参数，观察学习率和批次大小对训练的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import KMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "train_data = KMNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_data = KMNIST(root='./data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "BATCH_SIZE = (64, 128, 256) # 批次大小\n",
    "NEURON_NUM = 256 # 神经元数量\n",
    "LR = (1e-1, 1e-2, 1e-3) # 学习率\n",
    "EPOCHS = 10 # 训练轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练及预测函数\n",
    "def train_and_test(lr, batch_size):\n",
    "    print(f'====================学习率: {lr}, 批次大小: {batch_size}====================')\n",
    "    # 训练\n",
    "    train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(28 * 28, NEURON_NUM),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(NEURON_NUM, 10)\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    start_time = time.time() # 记录开始时间\n",
    "    for i in range(EPOCHS):\n",
    "        for x, y in train_dl:\n",
    "            # 前向传播\n",
    "            y_hat = model(x.reshape(-1, 28 * 28))\n",
    "            # 计算损失\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if i % 2 == 0:\n",
    "            print(f'epoch {i + 1}, loss {loss.item()}')\n",
    "    end_time = time.time() # 记录结束时间\n",
    "    print(f'train time: {end_time - start_time} seconds')\n",
    "    # 预测\n",
    "    test_dl = DataLoader(test_data, batch_size=batch_size)\n",
    "    correct = 0\n",
    "    total = len(test_data)\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dl:\n",
    "            out = model(x.reshape(-1, 28 * 28))\n",
    "            _, pred = torch.max(out, 1)\n",
    "            correct += (pred == y).sum().item()\n",
    "    print(f'accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================学习率: 0.1, 批次大小: 128====================\n",
      "epoch 1, loss 0.945385217666626\n",
      "epoch 3, loss 0.7070376873016357\n",
      "epoch 5, loss 0.546995222568512\n",
      "epoch 7, loss 0.5957476496696472\n",
      "epoch 9, loss 0.41252708435058594\n",
      "train time: 295.29851818084717 seconds\n",
      "accuracy: 0.7524\n",
      "====================学习率: 0.01, 批次大小: 128====================\n",
      "epoch 1, loss 2.125501871109009\n",
      "epoch 3, loss 1.6173046827316284\n",
      "epoch 5, loss 1.268863320350647\n",
      "epoch 7, loss 1.0883285999298096\n",
      "epoch 9, loss 0.8218655586242676\n",
      "train time: 294.4247143268585 seconds\n",
      "accuracy: 0.6032\n",
      "====================学习率: 0.001, 批次大小: 128====================\n",
      "epoch 1, loss 2.287616014480591\n",
      "epoch 3, loss 2.260935068130493\n",
      "epoch 5, loss 2.2311019897460938\n",
      "epoch 7, loss 2.1823010444641113\n",
      "epoch 9, loss 2.181776523590088\n",
      "train time: 321.70576763153076 seconds\n",
      "accuracy: 0.4547\n"
     ]
    }
   ],
   "source": [
    "# （1）调整学习率\n",
    "for lr in LR:\n",
    "    train_and_test(lr, BATCH_SIZE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================学习率: 0.01, 批次大小: 64====================\n",
      "epoch 1, loss 1.8516889810562134\n",
      "epoch 3, loss 1.0958340167999268\n",
      "epoch 5, loss 0.8617031574249268\n",
      "epoch 7, loss 0.7734382152557373\n",
      "epoch 9, loss 0.7711595892906189\n",
      "train time: 327.93442726135254 seconds\n",
      "accuracy: 0.6549\n",
      "====================学习率: 0.01, 批次大小: 128====================\n",
      "epoch 1, loss 2.1472628116607666\n",
      "epoch 3, loss 1.6492122411727905\n",
      "epoch 5, loss 1.1972010135650635\n",
      "epoch 7, loss 0.8833262324333191\n",
      "epoch 9, loss 0.770098865032196\n",
      "train time: 376.0450642108917 seconds\n",
      "accuracy: 0.6038\n",
      "====================学习率: 0.01, 批次大小: 256====================\n",
      "epoch 1, loss 2.2221620082855225\n",
      "epoch 3, loss 2.017033100128174\n",
      "epoch 5, loss 1.795637607574463\n",
      "epoch 7, loss 1.6515787839889526\n",
      "epoch 9, loss 1.4333432912826538\n",
      "train time: 351.65235900878906 seconds\n",
      "accuracy: 0.5235\n"
     ]
    }
   ],
   "source": [
    "# （2）调整批次大小\n",
    "for batch_size in BATCH_SIZE:\n",
    "    train_and_test(LR[1], batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
