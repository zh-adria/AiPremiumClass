{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# 1、张量创建\n",
    "a1 = [[1,2], [3,4]]\n",
    "a2 = torch.tensor(a1)\n",
    "print(a1)\n",
    "print(a2)\n",
    "a3 = np.array(a1)\n",
    "a4 = torch.from_numpy(a3)\n",
    "print(a3)\n",
    "print(a4)\n",
    "a5 = torch.tensor(a3)\n",
    "print(a5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.8376, 0.2956, 0.5259],\n",
      "        [0.3100, 0.8980, 0.1396],\n",
      "        [0.5937, 0.5577, 0.1904]])\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "a7 = torch.ones_like(a6)\n",
    "print(a6)\n",
    "print(a7)\n",
    "a8 = torch.zeros_like(a6)\n",
    "a9 = torch.rand_like(a6) # 如果a6中不指定元素类型dtype=torch.float32，会提示异常：\"check_uniform_bounds\" not implemented for 'Long'\n",
    "print(a8)\n",
    "print(a9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5363, 0.8547, 0.6221],\n",
      "        [0.4980, 0.8079, 0.9235],\n",
      "        [0.6420, 0.0363, 0.9245]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 使⽤随机值或常量值创建张量\n",
    "shape1 = (3, 3)\n",
    "a10 = torch.rand(shape1)\n",
    "a11 = torch.ones(shape1)\n",
    "a12 = torch.zeros(shape1)\n",
    "print(a10)\n",
    "print(a11)\n",
    "print(a12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3423, 0.8027, 0.6159],\n",
      "        [0.1695, 0.2874, 0.0209],\n",
      "        [0.4353, 0.8694, 0.3767],\n",
      "        [0.3369, 0.2818, 0.1074],\n",
      "        [0.5890, 0.6797, 0.4615]])\n",
      "tensor([[0.3611, 0.7151, 0.1436],\n",
      "        [0.8452, 0.9552, 0.0947],\n",
      "        [0.8486, 0.7029, 0.6817],\n",
      "        [0.4086, 0.3377, 0.3649],\n",
      "        [0.0487, 0.2333, 0.6606]])\n",
      "tensor([[-2.1703,  0.4440, -1.5605],\n",
      "        [ 1.1872, -0.2284,  0.0931],\n",
      "        [ 0.5562, -1.2871,  0.0130],\n",
      "        [ 0.1680, -0.9407, -0.1366],\n",
      "        [ 0.6455, -1.8513, -1.1154]])\n",
      "tensor([[-0.7406,  0.9654,  0.8645],\n",
      "        [-0.2863,  0.2678,  2.1574],\n",
      "        [-0.3779,  0.8856, -1.7784],\n",
      "        [ 0.1886,  0.0744,  1.5943],\n",
      "        [-1.6880,  0.9600,  0.5375]])\n",
      "tensor([[-0.5836, -1.0123, -0.7555],\n",
      "        [-1.7100,  1.5276, -0.5966],\n",
      "        [ 0.6149,  0.1347,  0.7784],\n",
      "        [-0.2301, -0.7709,  1.5764],\n",
      "        [-1.4163, -0.5135,  0.1054]])\n",
      "tensor([ 0.0000,  0.4762,  0.9524,  1.4286,  1.9048,  2.3810,  2.8571,  3.3333,\n",
      "         3.8095,  4.2857,  4.7619,  5.2381,  5.7143,  6.1905,  6.6667,  7.1429,\n",
      "         7.6190,  8.0952,  8.5714,  9.0476,  9.5238, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# 其他创建方法\n",
    "a13 = torch.rand(5,3) # 均匀分布\n",
    "a14 = torch.rand((5,3))\n",
    "print(a13)\n",
    "print(a14)\n",
    "a15 = torch.randn(5,3) # 标准正态分布\n",
    "a16 = torch.randn((5,3))\n",
    "print(a15)\n",
    "print(a16)\n",
    "a17 = torch.normal(mean=0, std=1, size=(5,3))\n",
    "print(a17)\n",
    "a18 = torch.linspace(0, 10, steps=22) # 线性间隔向量(返回⼀个1维张量，包含在区间start和end上均匀间隔的steps个点)\n",
    "print(a18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "维度： torch.Size([3, 4, 5])\n",
      "维度： torch.Size([3, 4, 5])\n",
      "元素类型： torch.float32\n",
      "存储位置： cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 2、张量的属性\n",
    "a19 = torch.ones((3,4,5))\n",
    "print(a19)\n",
    "print(\"维度：\", a19.shape)\n",
    "print(\"维度：\", a19.size())\n",
    "print(\"元素类型：\", a19.dtype)\n",
    "print(\"存储位置：\", a19.device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3、张量拼接，dim 参数指定了沿着哪个维度进行拼接\n",
    "a20 = torch.ones(2, 3)\n",
    "print(a20)\n",
    "print(a20.shape)\n",
    "a21 = torch.cat([a20, a20], dim=0)\n",
    "print(a21)\n",
    "print(a21.shape)\n",
    "a22 = torch.cat([a20, a20], dim=1)\n",
    "print(a22)\n",
    "print(a22.shape)\n",
    "a23 = torch.cat([a20, a20, a20], dim=0)\n",
    "print(a23)\n",
    "print(a23.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "torch.Size([2, 3, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "torch.Size([4, 3, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "a20 = torch.ones(2, 3, 4)\n",
    "print(a20)\n",
    "print(a20.shape)\n",
    "a21 = torch.cat([a20, a20], dim=0)\n",
    "print(a21)\n",
    "print(a21.shape)\n",
    "a22 = torch.cat([a20, a20], dim=1)\n",
    "print(a22)\n",
    "print(a22.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [15., 15., 15.],\n",
      "        [24., 24., 24.]])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [15., 15., 15.],\n",
      "        [24., 24., 24.]])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [15., 15., 15.],\n",
      "        [24., 24., 24.]])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [15., 15., 15.],\n",
      "        [24., 24., 24.]])\n",
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 4、张量算数运算\n",
    "# 点乘\n",
    "a23 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "print(a23)\n",
    "a24 = torch.ones(3,3)\n",
    "print(a24)\n",
    "r1 = a23 @ a24\n",
    "r2 = a23.matmul(a24)\n",
    "r3 = torch.matmul(a23, a24)\n",
    "r4 = torch.ones(3,3)\n",
    "torch.matmul(a23, a24, out=r4)\n",
    "print(r1)\n",
    "print(r2)\n",
    "print(r3)\n",
    "print(r4)\n",
    "print(a23.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 5., 0.],\n",
      "        [0., 0., 9.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 5., 0.],\n",
      "        [0., 0., 9.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 5., 0.],\n",
      "        [0., 0., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 叉乘\n",
    "a23 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "print(a23)\n",
    "a24 = torch.eye(3,3)\n",
    "print(a24)\n",
    "r1 = a23 * a24\n",
    "r2 = a23.mul(a24)\n",
    "r3 = torch.mul(a23, a24)\n",
    "print(r1)\n",
    "print(r2)\n",
    "print(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.) <class 'torch.Tensor'>\n",
      "45.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# 转换为python数值\n",
    "a25 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)\n",
    "s = a25.sum()\n",
    "i = s.item()\n",
    "print(s, type(s))\n",
    "print(i, type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[4., 4., 4.],\n",
      "        [4., 4., 4.],\n",
      "        [4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place操作\n",
    "a26 = torch.ones(3,3)\n",
    "print(a26)\n",
    "a26.add(3)\n",
    "print(a26)\n",
    "a26.add_(3)\n",
    "print(a26) # in-place操作，直接在原对象上修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3643,  0.6178, -0.2687, -1.0982,  0.7881,  1.3200, -0.7000, -1.2041,\n",
      "          0.0354, -1.8176],\n",
      "        [ 1.5282, -1.3045, -0.9800, -3.0414, -1.0705,  1.2879, -1.4402,  0.2408,\n",
      "          0.5597, -0.4214],\n",
      "        [ 1.4928, -0.0136,  0.1205,  0.3898, -1.2655,  0.8170, -1.7315, -1.8967,\n",
      "         -1.2994, -0.1273],\n",
      "        [ 2.3637,  1.4442, -1.0803,  0.2539,  1.0767,  0.3993, -0.2864,  1.0144,\n",
      "          0.7471,  0.1619],\n",
      "        [ 0.9635,  2.1311,  0.0893,  1.4448,  0.6213,  0.1077,  0.7644,  0.3736,\n",
      "         -0.4169,  0.1178],\n",
      "        [-1.2069, -0.0853,  0.0492,  0.0757, -1.3383, -1.4889, -2.6017, -1.4635,\n",
      "         -1.0001,  0.9490],\n",
      "        [-0.0874, -1.4874,  0.3384, -0.0111, -0.6986, -0.2471,  1.1679, -1.7987,\n",
      "          1.3660,  0.2930],\n",
      "        [-0.5454, -0.1600, -0.1981, -1.4923,  2.0955, -2.0320, -2.5412,  1.0250,\n",
      "          0.2086, -0.6704],\n",
      "        [ 0.1630,  0.1002,  1.4615,  0.9642, -1.8208,  0.5563,  0.3433,  0.7701,\n",
      "         -1.1473, -1.1008],\n",
      "        [-0.3824, -0.8716, -1.7106, -0.0632, -0.0277,  0.1472, -1.1649,  0.3255,\n",
      "         -1.1220,  0.6060]], requires_grad=True)\n",
      "tensor([-1.4950, -0.1759,  1.7414, -0.2323, -1.1131,  0.5201,  1.6891, -0.8227,\n",
      "         1.7756,  0.1796], requires_grad=True)\n",
      "tensor([0.0518], requires_grad=True)\n",
      "tensor([ 0.8567,  1.8826,  0.7774,  0.2314, -0.3929,  0.4755,  0.3390,  1.0754,\n",
      "        -1.7494, -0.1847], requires_grad=True)\n",
      "tensor([-4.4359, -5.7371, -1.0344,  0.3595,  3.3897, -5.2294, -9.4667, -6.0846,\n",
      "         2.7952, -4.4533], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5、计算图，先安装torchviz：pip install torchviz\n",
    "from torchviz import make_dot\n",
    "A = torch.randn(10, 10,requires_grad=True)\n",
    "b = torch.randn(10,requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn(10, requires_grad=True)\n",
    "print(A)\n",
    "print(b)\n",
    "print(c)\n",
    "print(x)\n",
    "\n",
    "result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n",
    "print(result)\n",
    "# ⽣成计算图节点\n",
    "dot = make_dot(result, params={'数据A': A, '数据b': b, '数据c': c, 'x': x})\n",
    "# 绘制计算图\n",
    "# 报错：ExecutableNotFound: failed to execute WindowsPath('dot')。解决：conda install graphviz\n",
    "dot.render('expression', format='png', cleanup=True, view=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
