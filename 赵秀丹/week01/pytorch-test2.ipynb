{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "data=[[1,2,3],[4,5,6]]\n",
    "x_data=torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np_array=np.array(data)\n",
    "x_np=torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones=torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor:\\n {x_ones}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      "tensor([[0.3941, 0.5622, 0.3820],\n",
      "        [0.0541, 0.2071, 0.9383]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand=torch.rand_like(x_data,dtype=torch.float)\n",
    "print(f\"Random Tensor:\\n{x_rand}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor:\n",
      "tensor([[0.7211, 0.7147, 0.1383, 0.6694, 0.9593, 0.5605],\n",
      "        [0.7386, 0.9275, 0.4288, 0.7691, 0.0265, 0.4312],\n",
      "        [0.8716, 0.9518, 0.5379, 0.0114, 0.4760, 0.0187],\n",
      "        [0.8058, 0.5327, 0.6799, 0.9324, 0.5375, 0.0089],\n",
      "        [0.8105, 0.4873, 0.4658, 0.4373, 0.1021, 0.5473]]) \n",
      "\n",
      "Ones Tensor:\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor:\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape=(5,6)\n",
    "rand_tensor=torch.rand(shape)\n",
    "ones_tensor=torch.ones(shape)\n",
    "zeros_tensor=torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor:\\n{rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor:\\n{ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor:\\n{zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 10.0000,  14.7368,  19.4737,  24.2105,  28.9474,  33.6842,  38.4211,\n",
       "         43.1579,  47.8947,  52.6316,  57.3684,  62.1053,  66.8421,  71.5789,\n",
       "         76.3158,  81.0526,  85.7895,  90.5263,  95.2632, 100.0000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##基于现有tensor构建，但是使用新值填充\n",
    "m=torch.ones(10,9,dtype=torch.double)\n",
    "n=torch.rand_like(m,dtype=torch.float)\n",
    "\n",
    "print(m.size())\n",
    "\n",
    "##均匀分布\n",
    "torch.rand(10,9)\n",
    "##标准正态分布\n",
    "torch.randn(5,3)\n",
    "##离散\n",
    "torch.normal(mean=1,std=2,size=(5,6))\n",
    "##线性间隔向量\n",
    "torch.linspace(start=10,end=100,steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor:torch.Size([2, 5])\n",
      "Datatype of tensor :torch.float32\n",
      "Device tensor is stored on :cpu\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.rand(2,5)\n",
    "print(f\"Shape of tensor:{tensor.shape}\")\n",
    "print(f\"Datatype of tensor :{tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on :{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    }
   ],
   "source": [
    "##设置在gpu运行\n",
    "if torch.cuda.is_available():\n",
    "    tensor=tensor.to('cuda')\n",
    "    print(\"y\")\n",
    "print(\"n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "First row:tensor([1., 2., 3.], dtype=torch.float64)\n",
      "First column:tensor([1., 6.], dtype=torch.float64)\n",
      "Last column:tensor([3., 8.], dtype=torch.float64)\n",
      "tensor([[1., 0., 3.],\n",
      "        [6., 0., 8.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "##张量的索引和切片\n",
    "# tensor=torch.ones(5,6)\n",
    "aa=np.array([[1,2,3],[6,7,8]])\n",
    "print(aa.shape)\n",
    "tensor=torch.tensor(aa,dtype=float)\n",
    "print(f\"First row:{tensor[0]}\")\n",
    "print(f\"First column:{tensor[:,0]}\")\n",
    "print(f\"Last column:{tensor[...,-1]}\")\n",
    "tensor[:,1]=0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 3.],\n",
      "        [6., 0., 8.],\n",
      "        [1., 0., 3.],\n",
      "        [6., 0., 8.],\n",
      "        [1., 0., 3.],\n",
      "        [6., 0., 8.]], dtype=torch.float64)\n",
      "\n",
      "tensor([[1., 0., 3., 1., 0., 3., 1., 0., 3.],\n",
      "        [6., 0., 8., 6., 0., 8., 6., 0., 8.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "##张量的拼接\n",
    "t1=torch.cat([tensor,tensor,tensor],dim=0)\n",
    "print(t1)\n",
    "\n",
    "print()\n",
    "t2=torch.cat([tensor,tensor,tensor],dim=1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:tensor([[1., 0., 3.],\n",
      "        [6., 0., 8.]], dtype=torch.float64)\n",
      "y3 tensor([[ 10.,  30.],\n",
      "        [ 30., 100.]], dtype=torch.float64)\n",
      "tensor([[ 1.,  0.,  9.],\n",
      "        [36.,  0., 64.]], dtype=torch.float64)\n",
      "\n",
      "tensor([[ 1.,  0.,  9.],\n",
      "        [36.,  0., 64.]], dtype=torch.float64)\n",
      "\n",
      "z3:tensor([[ 1.,  0.,  9.],\n",
      "        [36.,  0., 64.]], dtype=torch.float64)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZXD\\AppData\\Local\\Temp\\ipykernel_12128\\793515796.py:7: UserWarning: An output with one or more elements was resized since it had shape [2, 3], which does not match the required output shape [2, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Resize.cpp:35.)\n",
      "  torch.matmul(tensor,tensor.T,out=y3)\n"
     ]
    }
   ],
   "source": [
    "#算术运算\n",
    "y1=tensor@tensor.T\n",
    "y2=tensor.matmul(tensor.T)\n",
    "\n",
    "y3=torch.rand_like(tensor)\n",
    "\n",
    "torch.matmul(tensor,tensor.T,out=y3)\n",
    "\n",
    "z1=tensor*tensor\n",
    "z2=tensor.mul(tensor)\n",
    "\n",
    "z3=torch.rand_like(tensor)\n",
    "\n",
    "torch.mul(tensor,tensor,out=z3)\n",
    "\n",
    "print(f\"tensor:{tensor}\")\n",
    "print(f\"y3 {y3}\")\n",
    " \n",
    "print(z1)\n",
    "print()\n",
    "print(z2)\n",
    "print()\n",
    "print(f\"z3:{z3}\")\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg=tensor.sum()\n",
    "agg_item=agg.item()\n",
    "print(agg_item,type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 3.],\n",
      "        [6., 0., 8.]], dtype=torch.float64) \n",
      "\n",
      "tensor([[ 6.,  5.,  8.],\n",
      "        [11.,  5., 13.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(tensor,\"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([1., 1., 1., 1., 1.])\n",
      "n:[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t=torch.ones(5)\n",
    "print(f\"t:{t}\")\n",
    "n=t.numpy()\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([2., 2., 2., 2., 2.])\n",
      "n:[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.ones(5)\n",
    "t=torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n:[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n,1,out=n)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:tensor([ 1.4138,  5.8278, -0.2165,  1.2927, -0.7357,  2.2571,  5.6715],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression001.png'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "A=torch.randn(7,9,requires_grad=True)\n",
    "b=torch.randn(9,requires_grad=True)\n",
    "c=torch.randn(1,requires_grad=True)\n",
    "x=torch.randn(9,requires_grad=True)\n",
    "\n",
    "result=torch.matmul(A,x.T)+torch.matmul(b,x)+c\n",
    "print(f\"result:{result}\")\n",
    "\n",
    "dot=make_dot(result,params={'A':A,'b':b,'c':c,'x':x})\n",
    "dot.render('expression001',format='png',cleanup=True,view=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
