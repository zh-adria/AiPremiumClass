{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n"
     ]
    }
   ],
   "source": [
    "#导入sklearn包\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "##1、准备数据\n",
    "x=iris.data[0:100,:]\n",
    "y=iris.target[0:100]\n",
    "\n",
    "#1.1、拆分训练和测试集\n",
    "#当 shuffle=True 时，生成的样本会按照随机顺序排列；\n",
    "# #当 shuffle=False 时，生成的样本会按照类别顺序依次排列。\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.2,shuffle=True)\n",
    "\n",
    "##1.2、初始化模型参数\n",
    "print(train_x.shape)\n",
    "theta=np.random.randn(1,4)\n",
    "bias=0 \n",
    "##1.3、学习率\n",
    "lr=1e-1\n",
    "##1.4、模型训练的轮数\n",
    "epoch=5000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2、前向计算\n",
    "def forward(x,theta,bias):\n",
    "    z=np.dot(theta,x.T)+bias \n",
    "    ##sigmoid\n",
    "    y_hat=1/(1+np.exp(-z))\n",
    "    return y_hat\n",
    "\n",
    "#3、损失函数\n",
    "def loss_function(y,y_hat):\n",
    "    e=1e-8  ###防止y_hat=0\n",
    "    return -y*np.log(y_hat+e)-(1-y)*np.log(1-y_hat+e)\n",
    "\n",
    "#4、计算梯度\n",
    "def calc_gradient(x,y,y_hat):\n",
    "    m=x.shape[-1]\n",
    "    delta_w=np.dot(y_hat-y,x)/m\n",
    "    delta_b=np.mean(y_hat-y)\n",
    "    return delta_w,delta_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0  loss:  2.392200914951529\n",
      "step:  500  loss:  0.00026800216183980494\n",
      "step:  1000  loss:  0.0002241375534232674\n",
      "step:  1500  loss:  0.00019296372998128033\n",
      "step:  2000  loss:  0.0001696214445114697\n",
      "step:  2500  loss:  0.00015146194016948684\n",
      "step:  3000  loss:  0.00013691529907592024\n",
      "step:  3500  loss:  0.00012499050301277475\n",
      "step:  4000  loss:  0.00011503038676594261\n",
      "step:  4500  loss:  0.0001065815700164067\n",
      "[[-0.69216423 -5.27615664  6.5815708   2.77198987]]\n",
      "-0.048556157654977804\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    ##正向\n",
    "    y_hat=forward(train_x,theta,bias)\n",
    "    ##计算损失\n",
    "    loss=np.mean(loss_function(train_y,y_hat))\n",
    "    if i%500==0:\n",
    "        print('step: ',i,' loss: ',loss)\n",
    "    ###梯度下降\n",
    "    dw,db=calc_gradient(train_x,train_y,y_hat)\n",
    "    ##更新参数\n",
    "    theta-=lr*dw\n",
    "    bias-=lr*db\n",
    "print(theta)\n",
    "print(bias)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.048556157654977804\n",
      "[1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "##保存模型参数\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(bias)\n",
    "##保存模型参数 theta 、bias\n",
    "df_theta=pd.DataFrame(theta);\n",
    "df_theta.to_csv(\"theta.csv\",index=False)\n",
    "\n",
    "df_bias=pd.DataFrame([bias]);\n",
    "df_bias.to_csv(\"bias.csv\",index=False)\n",
    "\n",
    "print(test_y)\n",
    " \n",
    "###测试数据导出\n",
    "df=pd.DataFrame(test_y)\n",
    "df.to_csv(\"test_y.csv\",index=False)\n",
    "\n",
    "dfx=pd.DataFrame(test_x)\n",
    "dfx.to_csv(\"test_x.csv\",index=False)\n",
    "    \n",
    "     \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值：[1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      " 真实值：[1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##测试模型\n",
    "def predict(x):\n",
    "    \n",
    "    pred=forward(x,theta,bias)\n",
    "    return [1 if i>0.5 else 0 for i in pred[0]]\n",
    "    \n",
    " \n",
    "sum=0\n",
    "pred=predict(test_x)\n",
    "print(f\"预测值：{pred}\\n 真实值：{test_y}\")\n",
    " \n",
    "sum=np.sum(pred-test_y)\n",
    "sum\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
