{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用fasttext中的无监督学习来训练word2vec词向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "with open(r'F:\\NLP算法课程\\正式课\\0319\\语言模型及词向量相关知识\\cn_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "with open(r'F:\\NLP算法课程\\正式课\\0319\\语言模型及词向量相关知识\\浪潮之巅.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "words = jieba.lcut(content) # 得到分完词的list\n",
    "# 添加停用词和中文过滤\n",
    "filtered = [w for w in words \n",
    "            if w not in stopwords \n",
    "            and len(w) > 1  # 新增长度过滤\n",
    "            and '\\u4e00' <= w <= '\\u9fff']  # 仅保留中文\n",
    "\n",
    "# 保存分词结果\n",
    "with open('corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for sentence in filtered:\n",
    "        f.write(' '.join(sentence) + '\\n')  # 将分词结果转换为空格分隔格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext: [-3.81984748e-04 -5.31082449e-04  1.20665114e-04  3.79996723e-04\n",
      "  2.20582824e-05 -9.33811476e-04 -2.10810380e-04  5.34110295e-04\n",
      "  3.36948375e-04  4.43096360e-04  5.20702451e-04  3.91902373e-04\n",
      "  5.15083957e-04 -5.00595430e-04  9.17334837e-05 -6.30763301e-04\n",
      " -1.35641210e-04  3.56432982e-04 -3.04077199e-04  8.48774507e-04\n",
      " -2.28332196e-04  1.78923394e-04 -1.54820955e-04 -2.44773109e-04\n",
      "  7.36900314e-04  1.29717009e-04 -5.59824926e-04  5.01744275e-04\n",
      " -8.06300144e-04  3.06621718e-04 -9.73400074e-06 -4.56485441e-06\n",
      "  9.63647653e-06 -2.41475645e-04 -1.03469545e-04 -4.18703072e-04\n",
      " -1.13324357e-04  9.82562895e-04 -8.52955054e-05 -1.25719653e-03\n",
      "  4.72889769e-05  6.64324034e-05 -5.75779879e-04 -6.49228969e-05\n",
      "  6.99132041e-04 -2.24352159e-04 -7.07470346e-04  3.67770059e-04\n",
      "  9.29063477e-04  1.78462156e-04 -1.02151673e-04 -1.93125481e-04\n",
      "  5.65471419e-04  5.32329665e-04 -1.84248674e-05 -2.52920290e-04\n",
      "  1.05179125e-03  1.72848464e-04 -9.63172584e-04 -3.04652436e-04\n",
      "  9.87702748e-04  2.88837589e-04  5.30246296e-04 -3.18075938e-04\n",
      " -6.80472353e-04 -5.67953975e-04  3.16007965e-04  5.98235405e-04\n",
      "  5.56445157e-04  8.21420457e-04  3.35685922e-06  1.09856355e-03\n",
      " -5.46638446e-04 -5.11666585e-04  1.19215227e-04 -9.41731210e-04\n",
      " -6.14640943e-04  9.14223609e-04  1.15356222e-03  2.80100910e-04\n",
      "  8.39282409e-04 -9.20825638e-04  1.13979449e-05 -1.14809279e-03\n",
      "  7.27589359e-04  9.21694562e-04  1.01662590e-06  2.64810747e-04\n",
      " -6.07341237e-04 -1.58784842e-05 -1.06196315e-03  1.82605960e-04\n",
      "  1.80227333e-04  6.77298231e-04 -6.93608890e-04 -5.22244896e-04\n",
      " -1.20313547e-03 -7.64917873e-04  1.15421622e-04 -4.79907932e-04\n",
      "  4.91254497e-04  3.63529951e-04 -3.62842839e-04  5.05687785e-04\n",
      " -7.32850240e-05 -1.32270437e-03 -1.49652449e-04 -2.21475610e-04\n",
      "  5.03226729e-05  8.49184289e-04  3.11311189e-04  1.48453575e-03\n",
      "  9.12855539e-05  4.14049573e-04 -6.85570587e-04 -1.60693380e-04\n",
      " -3.56811506e-04 -1.40867909e-04  4.44587524e-04  7.37813883e-04\n",
      "  1.15375244e-03 -1.20955659e-03 -2.12340688e-04 -8.62235494e-04\n",
      "  1.39230528e-04 -1.18108583e-04  7.17952717e-05  3.34543176e-04\n",
      "  2.36545748e-06 -1.10135612e-03 -2.07193574e-04 -3.45191540e-04\n",
      "  2.01017130e-04  6.87669904e-04  3.96742616e-05  4.63131350e-04\n",
      " -8.53204168e-04  4.63489268e-04  2.45842821e-04 -1.01786654e-03\n",
      " -6.87685329e-04  3.75136035e-04  8.89821677e-05  7.10278764e-05\n",
      "  1.32376517e-04 -6.17031881e-04  4.84355929e-04  1.84309130e-04\n",
      " -3.35822784e-04  6.20871142e-04  3.44896893e-04  4.07583982e-04\n",
      " -6.52645540e-04  5.25168398e-05 -6.21605941e-05  3.57362820e-04\n",
      "  3.65719636e-04 -6.78686716e-04 -7.39333627e-04  4.76113608e-04\n",
      " -7.27780396e-04  2.41562520e-04 -1.58944109e-04  9.45408829e-04\n",
      "  4.65319114e-04 -5.70856442e-04  1.60127092e-04 -3.91278329e-04\n",
      " -4.66348662e-04 -4.44048463e-04  1.33778783e-04 -1.42343823e-04\n",
      " -8.89226620e-04 -7.83224707e-04  3.49869806e-04 -6.16669713e-04\n",
      "  8.23083450e-04  1.58209892e-04 -8.95894889e-04  2.25146883e-04\n",
      "  3.96134092e-05 -4.21055120e-05  2.26470685e-04  6.64630497e-04\n",
      " -6.01366744e-04 -4.35255206e-04 -1.40934353e-04  4.42461351e-05\n",
      " -6.97238953e-04  6.41865132e-04  1.84154997e-04 -6.36115845e-04\n",
      "  7.76813657e-04  8.91234595e-05 -1.11139438e-03  8.17204360e-04\n",
      "  7.05658676e-05  5.37508284e-04  3.61011189e-04 -4.94718202e-04\n",
      " -4.67870210e-04  4.16615294e-05  1.74635745e-04 -1.08405926e-04\n",
      " -1.03915714e-04 -4.20564575e-05  5.78645791e-04 -5.04550291e-04\n",
      " -2.20340429e-04 -2.71475874e-04  3.30958806e-04  6.04268098e-05\n",
      "  5.78680309e-04  6.76423020e-04  2.92121811e-04 -4.62912460e-04\n",
      "  1.58673225e-04 -6.31703006e-04  1.69881860e-05 -3.03417211e-04\n",
      " -1.03083437e-06 -5.09683625e-04 -5.22490824e-04 -1.29766049e-04\n",
      " -5.52157464e-04  2.22528543e-04 -2.95104313e-04 -1.22015621e-03\n",
      "  3.32860596e-04  2.17423076e-04 -1.31264608e-03  4.79681737e-04\n",
      " -5.38643159e-04 -7.16065522e-04 -3.04345274e-04 -6.35874865e-04\n",
      " -5.56489162e-04  2.79108819e-04 -6.91517431e-04  7.05470331e-04\n",
      "  7.76441593e-05  1.89889921e-04 -1.37200273e-04 -4.48731153e-04\n",
      "  1.49412124e-04 -7.73904903e-04 -4.98574482e-05  4.10731416e-04\n",
      "  1.26631625e-04 -4.18480777e-04  1.95408938e-05  7.14543392e-04\n",
      " -5.77277329e-04 -5.53584367e-04 -1.03720107e-04 -7.22033554e-04\n",
      "  2.29189638e-04  1.01196987e-04 -8.53416219e-04  3.48642701e-04\n",
      "  2.10854021e-04  3.78476543e-04  2.19727270e-04  1.38829142e-04\n",
      " -4.54575988e-04 -5.29278943e-04 -1.40317410e-04  3.50295275e-04\n",
      "  6.02269538e-05  7.44341814e-04 -3.49646143e-04  6.74960844e-04\n",
      " -1.57038961e-03 -4.52102366e-04 -3.81548714e-04  7.11569912e-04\n",
      "  1.35850441e-03  6.15060620e-04  3.10718606e-04  3.37421283e-04\n",
      "  5.11976425e-04  7.79433321e-05  3.20824533e-04  1.35998242e-03\n",
      "  2.05640725e-04  1.26523734e-03 -9.95837501e-04 -3.32612864e-04\n",
      "  6.98441756e-04  9.03983600e-05 -1.11565739e-03 -5.11419901e-04\n",
      " -4.10266977e-04 -4.85364260e-04  9.56399948e-04  3.55349825e-04\n",
      " -4.08682798e-04 -4.01688827e-04  1.27053818e-05  6.81487494e-04]\n",
      "fasttext： [(0.1362512707710266, '缩'), (0.1289866417646408, '空'), (0.127944216132164, '施'), (0.11883315443992615, '废'), (0.11453510075807571, '末'), (0.11210155487060547, '查'), (0.11090695112943649, '洛'), (0.11075159907341003, '望'), (0.11063854396343231, '短'), (0.11027277261018753, '猴')]\n"
     ]
    }
   ],
   "source": [
    "# fasttext\n",
    "model_fasttext = fasttext.train_unsupervised(\n",
    "    input='corpus.txt',        # 预处理后的文本文件（分词后的语料）\n",
    "    model='skipgram',          # 选择模式：skipgram 或 cbow\n",
    "    dim=300,                   # 词向量维度\n",
    "    ws=5,                      # 上下文窗口大小\n",
    "    minn=3,                    # 最小字符n-gram\n",
    "    maxn=6,                    # 最大字符n-gram\n",
    "    epoch=50                   # 训练轮次\n",
    ")\n",
    "# 保存模型\n",
    "model_fasttext.save_model('fasttext.bin')\n",
    "\n",
    "model_w2v = Word2Vec(filtered, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model_w2v.save('word2vec.bin')\n",
    "\n",
    "print('fasttext:',model_fasttext.get_word_vector(\"人工智能\")) \n",
    "print('fasttext：',model_fasttext.get_nearest_neighbors(\"人工智能\")) \n",
    "\n",
    "# print('Word2Vec向量:', model_w2v.wv['数学'])  # 获取词向量，如果是未登录词会报错\n",
    "# print('Word2Vec最近邻:', model_w2v.wv.most_similar('数学', topn=5))  # 取前5个相似词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "# 加载模型并获取目标词信息\n",
    "model = fasttext.load_model(\"fasttext.bin\")\n",
    "target_word = \"数学\"\n",
    "\n",
    "# 构建专属数据集\n",
    "related_words = [target_word]\n",
    "vectors = np.array([model.get_word_vector(target_word)])  # 单向量处理\n",
    "\n",
    "# 修改metadata生成\n",
    "with open('metadata.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Word\\n\") \n",
    "    f.write(f\"{target_word}\\n\")  # 仅写入目标词\n",
    "\n",
    "# 保存向量和配置\n",
    "np.save('vectors.npy', vectors)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = 'vectors.npy'\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "\n",
    "\n",
    "import os\n",
    "os.makedirs('word_vectors', exist_ok=True)  # 确保目录存在\n",
    "# 在调用 visualize_embeddings 之前添加文件同步（重要）\n",
    "import shutil\n",
    "shutil.copy('vectors.npy', 'word_vectors/') \n",
    "shutil.copy('metadata.tsv', 'word_vectors/')\n",
    "\n",
    "# 原代码保持不变\n",
    "projector.visualize_embeddings('word_vectors', config)\n",
    "\n",
    "# 启动TensorBoard\n",
    "projector.visualize_embeddings('word_vectors', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
